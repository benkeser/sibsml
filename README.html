<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">

<style type="text/css">
@font-face {
font-family: octicons-link;
src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}
body {
-webkit-text-size-adjust: 100%;
text-size-adjust: 100%;
color: #333;
font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
font-size: 16px;
line-height: 1.6;
word-wrap: break-word;
}
a {
background-color: transparent;
}
a:active,
a:hover {
outline: 0;
}
strong {
font-weight: bold;
}
h1 {
font-size: 2em;
margin: 0.67em 0;
}
img {
border: 0;
}
hr {
box-sizing: content-box;
height: 0;
}
pre {
overflow: auto;
}
code,
kbd,
pre {
font-family: monospace, monospace;
font-size: 1em;
}
input {
color: inherit;
font: inherit;
margin: 0;
}
html input[disabled] {
cursor: default;
}
input {
line-height: normal;
}
input[type="checkbox"] {
box-sizing: border-box;
padding: 0;
}
table {
border-collapse: collapse;
border-spacing: 0;
}
td,
th {
padding: 0;
}
* {
box-sizing: border-box;
}
input {
font: 13px / 1.4 Helvetica, arial, nimbussansl, liberationsans, freesans, clean, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
}
a {
color: #4078c0;
text-decoration: none;
}
a:hover,
a:active {
text-decoration: underline;
}
hr {
height: 0;
margin: 15px 0;
overflow: hidden;
background: transparent;
border: 0;
border-bottom: 1px solid #ddd;
}
hr:before {
display: table;
content: "";
}
hr:after {
display: table;
clear: both;
content: "";
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 15px;
margin-bottom: 15px;
line-height: 1.1;
}
h1 {
font-size: 30px;
}
h2 {
font-size: 21px;
}
h3 {
font-size: 16px;
}
h4 {
font-size: 14px;
}
h5 {
font-size: 12px;
}
h6 {
font-size: 11px;
}
blockquote {
margin: 0;
}
ul,
ol {
padding: 0;
margin-top: 0;
margin-bottom: 0;
}
ol ol,
ul ol {
list-style-type: lower-roman;
}
ul ul ol,
ul ol ol,
ol ul ol,
ol ol ol {
list-style-type: lower-alpha;
}
dd {
margin-left: 0;
}
code {
font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
font-size: 12px;
}
pre {
margin-top: 0;
margin-bottom: 0;
font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
}
.select::-ms-expand {
opacity: 0;
}
.octicon {
font: normal normal normal 16px/1 octicons-link;
display: inline-block;
text-decoration: none;
text-rendering: auto;
-webkit-font-smoothing: antialiased;
-moz-osx-font-smoothing: grayscale;
-webkit-user-select: none;
-moz-user-select: none;
-ms-user-select: none;
user-select: none;
}
.octicon-link:before {
content: '\f05c';
}
.markdown-body:before {
display: table;
content: "";
}
.markdown-body:after {
display: table;
clear: both;
content: "";
}
.markdown-body>*:first-child {
margin-top: 0 !important;
}
.markdown-body>*:last-child {
margin-bottom: 0 !important;
}
a:not([href]) {
color: inherit;
text-decoration: none;
}
.anchor {
display: inline-block;
padding-right: 2px;
margin-left: -18px;
}
.anchor:focus {
outline: none;
}
h1,
h2,
h3,
h4,
h5,
h6 {
margin-top: 1em;
margin-bottom: 16px;
font-weight: bold;
line-height: 1.4;
}
h1 .octicon-link,
h2 .octicon-link,
h3 .octicon-link,
h4 .octicon-link,
h5 .octicon-link,
h6 .octicon-link {
color: #000;
vertical-align: middle;
visibility: hidden;
}
h1:hover .anchor,
h2:hover .anchor,
h3:hover .anchor,
h4:hover .anchor,
h5:hover .anchor,
h6:hover .anchor {
text-decoration: none;
}
h1:hover .anchor .octicon-link,
h2:hover .anchor .octicon-link,
h3:hover .anchor .octicon-link,
h4:hover .anchor .octicon-link,
h5:hover .anchor .octicon-link,
h6:hover .anchor .octicon-link {
visibility: visible;
}
h1 {
padding-bottom: 0.3em;
font-size: 2.25em;
line-height: 1.2;
border-bottom: 1px solid #eee;
}
h1 .anchor {
line-height: 1;
}
h2 {
padding-bottom: 0.3em;
font-size: 1.75em;
line-height: 1.225;
border-bottom: 1px solid #eee;
}
h2 .anchor {
line-height: 1;
}
h3 {
font-size: 1.5em;
line-height: 1.43;
}
h3 .anchor {
line-height: 1.2;
}
h4 {
font-size: 1.25em;
}
h4 .anchor {
line-height: 1.2;
}
h5 {
font-size: 1em;
}
h5 .anchor {
line-height: 1.1;
}
h6 {
font-size: 1em;
color: #777;
}
h6 .anchor {
line-height: 1.1;
}
p,
blockquote,
ul,
ol,
dl,
table,
pre {
margin-top: 0;
margin-bottom: 16px;
}
hr {
height: 4px;
padding: 0;
margin: 16px 0;
background-color: #e7e7e7;
border: 0 none;
}
ul,
ol {
padding-left: 2em;
}
ul ul,
ul ol,
ol ol,
ol ul {
margin-top: 0;
margin-bottom: 0;
}
li>p {
margin-top: 16px;
}
dl {
padding: 0;
}
dl dt {
padding: 0;
margin-top: 16px;
font-size: 1em;
font-style: italic;
font-weight: bold;
}
dl dd {
padding: 0 16px;
margin-bottom: 16px;
}
blockquote {
padding: 0 15px;
color: #777;
border-left: 4px solid #ddd;
}
blockquote>:first-child {
margin-top: 0;
}
blockquote>:last-child {
margin-bottom: 0;
}
table {
display: block;
width: 100%;
overflow: auto;
word-break: normal;
word-break: keep-all;
}
table th {
font-weight: bold;
}
table th,
table td {
padding: 6px 13px;
border: 1px solid #ddd;
}
table tr {
background-color: #fff;
border-top: 1px solid #ccc;
}
table tr:nth-child(2n) {
background-color: #f8f8f8;
}
img {
max-width: 100%;
box-sizing: content-box;
background-color: #fff;
}
code {
padding: 0;
padding-top: 0.2em;
padding-bottom: 0.2em;
margin: 0;
font-size: 85%;
background-color: rgba(0,0,0,0.04);
border-radius: 3px;
}
code:before,
code:after {
letter-spacing: -0.2em;
content: "\00a0";
}
pre>code {
padding: 0;
margin: 0;
font-size: 100%;
word-break: normal;
white-space: pre;
background: transparent;
border: 0;
}
.highlight {
margin-bottom: 16px;
}
.highlight pre,
pre {
padding: 16px;
overflow: auto;
font-size: 85%;
line-height: 1.45;
background-color: #f7f7f7;
border-radius: 3px;
}
.highlight pre {
margin-bottom: 0;
word-break: normal;
}
pre {
word-wrap: normal;
}
pre code {
display: inline;
max-width: initial;
padding: 0;
margin: 0;
overflow: initial;
line-height: inherit;
word-wrap: normal;
background-color: transparent;
border: 0;
}
pre code:before,
pre code:after {
content: normal;
}
kbd {
display: inline-block;
padding: 3px 5px;
font-size: 11px;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.pl-c {
color: #969896;
}
.pl-c1,
.pl-s .pl-v {
color: #0086b3;
}
.pl-e,
.pl-en {
color: #795da3;
}
.pl-s .pl-s1,
.pl-smi {
color: #333;
}
.pl-ent {
color: #63a35c;
}
.pl-k {
color: #a71d5d;
}
.pl-pds,
.pl-s,
.pl-s .pl-pse .pl-s1,
.pl-sr,
.pl-sr .pl-cce,
.pl-sr .pl-sra,
.pl-sr .pl-sre {
color: #183691;
}
.pl-v {
color: #ed6a43;
}
.pl-id {
color: #b52a1d;
}
.pl-ii {
background-color: #b52a1d;
color: #f8f8f8;
}
.pl-sr .pl-cce {
color: #63a35c;
font-weight: bold;
}
.pl-ml {
color: #693a17;
}
.pl-mh,
.pl-mh .pl-en,
.pl-ms {
color: #1d3e81;
font-weight: bold;
}
.pl-mq {
color: #008080;
}
.pl-mi {
color: #333;
font-style: italic;
}
.pl-mb {
color: #333;
font-weight: bold;
}
.pl-md {
background-color: #ffecec;
color: #bd2c00;
}
.pl-mi1 {
background-color: #eaffea;
color: #55a532;
}
.pl-mdr {
color: #795da3;
font-weight: bold;
}
.pl-mo {
color: #1d3e81;
}
kbd {
display: inline-block;
padding: 3px 5px;
font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
line-height: 10px;
color: #555;
vertical-align: middle;
background-color: #fcfcfc;
border: solid 1px #ccc;
border-bottom-color: #bbb;
border-radius: 3px;
box-shadow: inset 0 -1px 0 #bbb;
}
.task-list-item {
list-style-type: none;
}
.task-list-item+.task-list-item {
margin-top: 3px;
}
.task-list-item input {
margin: 0 0.35em 0.25em -1.6em;
vertical-align: middle;
}
:checked+.radio-label {
z-index: 1;
position: relative;
border-color: #4078c0;
}
.sourceLine {
display: inline-block;
}
code .kw { color: #000000; }
code .dt { color: #ed6a43; }
code .dv { color: #009999; }
code .bn { color: #009999; }
code .fl { color: #009999; }
code .ch { color: #009999; }
code .st { color: #183691; }
code .co { color: #969896; }
code .ot { color: #0086b3; }
code .al { color: #a61717; }
code .fu { color: #63a35c; }
code .er { color: #a61717; background-color: #e3d2d2; }
code .wa { color: #000000; }
code .cn { color: #008080; }
code .sc { color: #008080; }
code .vs { color: #183691; }
code .ss { color: #183691; }
code .im { color: #000000; }
code .va {color: #008080; }
code .cf { color: #000000; }
code .op { color: #000000; }
code .bu { color: #000000; }
code .ex { color: #000000; }
code .pp { color: #999999; }
code .at { color: #008080; }
code .do { color: #969896; }
code .an { color: #008080; }
code .cv { color: #008080; }
code .in { color: #008080; }
</style>
<style>
body {
  box-sizing: border-box;
  min-width: 200px;
  max-width: 980px;
  margin: 0 auto;
  padding: 45px;
  padding-top: 0px;
}
</style>

</head>

<body>

<h1 id="introduction-to-machine-learning">Introduction to Machine Learning</h1>
<p>David Benkeser June 27, 2018</p>
<!-- README.md is generated from README.Rmd. Please edit that file -->

<h2 id="introduction">Introduction</h2>
<p>In this demonstration, we will illustrate some basic principals discussed in class using <code>R</code>.</p>
<h2 id="preliminaries">Preliminaries</h2>
<p>You can execute the following commands to install the packages needed to complete this demo.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="co"># if needed, install all the necessary pacakges to execute this demo</span></a>
<a class="sourceLine" id="cb1-2" data-line-number="2">pkgs &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;SuperLearner&quot;</span>, <span class="st">&quot;randomForest&quot;</span>, <span class="st">&quot;RCurl&quot;</span>, <span class="st">&quot;MASS&quot;</span>,</a>
<a class="sourceLine" id="cb1-3" data-line-number="3">          <span class="st">&quot;ggplot2&quot;</span>,<span class="st">&quot;nnls&quot;</span>)</a>
<a class="sourceLine" id="cb1-4" data-line-number="4">installed_pacakges &lt;-<span class="st"> </span><span class="kw">row.names</span>(<span class="kw">installed.packages</span>())</a>
<a class="sourceLine" id="cb1-5" data-line-number="5"><span class="co"># .libPaths(&quot;H:/&quot;)</span></a>
<a class="sourceLine" id="cb1-6" data-line-number="6"><span class="cf">for</span>(p <span class="cf">in</span> pkgs){</a>
<a class="sourceLine" id="cb1-7" data-line-number="7">  <span class="co"># check if p is installed</span></a>
<a class="sourceLine" id="cb1-8" data-line-number="8">  already_installed &lt;-<span class="st"> </span>p <span class="op">%in%</span><span class="st"> </span>installed_pacakges </a>
<a class="sourceLine" id="cb1-9" data-line-number="9">  <span class="co"># if not install it</span></a>
<a class="sourceLine" id="cb1-10" data-line-number="10">  <span class="cf">if</span>(<span class="op">!</span>already_installed){</a>
<a class="sourceLine" id="cb1-11" data-line-number="11">    <span class="kw">install.packages</span>(p)</a>
<a class="sourceLine" id="cb1-12" data-line-number="12">  }</a>
<a class="sourceLine" id="cb1-13" data-line-number="13">  <span class="co"># load package</span></a>
<a class="sourceLine" id="cb1-14" data-line-number="14">  <span class="kw">library</span>(p, <span class="dt">character.only =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb1-15" data-line-number="15">}</a></code></pre></div>
<p>I have made a data set available on GitHub that will be used in this demo. It can be read directly from GitHub using the following commands:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1">web_address &lt;-<span class="st"> </span><span class="kw">getURL</span>(<span class="st">&quot;https://raw.githubusercontent.com/benkeser/sllecture/master/chspred.csv&quot;</span>)</a>
<a class="sourceLine" id="cb2-2" data-line-number="2">full_data &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="dt">text =</span> web_address, <span class="dt">header =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<p>We can take a look at the data to make sure it is loaded properly:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="co"># head displays the first six rows of data</span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="kw">head</span>(full_data)</a>
<a class="sourceLine" id="cb3-3" data-line-number="3"><span class="co">#&gt;       waist    alcoh      hdl beta smoke ace       ldl      bmi aspirin</span></a>
<a class="sourceLine" id="cb3-4" data-line-number="4"><span class="co">#&gt; 1 110.16419 0.000000 66.49739    0     0   1 114.21622 27.99746       0</span></a>
<a class="sourceLine" id="cb3-5" data-line-number="5"><span class="co">#&gt; 2  89.97632 0.000000 50.06524    0     0   0 103.77662 20.89314       0</span></a>
<a class="sourceLine" id="cb3-6" data-line-number="6"><span class="co">#&gt; 3 106.19407 8.417438 40.50595    0     0   0 165.71580 28.45541       1</span></a>
<a class="sourceLine" id="cb3-7" data-line-number="7"><span class="co">#&gt; 4  90.05662 0.000000 36.17505    0     0   0  45.20349 23.96079       0</span></a>
<a class="sourceLine" id="cb3-8" data-line-number="8"><span class="co">#&gt; 5  78.61425 2.979014 71.06422    0     1   0 131.31211 10.96558       0</span></a>
<a class="sourceLine" id="cb3-9" data-line-number="9"><span class="co">#&gt; 6  91.65934 0.000000 59.49628    0     0   0 171.18718 29.13170       0</span></a>
<a class="sourceLine" id="cb3-10" data-line-number="10"><span class="co">#&gt;   gend      age estrgn       glu        ins   cysgfr dm   fetuina</span></a>
<a class="sourceLine" id="cb3-11" data-line-number="11"><span class="co">#&gt; 1    0 73.51795      0 159.93141  70.334308 75.00781  1 0.1751561</span></a>
<a class="sourceLine" id="cb3-12" data-line-number="12"><span class="co">#&gt; 2    0 61.77225      0 153.38882  33.969450 82.74331  1 0.5716507</span></a>
<a class="sourceLine" id="cb3-13" data-line-number="13"><span class="co">#&gt; 3    1 72.93120      0 121.71452 -17.301732 74.69888  0 0.3516775</span></a>
<a class="sourceLine" id="cb3-14" data-line-number="14"><span class="co">#&gt; 4    0 79.11913      0  53.96908  11.731511 95.78227  0 0.5439133</span></a>
<a class="sourceLine" id="cb3-15" data-line-number="15"><span class="co">#&gt; 5    1 69.01791      0  94.31526   9.711168 72.71094  0 0.4915944</span></a>
<a class="sourceLine" id="cb3-16" data-line-number="16"><span class="co">#&gt; 6    1 81.83463      0 212.90660 -28.226900 69.21838  1 0.4621461</span></a>
<a class="sourceLine" id="cb3-17" data-line-number="17"><span class="co">#&gt;         whr hsed race   logcystat  logtrig     logcrp       logcre health</span></a>
<a class="sourceLine" id="cb3-18" data-line-number="18"><span class="co">#&gt; 1 1.1689797    1    1 -0.34202495 5.406297  2.0125961 -0.673854825      0</span></a>
<a class="sourceLine" id="cb3-19" data-line-number="19"><span class="co">#&gt; 2 0.9011436    0    0 -0.08465306 4.859234  3.2932809 -0.555090108      1</span></a>
<a class="sourceLine" id="cb3-20" data-line-number="20"><span class="co">#&gt; 3 1.1797129    0    1 -0.44510754 4.508810  0.3013225 -0.011517925      0</span></a>
<a class="sourceLine" id="cb3-21" data-line-number="21"><span class="co">#&gt; 4 1.1359920    0    0 -0.48072046 5.183202  3.0242614 -0.575068973      1</span></a>
<a class="sourceLine" id="cb3-22" data-line-number="22"><span class="co">#&gt; 5 1.1027589    1    0  0.31206416 4.218965 -0.7056767  0.005340564      1</span></a>
<a class="sourceLine" id="cb3-23" data-line-number="23"><span class="co">#&gt; 6 0.9529133    1    0 -0.28715867 5.177331  0.9704625  0.212682488      1</span></a>
<a class="sourceLine" id="cb3-24" data-line-number="24"><span class="co">#&gt;    logkcal     sysbp mi</span></a>
<a class="sourceLine" id="cb3-25" data-line-number="25"><span class="co">#&gt; 1 4.392559 177.13454  0</span></a>
<a class="sourceLine" id="cb3-26" data-line-number="26"><span class="co">#&gt; 2 6.207056 136.37417  0</span></a>
<a class="sourceLine" id="cb3-27" data-line-number="27"><span class="co">#&gt; 3 6.731968 135.19927  0</span></a>
<a class="sourceLine" id="cb3-28" data-line-number="28"><span class="co">#&gt; 4 7.397201 139.01816  0</span></a>
<a class="sourceLine" id="cb3-29" data-line-number="29"><span class="co">#&gt; 5 8.277882  88.04703  0</span></a>
<a class="sourceLine" id="cb3-30" data-line-number="30"><span class="co">#&gt; 6 5.994176  69.59431  0</span></a>
<a class="sourceLine" id="cb3-31" data-line-number="31"><span class="co"># tail displays the last six rows of data</span></a>
<a class="sourceLine" id="cb3-32" data-line-number="32"><span class="kw">tail</span>(full_data)</a>
<a class="sourceLine" id="cb3-33" data-line-number="33"><span class="co">#&gt;          waist     alcoh      hdl beta smoke ace       ldl      bmi</span></a>
<a class="sourceLine" id="cb3-34" data-line-number="34"><span class="co">#&gt; 4585  97.80998  0.000000 74.56704    0     0   0  20.39784 22.59396</span></a>
<a class="sourceLine" id="cb3-35" data-line-number="35"><span class="co">#&gt; 4586  83.93628  0.000000 39.86891    0     1   0 200.30511 32.93323</span></a>
<a class="sourceLine" id="cb3-36" data-line-number="36"><span class="co">#&gt; 4587  98.69020 10.672029 35.08266    0     0   0  56.78766 17.21090</span></a>
<a class="sourceLine" id="cb3-37" data-line-number="37"><span class="co">#&gt; 4588  97.68590  0.000000 65.95610    0     0   0 187.39753 19.70763</span></a>
<a class="sourceLine" id="cb3-38" data-line-number="38"><span class="co">#&gt; 4589 104.86007  2.800136 43.03691    0     0   0  90.51863 20.83762</span></a>
<a class="sourceLine" id="cb3-39" data-line-number="39"><span class="co">#&gt; 4590  73.40203  0.000000 47.69960    0     0   0 128.18095 24.78673</span></a>
<a class="sourceLine" id="cb3-40" data-line-number="40"><span class="co">#&gt;      aspirin gend      age estrgn       glu        ins   cysgfr dm</span></a>
<a class="sourceLine" id="cb3-41" data-line-number="41"><span class="co">#&gt; 4585       0    0 79.03839      0 171.52806 -59.488629 86.81013  1</span></a>
<a class="sourceLine" id="cb3-42" data-line-number="42"><span class="co">#&gt; 4586       0    1 71.93363      0  70.19268  22.904675 65.85595  0</span></a>
<a class="sourceLine" id="cb3-43" data-line-number="43"><span class="co">#&gt; 4587       0    1 67.09645      0 137.51263   8.062108 99.62964  0</span></a>
<a class="sourceLine" id="cb3-44" data-line-number="44"><span class="co">#&gt; 4588       0    0 87.28538      0 147.96194 -77.834592 85.89258  0</span></a>
<a class="sourceLine" id="cb3-45" data-line-number="45"><span class="co">#&gt; 4589       1    0 73.41872      0 135.39740  61.664939 80.74006  0</span></a>
<a class="sourceLine" id="cb3-46" data-line-number="46"><span class="co">#&gt; 4590       0    0 69.98629      0  68.06760   1.511657 71.75666  0</span></a>
<a class="sourceLine" id="cb3-47" data-line-number="47"><span class="co">#&gt;        fetuina       whr hsed race   logcystat  logtrig     logcrp</span></a>
<a class="sourceLine" id="cb3-48" data-line-number="48"><span class="co">#&gt; 4585 0.5125178 0.8675563    0    0  0.08392824 5.249961  2.5213734</span></a>
<a class="sourceLine" id="cb3-49" data-line-number="49"><span class="co">#&gt; 4586 0.4535611 0.9854833    0    0  0.62371935 4.314962  0.6269751</span></a>
<a class="sourceLine" id="cb3-50" data-line-number="50"><span class="co">#&gt; 4587 0.4897765 1.0881311    1    0 -0.50401479 4.920840 -1.1959170</span></a>
<a class="sourceLine" id="cb3-51" data-line-number="51"><span class="co">#&gt; 4588 0.3670600 1.0320420    1    0 -0.37632885 3.560693 -1.0785190</span></a>
<a class="sourceLine" id="cb3-52" data-line-number="52"><span class="co">#&gt; 4589 0.5766547 0.7185098    1    0 -0.06307341 4.900429 -0.4000049</span></a>
<a class="sourceLine" id="cb3-53" data-line-number="53"><span class="co">#&gt; 4590 0.3559488 0.8614516    0    0  0.37455572 5.461931 -0.4738696</span></a>
<a class="sourceLine" id="cb3-54" data-line-number="54"><span class="co">#&gt;           logcre health   logkcal    sysbp mi</span></a>
<a class="sourceLine" id="cb3-55" data-line-number="55"><span class="co">#&gt; 4585 -0.47731979      1  7.129744 103.1167  0</span></a>
<a class="sourceLine" id="cb3-56" data-line-number="56"><span class="co">#&gt; 4586  0.35042604      1  8.676314 128.7980  0</span></a>
<a class="sourceLine" id="cb3-57" data-line-number="57"><span class="co">#&gt; 4587 -0.07601586      1  7.006918 169.3920  0</span></a>
<a class="sourceLine" id="cb3-58" data-line-number="58"><span class="co">#&gt; 4588 -0.40555671      1  0.000000 137.0874  0</span></a>
<a class="sourceLine" id="cb3-59" data-line-number="59"><span class="co">#&gt; 4589 -0.37884256      1  4.718733 124.9088  0</span></a>
<a class="sourceLine" id="cb3-60" data-line-number="60"><span class="co">#&gt; 4590  0.83207825      1 10.625681 126.6630  0</span></a>
<a class="sourceLine" id="cb3-61" data-line-number="61"><span class="co"># display the number of observations in the data</span></a>
<a class="sourceLine" id="cb3-62" data-line-number="62"><span class="kw">nrow</span>(full_data)</a>
<a class="sourceLine" id="cb3-63" data-line-number="63"><span class="co">#&gt; [1] 4590</span></a>
<a class="sourceLine" id="cb3-64" data-line-number="64"><span class="co"># display the number of columns in the data </span></a>
<a class="sourceLine" id="cb3-65" data-line-number="65"><span class="kw">ncol</span>(full_data)</a>
<a class="sourceLine" id="cb3-66" data-line-number="66"><span class="co">#&gt; [1] 28</span></a></code></pre></div>
<p>The column <code>mi</code> is an indicator of myocardial infarction (heart attack); all other variables can be considered features. These include demographic, medical, and other information on participants. We will use these data to predict myocardial infarction.</p>
<h2 id="prediction-with-logistic-regression">Prediction with logistic regression</h2>
<p>Our first exercise is to use logistic regression to predict myocardial infarction. We will consider two logistic regression models. The first regresses on <code>waist</code>, <code>smoke</code>, and <code>hdl</code>; the second regresses on all variables. We will fit these regression models using the full data and estimate their mean squared-error using the full data.</p>
<p>First, we train the two logistic regressions using the full data and generate prediction functions (i.e., machines) from which we can generate new predictions.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="co"># model 1 -- all variables</span></a>
<a class="sourceLine" id="cb4-2" data-line-number="2">model1 &lt;-<span class="st"> </span><span class="kw">glm</span>(mi <span class="op">~</span><span class="st"> </span>waist <span class="op">+</span><span class="st"> </span>smoke <span class="op">+</span><span class="st"> </span>hdl, <span class="dt">data =</span> full_data, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb4-3" data-line-number="3"><span class="co"># can look at the results</span></a>
<a class="sourceLine" id="cb4-4" data-line-number="4"><span class="kw">summary</span>(model1)</a>
<a class="sourceLine" id="cb4-5" data-line-number="5"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb4-6" data-line-number="6"><span class="co">#&gt; Call:</span></a>
<a class="sourceLine" id="cb4-7" data-line-number="7"><span class="co">#&gt; glm(formula = mi ~ waist + smoke + hdl, family = &quot;binomial&quot;, </span></a>
<a class="sourceLine" id="cb4-8" data-line-number="8"><span class="co">#&gt;     data = full_data)</span></a>
<a class="sourceLine" id="cb4-9" data-line-number="9"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb4-10" data-line-number="10"><span class="co">#&gt; Deviance Residuals: </span></a>
<a class="sourceLine" id="cb4-11" data-line-number="11"><span class="co">#&gt;     Min       1Q   Median       3Q      Max  </span></a>
<a class="sourceLine" id="cb4-12" data-line-number="12"><span class="co">#&gt; -0.5804  -0.2736  -0.2338  -0.1998   2.9808  </span></a>
<a class="sourceLine" id="cb4-13" data-line-number="13"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb4-14" data-line-number="14"><span class="co">#&gt; Coefficients:</span></a>
<a class="sourceLine" id="cb4-15" data-line-number="15"><span class="co">#&gt;              Estimate Std. Error z value Pr(&gt;|z|)    </span></a>
<a class="sourceLine" id="cb4-16" data-line-number="16"><span class="co">#&gt; (Intercept) -1.853886   0.601555  -3.082  0.00206 ** </span></a>
<a class="sourceLine" id="cb4-17" data-line-number="17"><span class="co">#&gt; waist       -0.022654   0.005356  -4.229 2.34e-05 ***</span></a>
<a class="sourceLine" id="cb4-18" data-line-number="18"><span class="co">#&gt; smoke        0.625000   0.223766   2.793  0.00522 ** </span></a>
<a class="sourceLine" id="cb4-19" data-line-number="19"><span class="co">#&gt; hdl          0.008611   0.004338   1.985  0.04715 *  </span></a>
<a class="sourceLine" id="cb4-20" data-line-number="20"><span class="co">#&gt; ---</span></a>
<a class="sourceLine" id="cb4-21" data-line-number="21"><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></a>
<a class="sourceLine" id="cb4-22" data-line-number="22"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb4-23" data-line-number="23"><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></a>
<a class="sourceLine" id="cb4-24" data-line-number="24"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb4-25" data-line-number="25"><span class="co">#&gt;     Null deviance: 1280.4  on 4589  degrees of freedom</span></a>
<a class="sourceLine" id="cb4-26" data-line-number="26"><span class="co">#&gt; Residual deviance: 1245.9  on 4586  degrees of freedom</span></a>
<a class="sourceLine" id="cb4-27" data-line-number="27"><span class="co">#&gt; AIC: 1253.9</span></a>
<a class="sourceLine" id="cb4-28" data-line-number="28"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb4-29" data-line-number="29"><span class="co">#&gt; Number of Fisher Scoring iterations: 6</span></a>
<a class="sourceLine" id="cb4-30" data-line-number="30"><span class="co"># we can now use model1 to make a &quot;machine&quot;, i.e., a function </span></a>
<a class="sourceLine" id="cb4-31" data-line-number="31"><span class="co"># that takes as input features of a new observation and outputs </span></a>
<a class="sourceLine" id="cb4-32" data-line-number="32"><span class="co"># a predicted probability of say Psi1 </span></a>
<a class="sourceLine" id="cb4-33" data-line-number="33">Psi1_longway &lt;-<span class="st"> </span><span class="cf">function</span>(new_waist, new_smoke, new_hdl, model){</a>
<a class="sourceLine" id="cb4-34" data-line-number="34">  <span class="co"># extract beta hats from model</span></a>
<a class="sourceLine" id="cb4-35" data-line-number="35">  beta0 &lt;-<span class="st"> </span>model<span class="op">$</span>coef[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb4-36" data-line-number="36">  beta1 &lt;-<span class="st"> </span>model<span class="op">$</span>coef[<span class="dv">2</span>]</a>
<a class="sourceLine" id="cb4-37" data-line-number="37">  beta2 &lt;-<span class="st"> </span>model<span class="op">$</span>coef[<span class="dv">3</span>]</a>
<a class="sourceLine" id="cb4-38" data-line-number="38">  beta3 &lt;-<span class="st"> </span>model<span class="op">$</span>coef[<span class="dv">4</span>]</a>
<a class="sourceLine" id="cb4-39" data-line-number="39">  <span class="co"># plogis is the inverse logit function</span></a>
<a class="sourceLine" id="cb4-40" data-line-number="40">  <span class="co"># i.e., we compute expit(b0 + b1 * waist + ...)</span></a>
<a class="sourceLine" id="cb4-41" data-line-number="41">  prediction &lt;-<span class="st"> </span><span class="kw">plogis</span>(beta0 <span class="op">+</span><span class="st"> </span>beta1 <span class="op">*</span><span class="st"> </span>new_waist <span class="op">+</span><span class="st"> </span>beta2 <span class="op">*</span><span class="st"> </span>new_smoke <span class="op">+</span><span class="st"> </span>beta3 <span class="op">*</span><span class="st"> </span>new_hdl)</a>
<a class="sourceLine" id="cb4-42" data-line-number="42">  <span class="co"># return the prediction</span></a>
<a class="sourceLine" id="cb4-43" data-line-number="43">  <span class="kw">return</span>(<span class="kw">as.numeric</span>(prediction))</a>
<a class="sourceLine" id="cb4-44" data-line-number="44">}</a>
<a class="sourceLine" id="cb4-45" data-line-number="45"></a>
<a class="sourceLine" id="cb4-46" data-line-number="46"><span class="co"># try it out on some new data</span></a>
<a class="sourceLine" id="cb4-47" data-line-number="47"><span class="kw">Psi1_longway</span>(<span class="dt">new_waist =</span> <span class="dv">90</span>, <span class="dt">new_smoke =</span> <span class="dv">0</span>, <span class="dt">new_hdl =</span> <span class="dv">50</span>, <span class="dt">model =</span> model1)</a>
<a class="sourceLine" id="cb4-48" data-line-number="48"><span class="co">#&gt; [1] 0.03040785</span></a>
<a class="sourceLine" id="cb4-49" data-line-number="49"><span class="kw">Psi1_longway</span>(<span class="dt">new_waist =</span> <span class="dv">100</span>, <span class="dt">new_smoke =</span> <span class="dv">0</span>, <span class="dt">new_hdl =</span> <span class="dv">40</span>, <span class="dt">model =</span> model1)</a>
<a class="sourceLine" id="cb4-50" data-line-number="50"><span class="co">#&gt; [1] 0.0224266</span></a>
<a class="sourceLine" id="cb4-51" data-line-number="51"><span class="kw">Psi1_longway</span>(<span class="dt">new_waist =</span> <span class="kw">mean</span>(full_data<span class="op">$</span>waist), </a>
<a class="sourceLine" id="cb4-52" data-line-number="52">             <span class="dt">new_smoke =</span> <span class="dv">1</span>, </a>
<a class="sourceLine" id="cb4-53" data-line-number="53">             <span class="dt">new_hdl =</span> <span class="kw">mean</span>(full_data<span class="op">$</span>hdl), <span class="dt">model =</span> model1)</a>
<a class="sourceLine" id="cb4-54" data-line-number="54"><span class="co">#&gt; [1] 0.04830798</span></a>
<a class="sourceLine" id="cb4-55" data-line-number="55"></a>
<a class="sourceLine" id="cb4-56" data-line-number="56"><span class="co"># we can instead make use of the predict method for glm for a more </span></a>
<a class="sourceLine" id="cb4-57" data-line-number="57"><span class="co"># concise version. here new_features is a data.frame a la full_data</span></a>
<a class="sourceLine" id="cb4-58" data-line-number="58">Psi1 &lt;-<span class="st"> </span><span class="cf">function</span>(new_features, model){</a>
<a class="sourceLine" id="cb4-59" data-line-number="59">  <span class="co"># call the predict method</span></a>
<a class="sourceLine" id="cb4-60" data-line-number="60">  <span class="co"># type = &quot;response&quot; ensures we get back the expit of the linear predictor</span></a>
<a class="sourceLine" id="cb4-61" data-line-number="61">  prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(model, <span class="dt">newdata =</span> new_features, <span class="dt">type =</span> <span class="st">'response'</span>)</a>
<a class="sourceLine" id="cb4-62" data-line-number="62">  <span class="kw">return</span>(<span class="kw">as.numeric</span>(prediction))</a>
<a class="sourceLine" id="cb4-63" data-line-number="63">}</a>
<a class="sourceLine" id="cb4-64" data-line-number="64"></a>
<a class="sourceLine" id="cb4-65" data-line-number="65"><span class="co"># try it out on some new data</span></a>
<a class="sourceLine" id="cb4-66" data-line-number="66">new_features1 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">waist =</span> <span class="dv">90</span>, <span class="dt">smoke =</span> <span class="dv">0</span>, <span class="dt">hdl =</span> <span class="dv">50</span>)</a>
<a class="sourceLine" id="cb4-67" data-line-number="67"><span class="kw">Psi1</span>(<span class="dt">new_features =</span> new_features1, <span class="dt">model =</span> model1)</a>
<a class="sourceLine" id="cb4-68" data-line-number="68"><span class="co">#&gt; [1] 0.03040785</span></a>
<a class="sourceLine" id="cb4-69" data-line-number="69">new_features2 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">waist =</span> <span class="dv">100</span>, <span class="dt">smoke =</span> <span class="dv">0</span>, <span class="dt">hdl =</span> <span class="dv">40</span>)</a>
<a class="sourceLine" id="cb4-70" data-line-number="70"><span class="kw">Psi1</span>(<span class="dt">new_features =</span> new_features2, <span class="dt">model =</span> model1)</a>
<a class="sourceLine" id="cb4-71" data-line-number="71"><span class="co">#&gt; [1] 0.0224266</span></a>
<a class="sourceLine" id="cb4-72" data-line-number="72"><span class="co"># also works with multiple rows</span></a>
<a class="sourceLine" id="cb4-73" data-line-number="73">new_features3 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">waist =</span> <span class="kw">c</span>(<span class="dv">100</span>,<span class="dv">110</span>), <span class="dt">smoke =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">hdl =</span> <span class="kw">c</span>(<span class="dv">40</span>,<span class="dv">60</span>))</a>
<a class="sourceLine" id="cb4-74" data-line-number="74"><span class="kw">Psi1</span>(<span class="dt">new_features =</span> new_features3, <span class="dt">model =</span> model1)</a>
<a class="sourceLine" id="cb4-75" data-line-number="75"><span class="co">#&gt; [1] 0.0224266 0.0390102</span></a>
<a class="sourceLine" id="cb4-76" data-line-number="76"></a>
<a class="sourceLine" id="cb4-77" data-line-number="77"><span class="co"># the mi ~ . formula fits a main terms logistic regression model</span></a>
<a class="sourceLine" id="cb4-78" data-line-number="78">model2 &lt;-<span class="st"> </span><span class="kw">glm</span>(mi <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> full_data, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb4-79" data-line-number="79"></a>
<a class="sourceLine" id="cb4-80" data-line-number="80"><span class="co">#================================================</span></a>
<a class="sourceLine" id="cb4-81" data-line-number="81"><span class="co"># Exercise 1:</span></a>
<a class="sourceLine" id="cb4-82" data-line-number="82"><span class="co">#================================================</span></a>
<a class="sourceLine" id="cb4-83" data-line-number="83"><span class="co"># a. Write a function like Psi1 that predicts for </span></a>
<a class="sourceLine" id="cb4-84" data-line-number="84"><span class="co"># new data based on model2.</span></a>
<a class="sourceLine" id="cb4-85" data-line-number="85"><span class="co"># Solution: Simplest way is to just call Psi1 with</span></a>
<a class="sourceLine" id="cb4-86" data-line-number="86"><span class="co"># model = model2!</span></a>
<a class="sourceLine" id="cb4-87" data-line-number="87">Psi2 &lt;-<span class="st"> </span>Psi1</a>
<a class="sourceLine" id="cb4-88" data-line-number="88"></a>
<a class="sourceLine" id="cb4-89" data-line-number="89"><span class="co">#</span></a>
<a class="sourceLine" id="cb4-90" data-line-number="90"><span class="co"># b. Use the function to predict on these the new</span></a>
<a class="sourceLine" id="cb4-91" data-line-number="91"><span class="co"># features defined below in predict_me </span></a>
<a class="sourceLine" id="cb4-92" data-line-number="92">predict_me &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">t</span>(<span class="kw">colMeans</span>(full_data[,<span class="dv">1</span><span class="op">:</span>(<span class="kw">ncol</span>(full_data)<span class="op">-</span><span class="dv">1</span>)])))</a>
<a class="sourceLine" id="cb4-93" data-line-number="93"><span class="co"># Solution: Call Psi2 with new_features = predict_me, model = model2</span></a>
<a class="sourceLine" id="cb4-94" data-line-number="94"><span class="kw">Psi2</span>(<span class="dt">new_features =</span> predict_me, <span class="dt">model =</span> model2)</a>
<a class="sourceLine" id="cb4-95" data-line-number="95"><span class="co">#&gt; [1] 0.009879685</span></a>
<a class="sourceLine" id="cb4-96" data-line-number="96"><span class="co">#</span></a>
<a class="sourceLine" id="cb4-97" data-line-number="97"><span class="co"># c (Bonus!). What values did I put in predict_me?</span></a>
<a class="sourceLine" id="cb4-98" data-line-number="98"><span class="co"># Solution: It's the mean values for each feature of the data. </span></a></code></pre></div>
<p>Now, we can compute the mean squared-error for the two logistic regressions using the full_data.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="co"># use Psi1 to obtain predictions on the full data set</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2">Psi1_allW &lt;-<span class="st"> </span><span class="kw">Psi1</span>(<span class="dt">new_features =</span> full_data, <span class="dt">model =</span> model1)</a>
<a class="sourceLine" id="cb5-3" data-line-number="3"><span class="co"># just for fun, check out some features</span></a>
<a class="sourceLine" id="cb5-4" data-line-number="4"><span class="kw">summary</span>(Psi1_allW)</a>
<a class="sourceLine" id="cb5-5" data-line-number="5"><span class="co">#&gt;     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. </span></a>
<a class="sourceLine" id="cb5-6" data-line-number="6"><span class="co">#&gt; 0.006186 0.020539 0.027634 0.031373 0.037474 0.169445</span></a>
<a class="sourceLine" id="cb5-7" data-line-number="7"><span class="kw">hist</span>(Psi1_allW)</a></code></pre></div>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAqAAAAHgCAYAAAB6jN80AAAEGWlDQ1BrQ0dDb2xvclNwYWNlR2VuZXJpY1JHQgAAOI2NVV1oHFUUPrtzZyMkzlNsNIV0qD8NJQ2TVjShtLp/3d02bpZJNtoi6GT27s6Yyc44M7v9oU9FUHwx6psUxL+3gCAo9Q/bPrQvlQol2tQgKD60+INQ6Ium65k7M5lpurHeZe58853vnnvuuWfvBei5qliWkRQBFpquLRcy4nOHj4g9K5CEh6AXBqFXUR0rXalMAjZPC3e1W99Dwntf2dXd/p+tt0YdFSBxH2Kz5qgLiI8B8KdVy3YBevqRHz/qWh72Yui3MUDEL3q44WPXw3M+fo1pZuQs4tOIBVVTaoiXEI/MxfhGDPsxsNZfoE1q66ro5aJim3XdoLFw72H+n23BaIXzbcOnz5mfPoTvYVz7KzUl5+FRxEuqkp9G/Ajia219thzg25abkRE/BpDc3pqvphHvRFys2weqvp+krbWKIX7nhDbzLOItiM8358pTwdirqpPFnMF2xLc1WvLyOwTAibpbmvHHcvttU57y5+XqNZrLe3lE/Pq8eUj2fXKfOe3pfOjzhJYtB/yll5SDFcSDiH+hRkH25+L+sdxKEAMZahrlSX8ukqMOWy/jXW2m6M9LDBc31B9LFuv6gVKg/0Szi3KAr1kGq1GMjU/aLbnq6/lRxc4XfJ98hTargX++DbMJBSiYMIe9Ck1YAxFkKEAG3xbYaKmDDgYyFK0UGYpfoWYXG+fAPPI6tJnNwb7ClP7IyF+D+bjOtCpkhz6CFrIa/I6sFtNl8auFXGMTP34sNwI/JhkgEtmDz14ySfaRcTIBInmKPE32kxyyE2Tv+thKbEVePDfW/byMM1Kmm0XdObS7oGD/MypMXFPXrCwOtoYjyyn7BV29/MZfsVzpLDdRtuIZnbpXzvlf+ev8MvYr/Gqk4H/kV/G3csdazLuyTMPsbFhzd1UabQbjFvDRmcWJxR3zcfHkVw9GfpbJmeev9F08WW8uDkaslwX6avlWGU6NRKz0g/SHtCy9J30o/ca9zX3Kfc19zn3BXQKRO8ud477hLnAfc1/G9mrzGlrfexZ5GLdn6ZZrrEohI2wVHhZywjbhUWEy8icMCGNCUdiBlq3r+xafL549HQ5jH+an+1y+LlYBifuxAvRN/lVVVOlwlCkdVm9NOL5BE4wkQ2SMlDZU97hX86EilU/lUmkQUztTE6mx1EEPh7OmdqBtAvv8HdWpbrJS6tJj3n0CWdM6busNzRV3S9KTYhqvNiqWmuroiKgYhshMjmhTh9ptWhsF7970j/SbMrsPE1suR5z7DMC+P/Hs+y7ijrQAlhyAgccjbhjPygfeBTjzhNqy28EdkUh8C+DU9+z2v/oyeH791OncxHOs5y2AtTc7nb/f73TWPkD/qwBnjX8BoJ98VQNcC+8AAEAASURBVHgB7d0JmBTF2cDxd5cFFLnkUgEVOYwHAiIiEhAR1IC3gAegrBpU1BiiKH6ExCAeMURBVMQjHhiCfgIaFUQEBBVE5BbBgMghCIggIHLDfP3Wl25nd2d3emZneqZm/v0868x0V1dV/6od3qnuqs4JOYuwIIAAAggggAACCCAQkEBuQOVQDAIIIIAAAggggAACRoAAlBMBAQQQQAABBBBAIFABAtBAuSkMAQQQQAABBBBAgACUcwABBBBAAAEEEEAgUAEC0EC5KQwBBBBAAAEEEECAAJRzAAEEEEAAAQQQQCBQAQLQQLkpDAEEEEAAAQQQQIAAlHMAAQQQQAABBBBAIFABAtBAuSkMAQQQQAABBBBAgACUcwABBBBAAAEEEEAgUAEC0EC5KQwBBBBAAAEEEECAAJRzAAEEEEAAAQQQQCBQAQLQQLkpDAEEEEAAAQQQQIAAlHMAAQQQQAABBBBAIFABAtBAuSkMAQQQQAABBBBAgACUcwABBBBAAAEEEEAgUAEC0EC5KQwBBBBAAAEEEECAAJRzAAEEEEAAAQQQQCBQAQLQQLkpDAEEEEAAAQQQQIAAlHMAAQQQQAABBBBAIFABAtBAuSkMAQQQQAABBBBAgACUcwABBBBAAAEEEEAgUAEC0EC5KQwBBBBAAAEEEECAAJRzAAEEEEAAAQQQQCBQAQLQQLkpDAEEEEAAAQQQQIAAlHMAAQQQQAABBBBAIFABAtBAuSkMAQQQQAABBBBAgACUcwABBBBAAAEEEEAgUAEC0EC5KQwBBBBAAAEEEECAAJRzAAEEEEAAAQQQQCBQAQLQQLkpDAEEEEAAAQQQQIAAlHMAAQQQQAABBBBAIFABAtBAuSkMgeAFfvzxRznvvPPM3/333x+xAtdee63ZftVVV3nb//a3v3n7HTp0yFsf65tVq1bJ9u3bY92N9GEC6j9gwABp2rSpVK9eXc466yyZMmVKWIpf3j7++ONeu7ntfsEFF8jFF18sN954o0yYMOGXxDG+27Rpk5f3Sy+9FHHv/fv3yxVXXCEtWrSQoUOHRkyT6JWRztXC6z788EOv7q+++mqBKvzwww/eNjV77733CmyfN2+et7244y6wAx8QQCCqQF7UFCRAAAGrBfbt2yf6j68uVatWjXgss2bNkrVr10qdOnW87cuWLfP2C4VC3nq/b37++Wd55JFH5LHHHpMvvvhCqlSp4ndX0hUSUEf9c5c5c+bIYYcd5n4s8PrVV1957VZgw38/aAB1ww03yNNPPy2HH354pCTFrtuzZ4+X969//euI6e655x556623zLZzzjknYppEr4x0rhZed/zxx3t11/8PrrvuOq8aU6dO9bbpyoYNG0qnTp0ibr/rrru89bxBAIH4BQhA47djTwQyWuD000+XrVu3mmPMycmJ+Vj//ve/y0MPPRTzfuxQVGD27NlmZV5ensydO9f8kKhdu3bRhIXWXHPNNVKtWjXRXsnVq1fLBx98YFJoEKoBVrdu3QrtUfLHChUqyKWXXmoSnXzyyQUS6w8d/bHxxBNPFFifLh/q168vavbdd9/JZ599VqBahXuTp0+fXmD7p59+aj7n5uZKmzZtCmzjAwIIxCdAABqfG3shkPECd955p+hfcYteVt+4caMceeSRUqNGDdF/nONZDh48aHpfjzvuOClTpkyJWRw4cEDWrVsn2pvlNyjWemrdKlWqVCDvn376STZs2CBly5aVo48+2ldvoJZdq1YtKVeunJeX9g5/++23pvc4Wv29ncLe+Dn+9evXmz1OPPFEcxk+bPcS3w4cOFBOPfVUL83o0aOlZ8+e5vO7775bJABVXy1L66QmGnCGLzVr1pR///vf4avMew2QtUfx66+/LrKttCu0Lnrpf8eOHeZcO+qoo+LOsm3btvL666+bIFR7/PWc08UNQPVc0GB9xYoVxsG9IuD+ADjttNOKvYoQd6XYEYEsFYjvX4wsxeKwEcgmgVtvvVUqVqxo/jQIcJfXXntNGjRoYP4hPumkk0QDAu1ZGj58uJtEunTpUqD3s0mTJnLMMcd42/XNpEmTTC+cBrDaO3XEEUfI+eefL8uXLy+QTj/s3r1b+vTpY4LIE044wdwHqZek9X5Ht47uTpdccolZd+WVV8qQIUNMWr1v8uGHHzZJ9BK19mJVrlxZfvWrX5my9ZJsfn6+6CVmd2nVqpXJ5/bbbzdBS926deXYY481txLccsstovdljhgxwgSkGhBrT+Mf/vAHd/eor36OXy8N6/EtWrTI5Kd118/t2rWLmn+kBF27dvWC/JkzZ3pJNMC7/vrrTRBer149075ajraHBtfuou9d78GDB7urReupwafu+/zzz3vrS/tGy9AfNxoIao+rBsXa/tOmTYsraw1A3cUNKleuXGl6h3X9b3/7W3ezuL2ga9asMT+0dENQtxR4leANApks4Px6Z0EAgQwWcHop9QZO89eyZcvQ//7v/xb5c/6RN9udf+g9CScg8/ZzesbMeqenKOT0PJr1Tm9YyLkPMOQEb+azrncCA5Ouc+fO3r5u2U7A5+U9ceLEkNOLWCSNpnXuSwx99NFHXlp94wyg8dI6vZkhJwgyn7W+bv7uDh07djTrtH5uXTWN0+MXcgLpkBq4+ziBc0jzcz87QZibTcgJms16J+gxr06AGSpfvryXtnHjxua9e/xuHk8++aSXR3Fv/B7/+++/75Xn5q+vZ555ZnFZh3r37u3ts2TJkgLpnN5Lb9tFF13kbXMCK7PeucQfcnr5zJ9r1759+5ATbJu0zmV8b3+nd9Xb3/khEBo0aFDI+aEQcgb0eGmcgNxLE+ubd955x8vH6YkNqb9r4PRUhpxg3Msy0rkaaZ0TyHt5uHUbOXKkt06Pz/lBZD47wajJ3/nB5W1/4403vDJ5gwACpROQ0u3O3gggkO4C4QGo+w94ca/RAtCbb77Z/GOsgZsblDi9hqFzzz035NxTGHrqqacMh3MZN/S73/3O+4fbufcw5PQ0mW3Opc+QM4DGbHN6FEPO/Yghpwcu9Oijj3qBZaNGjUK7du0y6TWodeurAa8GHs7l2JAGQO56fXUXNwDVda1btw5Nnjw55IyIDjmXVkMzZswIOT1pIQ1g3GDZuUQfci7FevVx83EDUM3nL3/5iwlend6wAkGoM+AmpMG5c19mSIM3Tev0/rpZRHyN5fg1oNP0p5xyisnb6XE2n7VNi1vCA1BtL2f0fOjuu+8OOTMcmOPWOuqfM0LdZOHcE2k+67pnn33Wy/Zf//pXyLkPOKSB3DfffGPWFxeAejs5bxIVgDq3Cpig0xnBH3LuLzXnm3N/qVfXf/zjH16xkYLNSOv0B4j7g+Hss882+zu9wiZPpzfcfHZ6zs1nZyCS+fz73//eK1PPUxYEEEiMwC/f2onJj1wQQCDNBAoHoNrjV/jPDUqiBaAacLlpzzjjDNPr9cknn5ggrPBha9DmpnXuqfM2v/jii956NwhyN2oPpLuPc4narA4PNMeMGeMmNUGJ2xOq+7hLeAD6+eefu6sLvGpAo8vevXtDWv/mzZubcp37RL10bgCq6zRwcRcNYLU87SHU4NtdNGjW9epS0hLr8WtezZo1M3lr72S0JTwAdS0Lv1522WXeMWkw79y76h2/tsErr7wScu6PLVJUkAGoW7jbVvqjxhnYZuqpx+MMeHKTmCDZPUa3tz5SAKo7aM+vptXebA3w3Z5V51YLk98zzzzjleHc8xtyprwyn90A1SuUNwggUCoB7gF1volYEMgWAZ2fUe/nLPznDsaI5uD0qIkORNFF50bUeUX1fkodmOP0eMrmzZujZeHdW6cJnUCoQPrwzzp1ky56j567OMGl+9YMHnIuD3ufC7/REeNO4FZ4tRlcoveO6n2Ueh+o1n/+/PkmnfNtWiS93t/qBOzeenfqIj1mJ4jx1us9rLo4Qa23LtIb995C3RZ+vIU/u8cfKQ+/6/QeV5071AmKzXFeffXV4lxGlvHjx3vHpIOztO100YFZo0aNkl69epn7enW+0bfffttvcQlP51yGN/f+6vnp/DiSfv36eWVEaitvYwlv3PtAtZ2cHwPeTA8dOnQwe4WfY3qf7oIFC8z6eO+7LaEqbEIgqwUYBZ/Vzc/BIxCbgM6PqNMAOZfaTSDj9IiZDHS6Jl338ccfm+0a/BW3uAGcbi88atzpVSyyW/i6wvlu2bKlSHp3hQ6WKZzeuSdSNMDQQTc6kl3f60Ab555MM0VReKDp5lN4vk23PjroKJ4l1uOPpwx3n3HjxhUYBe+uL/yqAbnO6/ncc8+Jc/+tCaI1wNP5RjVI1qBVBzAFuejgLx3kpYsOUnMuhYvOAqDrdYnUVmZDlP+4Aagmc277MKn1PHR/zOg5roPKdPDRsGHDRKeX0oUBSIaB/yCQMIFfftYnLEsyQgCBTBbQnj4dIa9POHLuDRRnEIcZTa7HrKO1dQLwwkt4b5Vz7523ufCUPuG9bTrljS4afLiLc7ncfSv69Bp3JLO3MuxN+FRJ7mqdo1KDT+25XLp0qXkqUN++fb3phmIJatxA1M3b72usx+8339Kk0x5x9dYJ5Ldt22ZGteusA+6iMx8EuehUUG7wqSPTtRdcg0Hnnl6vGrG0lbeT80af0OT+qNCpmHTRHmKdCcFd3F5Q/cHiLgSgrgSvCCRGgAA0MY7kgkBWCDj3SpppcfRV59DUKXF0SiLnvjrv+HVaJV10TkV30fkznXtRzUe95O0GDxpUaO+aXvrVJ/PopWFdtBfK/QdfHxPqBnvO/Y3ijDI3gZI+WlKnQipuKdy7quncKZ50m1tPDW7cJ0Xp05uSvcR6/Mmuj/aSaq+sTqnljGQ3wZk+jlKnQHKD+PDgLNn10fzddtL3OoWWu7zwwgvuW9m5c6f3PpY3ekx6a0H44gac7rrCn3V6KZ2CiwUBBBInQACaOEtyQiDjBfQxhBoM6uTu+o+yBonaQ6mXcHW5/PLLRefL1EXnCnUXvb9O7+HTSb51vTPIxVx+1x5Uff68BoN33HGHmWxceyedEc7exPDOCHBvfk0NYnVyfL2XVXunCj+Nxy2vuFdntL7Z5IywN/tqoKF5aACsi9ZPewCTucR6/Mmsi+atPx5cR31+utuuGnDp5WcN2PTe3yAXvXfXfXSr1knvv9R66Y8U98eIn/uNi6tz+GV4TVM44NTz1S1Ht7s/hvQ9CwIIJEaAADQxjuSCQFYI6FN09EkyGrBocKL3fOqleL2kqZOw6wAWd9EJ4d1/uPUSvF66d+/Z1HzGjh1rLqlqgKOXgLVX0h0Q5O7n5qWPeNTeUmf+S3OpVO/b1MnI9XKqLm5PnZu+uFdnSiLp3r272fz999/LdOeRixoAu88u1w16P2iyl1iPP5n10bZTS30+vAb/eu+jtqtO/q+BoHo4c6cmswpF8tYfJM58tWYglJ47el+qniN6y4b2zupSmnYKD0C19zf80r7mrQPtdPCWuxQ+H931vCKAQPwCOc7/3EWHfcafH3sigECWCGgAp8/V1suz2utZeMCPy6D32Wmwqj1/4b1K7nZ9+pA+RUe3hw/Qcbfr/hoU6cAQ7UUNv7SuQa4+UlJHpOu9nX4XHTSltwU4UydFLNNvPolIF+34E1GG3zy0LuqiPcQ68jzoS++F66mPBtVecg2Mtf1ZEEAgcwQIQDOnLTkSBDJSQHvn3Cly9N5Q5+lAJuDUAUndunUz9wLq/aA6ZQ8LAggggIAdAgSgdrQTtUQgawW0V04HjSxevDiigfaIOhPOi/PUnojbWZkeAjfddJOZdcBPbfQ2D+bd9CNFGgTsFSh+sj57j4maI4BABgnoPYrOozxlyJAh8uabb5rL/jqJuF6O1/v0dDJ8gs/0b3Adze53JLk7TVL6HxU1RACBeAXoAY1Xjv0QQCBlAu6gpZRVgIIRQAABBEolQABaKj52RgABBBBAAAEEEIhVgGmYYhUjPQIIIIAAAggggECpBAhAS8XHzggggAACCCCAAAKxChCAxipGegQQQAABBBBAAIFSCRCAloqPnRFAAAEEEEAAAQRiFSAAjVWM9AgggAACCCCAAAKlEiAALRUfOyOAAAIIIIAAAgjEKkAAGqsY6RFAAAEEEEAAAQRKJUAAWio+dkYAAQQQQAABBBCIVYAANFYx0iOAAAIIIIAAAgiUSoAAtFR87IwAAggggAACCCAQqwABaKxipEcAAQQQQAABBBAolQABaKn42BkBBBBAAAEEEEAgVgEC0FjFSI8AAggggAACCCBQKgEC0FLxsTMCCCCAAAIIIIBArAIEoLGKkR4BBBBAAAEEEECgVAIEoKXiY2cEEEAAAQQQQACBWAUIQGMVIz0CCCCAAAIIIIBAqQQIQEvFx84IIIAAAggggAACsQoQgMYqRnoEEEAAAQQQQACBUgkQgJaKj50RQAABBBBAAAEEYhUgAI1VjPQIIIAAAggggAACpRIgAC0VHzsjgAACCCCAAAIIxCpAABqrGOkRQAABBBBAAAEESiVAAFoqPnZGAAEEEEAAAQQQiFWAADRWMdIjgAACCCCAAAIIlEqAALRUfOyMAAIIIIAAAgggEKsAAWisYqRHAAEEEEAAAQQQKJUAAWip+NgZAQQQQAABBBBAIFYBAtBYxUiPAAIIIIAAAgggUCoBAtBS8bEzAggggAACCCCAQKwCBKCxipEeAQQQQAABBBBAoFQCBKCl4mNnBBBAAAEEEEAAgVgFrA9AQ6GQbN68WbZu3RrrsZMeAQQQQAABBBBAIAUCVgag69evl/79+0u9evWkXLlyUqtWLalevbpUqVJFmjZtKnfffbfs3LkzBZwUiQACCCCAAAIIIBBNIMfpQQxFS5RO29esWSNt2rSRnJwc6datm9SvX1+qVatmPmsv6KpVq2Ts2LGihzV16lRp0KBBOlWfuiCAAAIIIIAAAlkvYF0Aescdd8iiRYtkypQpUr58+YgNuH//funUqZP8+te/lkGDBkVMw0oEEEAAAQQQQACB1AjkpabY+EtduHCh9OrVq9jgU3MuW7as5Ofny5NPPkkAGj910vd87bXXZO7cuUkvp3ABZ555plx99dWFV/MZAQQQQAABBAISsC4Abd26tcycOVN69+5dItG0adOkTp06JaZhY+oEtm3bJtdee60MGTIk8Epcc801poe8cuXKgZdNgQgggAACCCAgYt0leO0B1SC0Xbt20qNHD3OPpw5Ays3NNSPhV69eLaNHj5aJEyeay/SajiX9BDQA1UFk+hr0ooHnunXrhAA0aHnKQwABBBBA4P8FrOsBbdasmSxevFhuueUWcyn+0KFDRdqyY8eOMnnyZBOkFtnICgQQQAABBBBAAIGUClgXgKpWw4YNzQj3ffv2ydq1a0V7PXXgUe3ataVu3bpmSqaUqlI4AggggAACCCCAQLECVgag7tHoHKA6zZLO/1mmTBkzHZO7jVcEEEAAAQQQQACB9BRgIvr0bBdqhQACCCCAAAIIZKyAdT2gfieiHzduHBPRZ+xpy4EhgAACCCCAgM0C1o2CZyJ6m0+3X+rOKPhfLHiHAAIIIIBAtglYdwlep2G6/vrrfU1EP2nSpGxrT44XAQQQQAABBBBIewHrAlB3IvposkxEH02I7QgggAACCCCAQGoErLsHtHv37mYi+k2bNvmaiD41rJSKAAIIIIAAAgggUJyAdQEoE9EX15SsRwABBBBAAAEE7BCwLgBV1mRORP/hhx/KU089FbX1lixZYtKdf/75UdOSAAEEEEAAAQQQQOAXASsDULf6OhG9BqP6t2vXLlm2bJl5HnzVqlXNxPRuulhe69evby7tR9vnvvvuk0iPAY22H9sRQAABBBBAAIFsF7AuAH3sscdEp/AZPHiw13aPPPKIDBo0SPbu3WvW6dORRowYIRdccIGXxu+b448/XvQv2jJkyBDzBKZo6diOAAIIIIAAAgggUFDAugB08eLFsnnzZu8oXnrpJRkwYIB06NBBdIDSjh07ZMyYMXL55ZfLrFmzRO8ZZUEAAQQQQAABBBBIHwHrAtDCdM8//7y0atVKpkyZ4m3q27evNG/eXIYNGyYvv/yyt543CCCAAAIIIIAAAqkXsG4e0MJkejm+Z8+ehVdL7969ZdGiRUXWswIBBBBAAAEEEEAgtQJWBqC7d++W/fv3G7nLLrtM1q9fX0Rx3rx5UqNGjSLrWYEAAggggAACCCCQWgHrAtCcnByZPn26VKpUSVq2bCkaaA4fPlwWLFhgJNetWyd9+vSRV199Va666qrU6lI6AggggAACCCCAQBEB6wLQ5557zgSbI0eOlLPPPtuMfM/Ly5OVK1eag5swYYLoNr0Ef9NNNxU5YFYggAACCCCAAAIIpFbAukFIOvenjmzXv/z8fE/vwIED5v0ll1wiF110kdStW9fbxhsEEEAAAQQQQACB9BGwLgAtjk57QXWpXbt2cUlYjwACCCCAAAIIIJAGAtZdgk8DM6qAAAIIIIAAAgggUAoBAtBS4LErAggggAACCCCAQOwC1gWgLVq0kAoVKvj6izQ/aOxE7IEAAggggAACCCCQSAHr7gEdOnSodOnSRfbt2ycDBw6U3NziY+gTTzwxkVbkhQACCCCAAAIIIJAAAesC0LZt28onn3xiRsEfPHhQ+vXrlwAGskAAAQQQQAABBBAISqD47sOgahBHOdqzOXjwYHnwwQdly5YtceTALggggAACCCCAAAKpErCuB9SF6tu3rzRv3ly0F5QFAQQQQAABBBBAwB4BawPQMmXKSPv27e2RpqYIIIAAAggggAACRsDKS/C0HQIIIIAAAggggIC9AgSg9rYdNUcAAQQQQAABBKwUIAC1stmoNAIIIIAAAgggYK8AAai9bUfNEUAAAQQQQAABKwUIQK1sNiqNAAIIIIAAAgjYK0AAam/bUXMEEEAAAQQQQMBKAQJQK5uNSiOAAAIIIIAAAvYKEIDa23bUHAEEEEAAAQQQsFKAANTKZqPSCCCAAAIIIICAvQIEoPa2HTVHAAEEEEAAAQSsFCAAtbLZqDQCCCCAAAIIIGCvAAGovW1HzRFAAAEEEEAAASsFCECtbDYqjQACCCCAAAII2CtAAGpv21FzBBBAAAEEEEDASgECUCubjUojgAACCCCAAAL2ChCA2tt21BwBBBBAAAEEELBSgADUymaj0ggggAACCCCAgL0CBKD2th01RwABBBBAAAEErBQgALWy2ag0AggggAACCCBgrwABqL1tR80RQAABBBBAAAErBQhArWw2Ko0AAggggAACCNgrQABqb9tRcwQQQAABBBBAwEoBAlArm41KI4AAAggggAAC9goQgNrbdtQcAQQQQAABBBCwUoAA1Mpmo9IIIIAAAggggIC9AgSg9rYdNUcAAQQQQAABBKwUIAC1stmoNAIIIIAAAgggYK8AAai9bUfNEUAAAQQQQAABKwUIQK1sNiqNAAIIIIAAAgjYK0AAam/bUXMEEEAAAQQQQMBKAQJQK5uNSiOAAAIIIIAAAvYKEIDa23bUHAEEEEAAAQQQsFKAANTKZqPSCCCAAAIIIICAvQIEoPa2HTVHAAEEEEAAAQSsFCAAtbLZqDQCCCCAAAIIIGCvAAGovW1HzRFAAAEEEEAAASsFCECtbDYqjQACCCCAAAII2CtAAGpv21FzBBBAAAEEEEDASgECUCubjUojgAACCCCAAAL2ChCA2tt21BwBBBBAAAEEELBSgADUymaj0ggggAACCCCAgL0CBKD2th01RwABBBBAAAEErBQgALWy2ag0AggggAACCCBgrwABqL1tR80RQAABBBBAAAErBQhArWw2Ko0AAggggAACCNgrQABqb9tRcwQQQAABBBBAwEoBAlArm41KI4AAAggggAAC9goQgNrbdtQcAQQQQAABBBCwUoAA1Mpmo9IIIIAAAggggIC9AgSg9rYdNUcAAQQQQAABBKwUIAC1stmoNAIIIIAAAgggYK8AAai9bUfNEUAAAQQQQAABKwUIQK1sNiqNAAIIIIAAAgjYK0AAam/bUXMEEEAAAQQQQMBKAesD0FAoJJs3b5atW7da2QBUGgEEEEAAAQQQyDYBKwPQ9evXS//+/aVevXpSrlw5qVWrllSvXl2qVKkiTZs2lbvvvlt27tyZbW3J8SKAAAIIIIAAAlYI5FlRy7BKrlmzRtq0aSM5OTnSrVs3qV+/vlSrVs181l7QVatWydixY2XcuHEydepUadCgQdjevEUAAQQQQAABBBBItYB1AeiQIUNMz+eUKVOkfPnyEf0efvhh6dSpk4waNUoGDRoUMQ0rEUAAAQQQQAABBFIjYN0l+IULF8r1119fbPCpjGXLlpX8/HyZNGlSalQpFQEEEEAAAQQQQKBYAesC0NatW8vMmTOLPSB3w7Rp06ROnTruR14RQAABBBBAAAEE0kTAukvw3bt3Fw1CN23aJD169DD3eOoApNzcXDMSfvXq1TJ69GiZOHGi6GV6FgQQQAABBBBAAIH0ErAuAG3WrJksXrxYbrnlFunVq5ccOnSoiGjHjh1l8uTJ0q5duyLbWIEAAggggAACCCCQWgHrAlDlatiwoRnhvm/fPlm7dq1or+f+/fuldu3aUrduXTMlU2pZKR0BBBBAAAEEEECgOAErA1D3YHQOUJ1mSef/LFOmjJmOyd3GKwIIIIAAAggggEB6Clg3CEkZmYg+PU8maoUAAggggAACCPgRsK4HlIno/TQraRBAAAEEEEAAgfQVsC4AZSL69D2ZqBkCCCCAAAIIIOBHwLpL8ExE76dZSYMAAggggAACCKSvgHUBKBPRp+/JRM0QQAABBBBAAAE/AtZdgmciej/NGlsafWTpN998E9tOpUy9a9cuOXjwYClzYXcEEEAAAQQQsFHAugA02RPR65yic+bMidqWW7Zske3bt0dNl+4Jli1bJp06dZI+ffoEWtUffvhBdu7cGWiZFIYAAggggAAC6SFgXQCqbMmciF4D0HHjxkVtHQ1Ad+zYETVduifQCfxPO+00GTFiRKBV1dkM3njjjUDLpDAEEEAAAQQQSA+BqAHoxx9/LOPHj5f8/Hxp2rRpetT6v7VIxkT05557ruhftOXss8+WY489NloytqehwIEDB+R//ud/pHz58oHW7sQTT5Sbb75ZcnOtu/U6UCcKQwABBBDIfIGoAWjVqlXl/fffl2HDhpkAVAPRHj16SM2aNVOmoxPRDx8+XF5//XUzKb0GFLpUrlxZ6tWrJ/os+EGDBknFihVTVkcKTl+B3bt3y1FHHRX4+aHnZJs2baRx48bpi0PNEEAAAQQQCEAgagCql2eXLl0qc+fOlVGjRslDDz0k9957r3Tu3Fl69eolF198sZQtWzaAqv5/EUxEHxh1Rhd04403St26dQM9xhdffDHQ8igMAQQQQACBdBWIGoC6FW/RooXo32OPPWZ6RN98801zWV4vg2uP6K233ionnXSSmzxpr0xEnzRaMkYAAQQQQAABBAIRiPlmtLVr18qCBQtk/vz5ZhBO/fr15bPPPpNTTjlF/vSnPyW90kxEn3RiCkAAAQQQQAABBJIq4CsA1Slznn76adGBNzoCXd/rfZZLliwxweenn35q7sd88MEHTWCazBozEX0ydckbAQQQQAABBBBIvkDUS/AfffSRCTa1Knq/59tvv23mjczLK7ir3hOqy6ZNm8xrsv7DRPTJkiVfBBBAAAEEEEAgGIGCUWSEMitUqCB/+9vfoo581yltNm7caEYXR8gmYauSPRF9wipKRggggAACCCCAAAIRBaIGoDrw6IwzzpAxY8ZIq1atRO/51OW2226TO++80xt4pD2iOrVNEEsyJ6IPov6UgQACCCCAAAIIZLNA1ABUcS688EKZPn26+dMANBQKyaJFi8x8hn//+9+lb9++KTHUEfgajOofCwIIIIAAAggggIAdAlEHIa1YsUJmzJhhBhzpACBdcnJyZObMmfL444/LH//4R9m3b58dR0stEUAAAQQQQAABBFIuEDUAnTp1qpn/Ux8jWHjp2bOn7Nq1S3RqpqAWvSVA70v186f1Y0EAAQQQQAABBBBIL4Gol+B1cvk5c+bIt99+W+TZ5++++66UKVNG6tSpE9hRDR06VLp06WJ6XQcOHFjic7UjBc2BVZSCEEAAAQQQQAABBCIKRA1AdeDR0UcfLdddd538+c9/Fg3q9uzZI59//rloANitWzc5/PDDI2aejJVt27aVTz75RHQ0/MGDB6Vfv37JKIY8EUAAAQQQQAABBJIkEPUS/GGHHSazZs2SrVu3SocOHUwvaKNGjUTn4zzrrLNkxIgRSapa8dlqEDx48GDRie+3bNlSfEK2IIAAAggggAACCKSdQNQeUK3xscceK4sXL5Z169aJPgpTL7vrpfkTTjghZQekI++bN29uekFTVgkKRgABBBBAAAEEEIhZwFcA6uZat25d0b90WDQIbt++fTpUhToggAACCCCAAAIIxCDgKwDVS/DDhg0zPaCRplyaO3duDEWSFAEEEEAAAQQQQCCbBaIGoDr6/Te/+Y1UqVJFzj77bKlcuXI2e3HsCCCAAAIIIIAAAqUUiBqA6jygubm55h7QI488spTFsTsCCCCAAAIIIIBAtgtEHQWvj93U+z4JPrP9VOH4EUAAAQQQQACBxAhEDUB1oM8333wjX375ZWJKJBcEEEAAAQQQQACBrBaIegle5wHVOT/btWsnV199tekN1RHo4cu9994b/pH3CCCAAAIIIIAAAggUKxA1AF20aJG88cYbJoN//vOfETMiAI3IwkoEEEAAAQQQQACBCAJRA9ALL7xQtm/fHmFXViGAAAIIIIAAAgggELtA1HtAw7P8+eefzWj4nTt3yt69e8M38R4BBBBAAAEEEEAAAV8CvgJQfQRn165dpWLFitK0aVNZunSp9O/fX/r16ye7du3yVRCJEEAAAQQQQAABBBBQgagBqD756NJLL5Xly5fL0KFDpUKFCkaubdu28sILL4g+k50FAQQQQAABBBBAAAG/AlHvAZ0yZYqsX7/eBKD6NKT777/f5N2lSxfzVKRevXqJzhWak5Pjt0zSIYAAAggggAACCGSxQNQe0BUrVsipp55qHsVZ2OnMM8+UDRs2yOrVqwtv4jMCCCCAAAIIIIAAAhEFogagJ5xwgsycOVM2b95cJIPXXntN8vLypE6dOkW2sQIBBBBAAAEEEEAAgUgCUS/Bn3feeWby+c6dO8tdd90lhw4dEu0Vfeedd2TkyJFmkvpy5cpFypt1CCCAAAIIIIAAAggUEYgagOrI9zfffFPy8/NNsKk59OzZ02R0+eWXyxNPPFEkU1YggAACCCCAAAIIIFCcQNQAVHds0qSJzJ07V+bNm2d6P7XHU+8LPfnkk4vLl/UIIIAAAggggAACCEQU8BWA6p65ubmig470jwUBBBBAAAEEEEAAgXgFogags2fPlvvuu6/E/KdPn17idjYigAACCCCAAAIIIOAKRA1Ay5cvL8ccc4yb3rzu2LFDvvrqK9EnJDERfQEaPiCAAAIIIIAAAghEEYgagJ5++ukyZsyYItno5PO/+93vZO3atUW2sQIBBBBAAAEEEEAAgeIEos4DWtyO+uQjfRb8G2+8ITt37iwuGesRQAABBBBAAAEEECggEHcAqrls2rRJDh48KNu3by+QKR8QQAABBBBAAAEEEChOIOoleH3M5ttvv11gfw06t27dKs8//7ycdNJJPAmpgA4fEEAAAQQQQAABBEoSiBqALl26VO65554ieRxxxBHSrFkzJqIvIsMKBBBAAAEEEEAAgZIEogag+gjOvXv3lpQH2xBAAAEEEEAAAQQQ8C1QqntAfZdCQgQQQAABBBBAAAEE/isQtQfUz0T04Zovvvii1K9fP3wV7xFAAAEEEEAAAQQQ8ASi9oAeeeSRcvjhh8tHH30kZcuWlaZNm0rNmjVl0aJFMmPGDPOITp2o3v3Ly4sa03qF8wYBBBBAAAEEEEAg+wSiRosVK1aUhQsXypQpU+S8887zhHQk/B133CFffPFFxInqvYS8QQABBBBAAAEEEEAgTCBqADp58mTRpyGFB5+6f5kyZWTgwIFSt25d2bBhQ5HHdYaVwVsEEEAAAQQQQAABBDyBqJfgK1euLHPmzIn4tKONGzeaS/DaS8qCAAIIIIAAAggggIAfgagBaMeOHWXPnj1yww03mPs+9bGb33//vYwfP166desmV111lVSqVMlPWaRBAAEEEEAAAQQQQECiXoKvUqWKzJw5Uy655BIz8Xy4mQafzz77bPgq3iOAAAIIIIAAAgggUKJA1ABU99aR7ytXrpQvv/zSDEjSpyCddtpp5jGcJebORgQQQAABBBBAAAEECgn4CkB1H52CqVGjRuaeT53nUz+zIIAAAggggAACCCAQq0DUe0A1w3Xr1knXrl1FBxtpb6g+H75///7Sr18/2bVrV6xlkh4BBBBAAAEEEEAgiwWiBqD79u2TSy+9VJYvXy5Dhw6VChUqGK62bdvKCy+8IH379s1iPg4dAQQQQAABBBBAIFaBqJfgdQL69evXmwBUByTdf//9powuXbqITtHUq1cvCYVCkpOTE2vZpEcAAQQQQAABBBDIQoGoPaArVqyQU089VTT4LLyceeaZZhL61atXF97EZwQQQAABBBBAAAEEIgpEDUBPOOEEMw3T5s2bi2Tw2muviT77vU6dOkW2sQIBBBBAAAEEEEAAgUgCUS/B6yM49XGbnTt3lrvuuksOHTok2iv6zjvvyMiRI6V79+5Srly5SHmzDgEEEEAAAQQQQACBIgJRA1Ad+f7mm29Kfn6+CTY1h549e5qMLr/8cnniiSeKZMoKBBBAAAEEEEAAAQSKE4gagG7bts1MQK9PQ1qyZInp/dQeT70v9OSTTy4uX9YjgAACCCCAAAIIIBBRIGoAOmHCBNPj+e2334oOOtI/FgQQQAABBBBAAAEE4hWIOgipRo0aJu/t27fHWwb7IYAAAggggAACCCDgCUTtAW3WrJm59/Occ86RK664Qho0aCDly5f3MtA3OjiJBQEEEEAAAQQQQAABPwJRA9AFCxbIW2+9ZfIaM2ZMxDwJQCOysBIBBBBAAAEEEEAggkDUAPQ3v/mN/PzzzxF2ZRUCCCCAAAIIIIAAArELRLwH9MCBA7Jnz57Yc2MPBBBAAAEEEEAAAQSiCEQMQHVuz/r16xfYdd26dbJs2bIC6/iAAAIIIIAAAggggECsAhED0EiZDB06VK677rpIm1iHAAIIIIAAAggggIBvAd8BqO8cSYgAAggggAACCCCAQAkCBKAl4LAJAQQQQAABBBBAIPECBKCJNyVHBBBAAAEEEEAAgRIECEBLwGETAggggAACCCCAQOIFip0HdPPmzdK4cWOvxI0bN5r5QMPXuRuXLFnivuUVAQQQQAABBBBAAIESBSIGoA0bNpSLL764wI6NGjUq8JkPCCCAAAIIIIAAAgjEIxAxAL3ssstE/1gQQAABBBBAAAEEEEi0gPX3gIZCIdHbBbZu3ZpoG/JDAAEEEEAAAQQQSIKAlQHo+vXrpX///lKvXj0pV66c1KpVS6pXry5VqlSRpk2byt133y07d+5MAhdZIoAAAggggAACCJRWIOIl+NJmmsz916xZI23atJGcnBzp1q2beWRotWrVzGftBV21apWMHTtWxo0bJ1OnTpUGDRokszrkjQACCCCAAAIIIBCjgHUB6JAhQ0zP55QpU6R8+fIRD/fhhx+WTp06yahRo2TQoEER07ASAQQQQAABBBBAIDUC1l2CX7hwoVx//fXFBp/KWLZsWcnPz5dJkyalRpVSEUAAAQQQQAABBIoVsC4Abd26tcycObPYA3I3TJs2TerUqeN+5BUBBBBAAAEEEEAgTQSsuwTfvXt30SB006ZN0qNHD3OPpw5Ays3NNSPhV69eLaNHj5aJEyeKXqZnQQABBBBAAAEEEEgvAesC0GbNmsnixYvllltukV69esmhQ4eKiHbs2FEmT54s7dq1K7KNFQgggAACCCCAAAKpFbAuAFUufVKTjnDft2+f6Kj4RYsWmUD0V7/6ldStW9dMyZRaVkpHAAEEEEAAAQQQKE7AygBU5wEdPny4vP7666LvDxw4YI6vcuXKZoS89oDq6PeKFSsWd9ysRwABBBBAAAEEEEiRgHUBKPOApuhMoVgEEEAAAQQQQCBBAtYFoMwDmqCWJxsEEEAAAQQQQCBFAtZNw5TseUBfeukl81QlfdJSSX+zZ8+WJUuWpKjZKBYBBBBAAAEEELBXwLoANNnzgN5www0SCoWi/rVq1UoaN25sb8tTcwQQQAABBBBAIEUC1l2CZx7QFJ0pFIsAAggggAACCCRIwLoAlHlAE9TyZIMAAggggAACCKRIwLoAVJ3C5wFdu3at6NOP9u/fL7Vr12Ye0BSdSBQbXeDgwYOyfPlyc3tH9NSJS1GhQgXzxLDE5UhOCCCAAAIIlE7AygDUPeRy5cqZYFQD0l27dsmyZcvM4zirVq0qZcqUcZPxikBaCKxatco8vatevXqB1kcHy82fP19OP/30QMulMAQQQAABBIoTsC4Afeyxx2Tbtm0yePBg75geeeQRM/H83r17zboGDRrIiBEj5IILLvDS8AaBdBAYNWqUXHHFFYFWpXPnzrJhwwYC0EDVKQwBBBBAoCQB6wJQfQ785s2bvWPSaZMGDBggHTp0EB2gtGPHDhkzZoxcfvnlMmvWLNF7RlkQQAABBBBAAAEE0kfAugC0MN3zzz8vOiXSlClTvE19+/aV5s2by7Bhw+Tll1/21vMGAQQQQAABBBBAIPUC1s0DWphML8f37Nmz8Grp3bu3LFq0qMh6ViCAAAIIIIAAAgikVsDKAHT37t1m1LvSXXbZZbJ+/foiivPmzZMaNWoUWc8KBBBAAAEEEEAAgdQKWBeA6uMxp0+fLpUqVZKWLVuKBprDhw+XBQsWGMl169ZJnz595NVXX5WrrroqtbqUjgACCCCAAAIIIFBEwLoA9LnnnjPB5siRI+Xss88WHfmel5cnK1euNAc3YcIE0W16Cf6mm24qcsCsQAABBBBAAAEEEEitgHWDkHTuTx3Zrn/5+fme3oEDB8z7Sy65RC666CIzIb23kTcIIIAAAggggAACaSNgXQBanJz2guqiT0NiQQABBBBAAAEEEEhfAesuwacvJTVDAAEEEEAAAQQQ8CNAAOpHiTQIIIAAAggggAACCRMgAE0YJRkhgAACCCCAAAII+BEgAPWjRBoEEEAAAQQQQACBhAkQgCaMkowQQAABBBBAAAEE/AgQgPpRIg0CCCCAAAIIIIBAwgQIQBNGSUYIIIAAAggggAACfgQIQP0okQYBBBBAAAEEEEAgYQIEoAmjJCMEEEAAAQQQQAABPwIEoH6USIMAAggggAACCCCQMAEC0IRRkhECCCCAAAIIIICAHwECUD9KpEEAAQQQQAABBBBImAABaMIoyQgBBBBAAAEEEEDAjwABqB8l0iCAAAIIIIAAAggkTIAANGGUZIQAAggggAACCCDgR4AA1I8SaRBAAAEEEEAAAQQSJkAAmjBKMkIAAQQQQAABBBDwI0AA6keJNAgggAACCCCAAAIJEyAATRglGSGAAAIIIIAAAgj4ESAA9aNEGgQQQAABBBBAAIGECRCAJoySjBBAAAEEEEAAAQT8CBCA+lEiDQIIIIAAAggggEDCBAhAE0ZJRggggAACCCCAAAJ+BAhA/SiRBgEEEEAAAQQQQCBhAgSgCaMkIwQQQAABBBBAAAE/AgSgfpRIgwACCCCAAAIIIJAwAQLQhFGSEQIIIIAAAggggIAfAQJQP0qkQQABBBBAAAEEEEiYAAFowijJCAEEEEAAAQQQQMCPQJ6fRKRBAAF7Bfbs2SOvvvqqzJ49O9CDqFSpktxzzz2BlklhCCCAAAJ2CBCA2tFO1BKBuAUWLVokbdq0kby8YP93nzFjhmgQeuutt8Zdd3ZEAAEEEMhMgWD/RcpMQ44KgbQWyM3NlebNm8uf//znQOtJ4BkoN4UhgAACVglwD6hVzUVlEUAAAQQQQAAB+wUIQO1vQ44AAQQQQAABBBCwSoAA1KrmorIIIIAAAggggID9AgSg9rchR4AAAggggAACCFglQABqVXNRWQQQQAABBBBAwH4BAlD725AjQAABBBBAAAEErBIgALWquagsAggggAACCCBgvwABqP1tyBEggAACCCCAAAJWCRCAWtVcVBYBBBBAAAEEELBfgADU/jbkCBBAAAEEEEAAAasECECtai4qiwACCCCAAAII2C9AAGp/G3IECCCAAAIIIICAVQIEoFY1F5VFAAEEEEAAAQTsFyAAtb8NOQIEEEAAAQQQQMAqAQJQq5qLyiKAAAIIIIAAAvYLEIDa34YcAQIIIIAAAgggYJUAAahVzUVlEUAAAQQQQAAB+wUIQO1vQ44AAQQQQAABBBCwSoAA1KrmorIIIIAAAggggID9AgSg9rchR4AAAggggAACCFglQABqVXNRWQQQQAABBBBAwH4BAlD725AjQAABBBBAAAEErBIgALWquagsAggggAACCCBgvwABqP1tyBEggAACCCCAAAJWCeRZVVsqiwAC1ghs2bJFHn30UXn33XcDrfPGjRtl/PjxctxxxwVaLoUhgAACCPgXIAD1b0VKBBCIQWDJkiXSpEkT6d27dwx7lT7p9OnT5ZlnnpFHHnmk9JmRAwIIIIBAUgQIQJPCSqYIIJCTkyNHHHGEXHzxxYFifPHFF7Jjx45Ay6QwBBBAAIHYBLgHNDYvUiOAAAIIIIAAAgiUUoAAtJSA7I4AAggggAACCCAQmwABaGxepEYAAQQQQAABBBAopQABaCkB2R0BBBBAAAEEEEAgNgEGIcXmRWoEELBAQAcivfTSS4HXtGvXrlKpUqXAy6VABBBAwDYBAlDbWoz6IoBAiQKzZ8+WCRMmSM2aNUtMl+iN//73v+WDDz6Qf/3rX4nOmvwQQACBjBMgAE2jJh07dqx8//33gdZo/fr1sm/fvkDLpDAEkimwZ88eadWqVeA9oKNHj5aJEycm89DIGwEEEMgYAQLQNGlK7Tnp1q2b9OnTJ9Aaff755/L1118HWiaFIYAAAggggEB2CxCApkn77927Vy666CIZMWJEoDXSXteePXsGWiaFIYAAAggggEB2CxCAZnf7c/QIIJAgAX0Gvd7/OWXKlATl6C8bvW2nX79+MmTIEH87kAoBBBBIAwEC0DRoBKqAAAL2C6xcuVKOO+44mTNnTqAHs2TJErn//vsDLZPCEEAAgdIKEICWVpD9EUAAgf8K5OTkyFFHHRWox/z580WnnWrTpk2g5epgr06dOsngwYMDLZfCEEAgMwSsD0BDoZD88MMPUqZMGalWrVpmtApHgQACCPgU0J7XgwcPyl//+lefeyQmmQag1113HQFoYjjJBYGsE7AyANWpg4YPHy6vv/666PsDBw6YhqtcubLUq1dPOnbsKIMGDZKKFStmXYNywAggkH0C+gM86B7Q//znP/Ljjz/KGWecETi43urw5ptvBl4uBSKAQOIErAtA16xZY75o9VKXTltUv3590/Opn7du3SqrVq0SHdk9btw4mTp1qjRo0CBxWuSEAAIIIGAE9MrT/v375bnnngtcpEWLFnL++ecHXu7SpUtl27ZtgXduaJlr164N/PYOBXY7eILE1n/P9UcVS2YLWBeA6kjPek4vp440LV++fMTWefjhh829SaNGjTI9oRETFbNyxowZMnLkyGK2/rJ6xYoV8u2335oJr39ZG/877a3Vp7dcc8018WcSx546glangAq6XL18p0vQ5bpEvXv3lipVqrgfA3lV54EDB5qe+0AK/G8hGijoFYNly5YFWawpT8s8dOhQoOV+8803Zm7boM+tr776SvQHctDlrlu3Tnbs2BF4uRoUadumavR9bm5uoOeVFvbdd9+ZHl/tgQ1y0d7eo48+OsgiKStggQceeED+9Kc/BVxqaovLce6hDKW2CrGVrpeZevXqJRpAlLT885//lCeffFI+++yzkpIV2aY9qH720Zv+8/PzpVGjRkXyiHfF5MmTTS9uvPvHu99hhx0mbkAYbx7x7Ee58ajFvk/ZsmVNT1Xse5ZuD+3B0HsTU7FoD0oqvtry8vJS0mOkP8b1B07QS6rKzbbvDj2Xd+3aFXTzmn+Pjj322MDL1f9/d+7cGXi5WuCGDRvkmGOOCbzszp07p6TcwA80rEDrAtB7773XPK7y5ZdfDjuMom9vvPFGc6lk/PjxRTeyBgEEEEAAAQQQQCBlAtZdgu/evbu0bt1aNm3aJD169DD3eFavXl30cozeA7p69Wpxn8kc9ITQKWtFCkYAAQQQQAABBCwSsK4HVG312eW33HKLTJ8+PeL9ZToKfsCAAdK+fXuLmoKqIoAAAggggAAC2SFgZQDqNs2+ffvMyEDt9dTRmLVr15a6deuK9oiyIIAAAggggAACCKSngNUBaHqSUisEEEAAAQQQQACBkgSCn8eipNqwDQEEEEAAAQQQQCDjBQhAM76JOUAEEEAAAQQQQCC9BAhA06s9qA0CCCCAAAIIIJDxAgSgGd/EHCACCCCAAAIIIJBeAtbNA5pefImrzcyZM0Wf3tS4cePEZUpOCDgC+tSuOnXqSLVq1fBAIGEC+vS0xYsXS8uWLROWJxkhoAL6ON0WLVrItddeC0gGCxCApknjLly4UN577z3RxxeyIJBIAT2vmjRpIscff3wisyWvLBfQ58+/9dZbUqlSpSyX4PATLTBr1izR84sANNGy6ZUfAWiatIcGB6eddpo89dRTaVIjqpEpAtqbcNttt0mnTp0y5ZA4jjQQWLNmjXz00Ud8Z6VBW2RaFfr378983pnWqBGOh3tAI6CwCgEEEEAAAQQQQCB5AgSgybMlZwQQQAABBBBAAIEIAgSgEVBYhQACCCCAAAIIIJA8AQLQ5NmSMwIIIIAAAggggEAEAQLQCCisQgABBBBAAAEEEEieAAFo8mzJGQEEEEAAAQQQQCCCAAFoBBRWIYAAAggggAACCCRPgAA0ebbkjAACCCCAAAIIIBBBICfkLBHWsypggZ9++km2bNki9erVC7hkist0gdWrV5tJnXliTaa3dLDHt3//flm5cqWcdNJJwRZMaRkvsHHjRvNUwJo1a2b8sWbzARKAZnPrc+wIIIAAAggggEAKBLgEnwJ0ikQAAQQQQAABBLJZgAA0m1ufY0cAAQQQQAABBFIgQACaAnSKRAABBBBAAAEEslmAADSbW59jRwABBBBAAAEEUiBAAJoCdIpEAAEEEEAAAQSyWYAANJtbn2NHAAEEEEAAAQRSIEAAmgJ0ikQAAQQQQAABBLJZgAA0m1ufY0cAAQQQQAABBFIgQACaAnSKRAABBBBAAAEEslmAADSbW59jRwABBBBAAAEEUiBAAJpE9FAoFFfufvbzkyauwtnJCoF42j+efazAoJIJFYj3PNm9e3eJ9Yg33xIzZaM1AvG2/8GDB2Xfvn3WHCcV9S9AAOrfynfKBQsWSI8ePeTII4+U+vXry+DBg6Puu3PnTunfv780atRIqlWrJldeeaVs2bKlwH5+0hTYgQ8ZJ/DKK6/IueeeKxUqVJCWLVvK9OnTox6jn/Oxd+/ectJJJxX5+/nnn6PmTwL7BUr73fLiiy9KjRo1IkLEc85GzIiVVgr4+f4p7sAOHTokl156qdx8881FkvCdVYTEuhV51tU4zSu8a9cu6dq1q5x11lny4YcfyqJFi+T222+X3Nxc+eMf/1hs7QcMGCATJ06UkSNHSrly5eTOO++Ujh07yvz58yUnJ8fs5ydNsQWwwXqBjz76yHwRP/bYYzJs2DB59tlnpVOnTvLZZ59JkyaQEpnzAAAPyklEQVRNIh6f3/Nx0qRJcsopp5jzNjyjsmXLhn/kfYYKlOa75a233pI+ffpImTJliujEc84WyYQV1gr4/f6JdIB79+6Vvn37mn8Xe/XqVSQJ31lFSOxb4XSLsyRQ4P777w9Vrlw55FyO8nIdNGhQyOkdCO3Zs8dbF/5m8eLFISdADTlf5N7qpUuX6vX7kPM/mVnnJ423M28yUuDkk08OOT3rBY6tcePGoRtvvLHAuvAPfs5Hp6fdnGsTJkwI35X3WSIQ73fL9u3bzfmo31Mnnnhi6PDDDy8iFs85WyQTVlgr4Of7J9LBzZ07N+T8IA5VrVo1VKtWrZATgBZIxndWAQ5rP3AJPsG/Gd5//33TK3XYYYd5OV922WXyww8/yOeff+6tC3/zwQcfmF5P7c1yF+eLW5wvdXGCArPKTxp3X14zT2DdunWybNkyueKKKwocnJ5b2nNe3OLnfPziiy/M7qeffrp51cteLNkjEO93y7x58+STTz4R7QG99dZbvSs1rly856y7P6/2C/j5/ol0lC+88ILUqVNH9PK93sZWeOE7q7CInZ8JQBPcbl9//bX5Hyc8W/0fSZeNGzeGr/be6z41a9Y0Qai30nlTu3Zt2bRpk1nlJ034vrzPLIEVK1aYA3LPJffo9PPmzZuluKDRz/mot4kcccQR8swzz0jDhg3F6XWQq666yuTrlsNr5grE+93SvHlzWb58ueiPoEhLvOdspLxYZ6eAn++fSEf2wAMPyOTJk6VevXqRNptb2/jOikhj1UoC0AQ3144dO6R69eoFctV/0HVxg8kCG50Puo8OPCq86CAmdx8/aQrvz+fMEfjpp5/MwRQ+t/Qc0VGihQesuUfu53x0LsGKDjZauXKlOLeLmAFw77zzjpx//vkmbzcvXjNTIN7vlipVqhT50RwuFO85G54H7+0W8PP9E+kItUOmpIXvrJJ07NnGIKQEt5UO2nAHDblZu5/379/vrirwqvvoIKXCi+7nTj/hJ03h/fmcOQJ5ef//v6p7LhU+Mvc8Kbzez/mYn59vgs2rr77a7K4zOOgIex08N27cONMbWjhfPmeOQLK+W+I9ZzNHliPx8/0TjxLfWfGopd8+RaOe9KujVTU6+uij5ccffyxQ523btpnPlSpVKrDe/RBpH92m+TgDmkwyP2nc/HjNPIFjjjnGHJR7LrlH6J5r7nnirndfI503bh7u+dimTRtxg093vy5dupgfRQsXLnRX8ZqhApHOET3U8O+feA493nM2nrLYJz0FIp1bhb9/4qk531nxqKXfPgSgCW4T/R+u8L2eGzZsMKU0aNAgYmn6Ra338eml1PBF83FvwPaTJnxf3meWgJ5Xurjnknt0eo7o/ItuMOmud1/9nI861ZfeqxW+uL1iOiUYS2YLJOu7Jd5zNrO1s+vo/Hz/xCPCd1Y8aum3DwFogttE5+7U+cnCg0kdya49VGeccUbE0jp06GDuwQufVPybb74xo57PO+88s4+fNBEzZ2VGCGiQcOqpp3qzIrgH9e6774p7jrjrwl/9nI89e/YU7fEMX95++205cOBAsedseFre2y2QrO+WeM9ZuzWpfbiAn++f8PR+3/Od5VcqzdNZO4FUmlb8u+++Czm9RyHn/rnQ1q1bQ05QGXIGGIWcicO9GjujQ0POKOPQtGnTvHXt27cP6ZyO//nPf0LO9CUhJ6gIOZcZQs7o5pjSeIl5k3ECzij1kDO9V2js2LEhnYPx4YcfNp+dwUPesb766qvm3HImgDbr/JyPzsT2Zh5QnbPv+++/D+kcfM4TuULOD6YC559XCG8yTsDP989tt90WeuihhyIe++OPPx5yns5VZJufc7bITqzIGAE/3z+Fv7MKH3yrVq2KzAPKd1ZhJTs/i53VTu9aO71SZuJ557eHCT6dx4iFnN4kr9LOk2vMP/jOXGfeOg06W7dubdY7N++HnBHIIZ2MPnzxkyY8Pe8zS0DPobvuusv8wNFzSyf5dh5zWOAg+/XrZ84hZ/Sptz7a+ag/cu67776Qc7ndO/8uueQS8wPKy4Q3GS3g57vluOOOC1144YURHYoLQP2csxEzZGXGCET7/on0nRV+8JECUL6zwoXsfZ+jVU/zTlorq6esa9askbp164o7GtTPgeiE9ToiPtK0TO7+ftK4aXnNPAHniVri9FSKExD4Pjg/56OOpF+9erU5Z/VZ8yzZJ5Cs75Z4ztns08/cI/bz/RPP0fOdFY9a+uxDAJo+bUFNEEAAAQQQQACBrBBgEFJWNDMHiQACCCCAAAIIpI8AAWj6tAU1QQABBBBAAAEEskKAADQrmpmDRAABBBBAAAEE0keAADR92oKaIIAAAggggAACWSFAAJoVzcxBIoAAAggggAAC6SNAAJo+bUFNEEAAAQQQQACBrBAgAM2KZuYgEUAAAQQQQACB9BEgAE2ftqAmCCCAAAIIIIBAVggQgGZFM3OQCCCAAAIIIIBA+ggQgKZPW1ATBBBAAAEEEEAgKwQIQLOimTlIBBBAAAEEEEAgfQQIQNOnLagJAggggAACCCCQFQIEoFnRzBwkAggggAACCCCQPgIEoOnTFtQEAQQQQAABBBDICgEC0KxoZg4SAQQQQAABBBBIHwEC0PRpC2qCAAIIIIAAAghkhQABaFY0MweJAAIIIIAAAgikjwABaPq0BTVBAAEEEEAAAQSyQoAANCuamYNEAAEEEEAAAQTSR4AANH3agpoggAACCCCAAAJZIUAAmhXNzEEigAACCCCAAALpI0AAmj5tQU0QQAABBBBAAIGsECAAzYpm5iARQAABBBBAAIH0ESAATZ+2oCYIIIAAAggggEBWCBCAZkUzc5AIIJBKgYMHD8q+fftSWQXKRgABBNJKgAA0rZqDyiCAQJACw4cPl5ycnAJ/FSpUkHr16skf/vAH+fHHH31X58gjj5RHH320SPpDhw7JpZdeKjfffHORbYlY0bNnT2nbtq2XVfny5eXJJ5+U1157zRzXggULvG36ZtWqVWZ95cqVZf/+/QW2vfjii2bbmjVrCqznAwIIIJBogbxEZ0h+CCCAgG0CI0aMkEqVKplq7969WxYvXiwanH755ZcyefJkX4dzzTXXSOPGjQuk3bt3r/Tt21cmTpwovXr1KrAt2R/OPfdcU8Snn34qp59+ulfcBx98ILVq1ZLvv/9edNs555zjbfvkk0+kQYMGcvzxx3vreIMAAggkQ4AANBmq5IkAAlYJdO3aVWrWrFmgzhUrVpS//vWvor2BfgKyZ555psD+8+bNk+uvv16+++47E/AV2BjAh6OPPlpOPvlkE2TedtttXokagGqPrAaf+r5wANqhQwcvLW8QQACBZAlwCT5ZsuSLAAJWCzRr1szU/+uvvzavc+bMkXbt2pme0hNOOEHy8/Nl69at3jFqj+PLL7/sfX7hhRekTp06opfA69ev762P9c348eOlTZs2Uq1aNdGgslOnTrJs2TJf2bRv394Emm5ivR1g2rRpct5550nHjh0L9O5qj+iKFSuEANTV4hUBBJIpQACaTF3yRgABawU08NOlUaNG8vPPP0vnzp1Fe0Vfeukl6devnwneevTo4R3fokWLZNOmTd7nBx54wKTR+0njXcaOHStdunSRpk2byj/+8Q/p06ePLFy40Kzzk6cGoCtXrpTNmzeb5Norq/e1apCpf3PnzvWCaL38rvfD6j4sCCCAQLIFuASfbGHyRwCBtBfQQM+9B/Snn36S2bNny7hx40ygd9xxx4n2fm7ZskUefPBB737K2rVry8yZMyUUCpnArfBBFr6kX3i7n8+zZs0yl8uffvppk/yKK66QcuXKyYABA2Tbtm1StWrVErPRHlsNKvVyu15210vuep+q3gPqbps6dap069ZNNABt0qRJkVsRSiyAjQgggECcAgSgccKxGwIIZI5A+D2Subm55tK5joL/y1/+Yg7y1FNPNb2fV155pfz2t781wZwGg/qXzOXxxx/3std7SXVQ1NKlS826Xbt2RQ1ANQjWuocHoO4ldh0F36JFC/n4449NAKrBtLvNK5Q3CCCAQJIEuASfJFiyRQABewT0nkq9TK1/Ogp+7dq1MmTIEDniiCPMQeir9hTWqFFDBg4caHoKTzzxRHn77beTepDa63rjjTea+z/1flK973T58uWmTO159bPoJXXt0dXbCLRHNTzI1Peff/65aDA7f/78Atv85E0aBBBAIF4BAtB45dgPAQQyRqB69eomuNQAUy9xR1patmxpgrXVq1fLU089JTrfpvaA6ryayVr0HtN3333XzC+qA4TWr18vt99+uykulgBU7/3US+w6CEkvvbuLBqB6T6kGqLqEj4h30/CKAAIIJEOAADQZquSJAAIZJaCXp3WU+w8//GCmZNIgcNSoUSag0zlDk7Hok5OmTJkid9xxh/Tu3VsaNmxoitGeSl306Up+Fg04d+7cKa+88opoEO3e66r7tm7d2mShA5zOOussc5uBnzxJgwACCJRWgAC0tILsjwACGS+gE7l/9dVX8vvf/968ai+oTl6fl5fnBXGJRtCe2FatWpkeUJ2LdMeOHfL888+b3lctSy+b+1l0+iYdXKSDqsIvv+u+hx12mKm/DsIqvM1P3qRBAAEE4hUgAI1Xjv0QQCBrBPTxnM8++6yZlP60004TnQd00qRJ8t577yV11LhO5aSLlqe3CWiv64wZM6RMmTLy2Wef+fbX+0C1RzVSkKnritvmuwASIoAAAjEK5Dj3Efm7kz3GjEmOAAIIZKKA9kTqgJ5jjjkmsMPbuHGjaBCsI9dZEEAAgUwQIADNhFbkGBBAAAEEEEAAAYsEmAfUosaiqgggkBkCDz30kIwePbrEg9FBQfrUJRYEEEAgEwXoAc3EVuWYEEAgrQV0Unmd47OkReceLc0z5EvKm20IIIBAqgUIQFPdApSPAAIIIIAAAghkmQCj4LOswTlcBBBAAAEEEEAg1QIEoKluAcpHAAEEEEAAAQSyTIAANMsanMNFAAEEEEAAAQRSLUAAmuoWoHwEEEAAAQQQQCDLBAhAs6zBOVwEEEAAAQQQQCDVAgSgqW4BykcAAQQQQAABBLJMgAA0yxqcw0UAAQQQQAABBFItQACa6hagfAQQQAABBBBAIMsECECzrME5XAQQQAABBBBAINUCBKCpbgHKRwABBBBAAAEEskyAADTLGpzDRQABBBBAAAEEUi1AAJrqFqB8BBBAAAEEEEAgywQIQLOswTlcBBBAAAEEEEAg1QIEoKluAcpHAAEEEEAAAQSyTIAANMsanMNFAAEEEEAAAQRSLUAAmuoWoHwEEEAAAQQQQCDLBAhAs6zBOVwEEEAAAQQQQCDVAgSgqW4BykcAAQQQQAABBLJMgAA0yxqcw0UAAQQQQAABBFIt8H98+hhsAnS3DAAAAABJRU5ErkJggg==" /><!-- --></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="co"># now compute the MSE in a way that matches formulas</span></a>
<a class="sourceLine" id="cb6-2" data-line-number="2"><span class="co"># presented in class</span></a>
<a class="sourceLine" id="cb6-3" data-line-number="3"><span class="co"># how many observations?</span></a>
<a class="sourceLine" id="cb6-4" data-line-number="4">n &lt;-<span class="st"> </span><span class="kw">nrow</span>(full_data)</a>
<a class="sourceLine" id="cb6-5" data-line-number="5"><span class="co"># outcome</span></a>
<a class="sourceLine" id="cb6-6" data-line-number="6">Y &lt;-<span class="st"> </span>full_data<span class="op">$</span>mi</a>
<a class="sourceLine" id="cb6-7" data-line-number="7"><span class="co"># estimate</span></a>
<a class="sourceLine" id="cb6-8" data-line-number="8">mse_Psi1 &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">/</span>n <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>((Y <span class="op">-</span><span class="st"> </span>Psi1_allW)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb6-9" data-line-number="9">mse_Psi1</a>
<a class="sourceLine" id="cb6-10" data-line-number="10"><span class="co">#&gt; [1] 0.03005748</span></a>
<a class="sourceLine" id="cb6-11" data-line-number="11"><span class="co"># or a one-liner</span></a>
<a class="sourceLine" id="cb6-12" data-line-number="12">mse_Psi1 &lt;-<span class="st"> </span><span class="kw">mean</span>((full_data<span class="op">$</span>mi <span class="op">-</span><span class="st"> </span>Psi1_allW)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb6-13" data-line-number="13">mse_Psi1</a>
<a class="sourceLine" id="cb6-14" data-line-number="14"><span class="co">#&gt; [1] 0.03005748</span></a>
<a class="sourceLine" id="cb6-15" data-line-number="15"></a>
<a class="sourceLine" id="cb6-16" data-line-number="16"><span class="co">#================================================</span></a>
<a class="sourceLine" id="cb6-17" data-line-number="17"><span class="co"># Exercise 2:</span></a>
<a class="sourceLine" id="cb6-18" data-line-number="18"><span class="co">#================================================</span></a>
<a class="sourceLine" id="cb6-19" data-line-number="19"><span class="co"># a. Compute the estimated MSE for Psi2. </span></a>
<a class="sourceLine" id="cb6-20" data-line-number="20"><span class="co"># mse_Psi2 &lt;- ... </span></a>
<a class="sourceLine" id="cb6-21" data-line-number="21"><span class="co"># Solution: </span></a>
<a class="sourceLine" id="cb6-22" data-line-number="22">Psi2_allW &lt;-<span class="st"> </span><span class="kw">Psi2</span>(<span class="dt">new_features =</span> full_data, <span class="dt">model =</span> model2)</a>
<a class="sourceLine" id="cb6-23" data-line-number="23">mse_Psi2 &lt;-<span class="st"> </span><span class="kw">mean</span>((Y <span class="op">-</span><span class="st"> </span>Psi2_allW)<span class="op">^</span><span class="dv">2</span>) </a>
<a class="sourceLine" id="cb6-24" data-line-number="24">mse_Psi2</a>
<a class="sourceLine" id="cb6-25" data-line-number="25"><span class="co">#&gt; [1] 0.02536199</span></a>
<a class="sourceLine" id="cb6-26" data-line-number="26"><span class="co">#</span></a>
<a class="sourceLine" id="cb6-27" data-line-number="27"><span class="co"># b. (Bonus!) Negative log-likelihood loss is an alternative</span></a>
<a class="sourceLine" id="cb6-28" data-line-number="28"><span class="co"># loss function, L(psi,o) = -log(psi(x)^y + (1-psi(x))^(1-y)),</span></a>
<a class="sourceLine" id="cb6-29" data-line-number="29"><span class="co"># where o = (x,y).</span></a>
<a class="sourceLine" id="cb6-30" data-line-number="30"><span class="co"># Compute the estimated average negative log-likelihood for</span></a>
<a class="sourceLine" id="cb6-31" data-line-number="31"><span class="co"># both Psi1 and Psi2. </span></a>
<a class="sourceLine" id="cb6-32" data-line-number="32"><span class="co">#</span></a>
<a class="sourceLine" id="cb6-33" data-line-number="33">nloglik_Psi2 &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="op">-</span>(Y <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(Psi2_allW) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>Y)<span class="op">*</span><span class="kw">log</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>Psi2_allW)))</a>
<a class="sourceLine" id="cb6-34" data-line-number="34">nloglik_Psi2</a>
<a class="sourceLine" id="cb6-35" data-line-number="35"><span class="co">#&gt; [1] 0.1028601</span></a></code></pre></div>
<p>As discussed in class, using the same data to train algorithms as to evaluate them leads to overly optimistic estimates of performance. This fact motivated the use of cross-validation. Here, we use two-fold cross-validation to estimate the MSE of the two logistic regression models.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="co"># first we assign a split for each of the n observations</span></a>
<a class="sourceLine" id="cb7-2" data-line-number="2"><span class="co"># here, we use the first half of data as one split, the second</span></a>
<a class="sourceLine" id="cb7-3" data-line-number="3"><span class="co"># half of the data as the other split</span></a>
<a class="sourceLine" id="cb7-4" data-line-number="4">split &lt;-<span class="st"> </span><span class="kw">sort</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>),<span class="kw">round</span>(n<span class="op">/</span><span class="dv">2</span>,<span class="dv">0</span>)))</a>
<a class="sourceLine" id="cb7-5" data-line-number="5"><span class="co"># take a look to make sure the right number in each split</span></a>
<a class="sourceLine" id="cb7-6" data-line-number="6"><span class="kw">table</span>(split)</a>
<a class="sourceLine" id="cb7-7" data-line-number="7"><span class="co">#&gt; split</span></a>
<a class="sourceLine" id="cb7-8" data-line-number="8"><span class="co">#&gt;    1    2 </span></a>
<a class="sourceLine" id="cb7-9" data-line-number="9"><span class="co">#&gt; 2295 2295</span></a>
<a class="sourceLine" id="cb7-10" data-line-number="10"></a>
<a class="sourceLine" id="cb7-11" data-line-number="11"><span class="co"># now define first training sample and validation sample</span></a>
<a class="sourceLine" id="cb7-12" data-line-number="12">train1 &lt;-<span class="st"> </span>full_data[split <span class="op">==</span><span class="st"> </span><span class="dv">1</span>,]</a>
<a class="sourceLine" id="cb7-13" data-line-number="13">valid1 &lt;-<span class="st"> </span>full_data[split <span class="op">==</span><span class="st"> </span><span class="dv">2</span>,]</a>
<a class="sourceLine" id="cb7-14" data-line-number="14"></a>
<a class="sourceLine" id="cb7-15" data-line-number="15"><span class="co"># similarly, reverse their roles</span></a>
<a class="sourceLine" id="cb7-16" data-line-number="16">train2 &lt;-<span class="st"> </span>full_data[split <span class="op">==</span><span class="st"> </span><span class="dv">2</span>,]</a>
<a class="sourceLine" id="cb7-17" data-line-number="17">valid2 &lt;-<span class="st"> </span>full_data[split <span class="op">==</span><span class="st"> </span><span class="dv">1</span>,]</a>
<a class="sourceLine" id="cb7-18" data-line-number="18"></a>
<a class="sourceLine" id="cb7-19" data-line-number="19"><span class="co"># now fit model1 using only train1 data</span></a>
<a class="sourceLine" id="cb7-20" data-line-number="20">model1_train1 &lt;-<span class="st"> </span><span class="kw">glm</span>(mi <span class="op">~</span><span class="st"> </span>waist <span class="op">+</span><span class="st"> </span>smoke <span class="op">+</span><span class="st"> </span>hdl, <span class="dt">data =</span> train1, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb7-21" data-line-number="21"><span class="co"># take a peak</span></a>
<a class="sourceLine" id="cb7-22" data-line-number="22">model1_train1</a>
<a class="sourceLine" id="cb7-23" data-line-number="23"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb7-24" data-line-number="24"><span class="co">#&gt; Call:  glm(formula = mi ~ waist + smoke + hdl, family = &quot;binomial&quot;, </span></a>
<a class="sourceLine" id="cb7-25" data-line-number="25"><span class="co">#&gt;     data = train1)</span></a>
<a class="sourceLine" id="cb7-26" data-line-number="26"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb7-27" data-line-number="27"><span class="co">#&gt; Coefficients:</span></a>
<a class="sourceLine" id="cb7-28" data-line-number="28"><span class="co">#&gt; (Intercept)        waist        smoke          hdl  </span></a>
<a class="sourceLine" id="cb7-29" data-line-number="29"><span class="co">#&gt;   -0.854339    -0.024073     0.464426    -0.008184  </span></a>
<a class="sourceLine" id="cb7-30" data-line-number="30"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb7-31" data-line-number="31"><span class="co">#&gt; Degrees of Freedom: 2294 Total (i.e. Null);  2291 Residual</span></a>
<a class="sourceLine" id="cb7-32" data-line-number="32"><span class="co">#&gt; Null Deviance:       591.5 </span></a>
<a class="sourceLine" id="cb7-33" data-line-number="33"><span class="co">#&gt; Residual Deviance: 580.1     AIC: 588.1</span></a>
<a class="sourceLine" id="cb7-34" data-line-number="34"></a>
<a class="sourceLine" id="cb7-35" data-line-number="35"><span class="co"># now we will evaluate MSE in valid1</span></a>
<a class="sourceLine" id="cb7-36" data-line-number="36"><span class="co"># note we can still use the Psi1 function, but just change</span></a>
<a class="sourceLine" id="cb7-37" data-line-number="37"><span class="co"># the model statement</span></a>
<a class="sourceLine" id="cb7-38" data-line-number="38">Psi1_valid1W &lt;-<span class="st"> </span><span class="kw">Psi1</span>(<span class="dt">new_features =</span> valid1, <span class="dt">model =</span> model1_train1)</a>
<a class="sourceLine" id="cb7-39" data-line-number="39"><span class="co"># take a peak</span></a>
<a class="sourceLine" id="cb7-40" data-line-number="40"><span class="kw">head</span>(Psi1_valid1W)</a>
<a class="sourceLine" id="cb7-41" data-line-number="41"><span class="co">#&gt; [1] 0.03959560 0.03684553 0.01492446 0.02917764 0.01625422 0.03405874</span></a>
<a class="sourceLine" id="cb7-42" data-line-number="42"><span class="co"># compute the MSE</span></a>
<a class="sourceLine" id="cb7-43" data-line-number="43">mse_Psi1_valid1 &lt;-<span class="st"> </span><span class="kw">mean</span>((valid1<span class="op">$</span>mi <span class="op">-</span><span class="st"> </span>Psi1_valid1W)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb7-44" data-line-number="44"></a>
<a class="sourceLine" id="cb7-45" data-line-number="45"><span class="co"># now reverse the roles!</span></a>
<a class="sourceLine" id="cb7-46" data-line-number="46"><span class="co"># fit model1 using only train2 data</span></a>
<a class="sourceLine" id="cb7-47" data-line-number="47">model1_train2 &lt;-<span class="st"> </span><span class="kw">glm</span>(mi <span class="op">~</span><span class="st"> </span>waist <span class="op">+</span><span class="st"> </span>smoke <span class="op">+</span><span class="st"> </span>hdl, <span class="dt">data =</span> train2, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb7-48" data-line-number="48"><span class="co"># take a peak</span></a>
<a class="sourceLine" id="cb7-49" data-line-number="49">model1_train2</a>
<a class="sourceLine" id="cb7-50" data-line-number="50"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb7-51" data-line-number="51"><span class="co">#&gt; Call:  glm(formula = mi ~ waist + smoke + hdl, family = &quot;binomial&quot;, </span></a>
<a class="sourceLine" id="cb7-52" data-line-number="52"><span class="co">#&gt;     data = train2)</span></a>
<a class="sourceLine" id="cb7-53" data-line-number="53"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb7-54" data-line-number="54"><span class="co">#&gt; Coefficients:</span></a>
<a class="sourceLine" id="cb7-55" data-line-number="55"><span class="co">#&gt; (Intercept)        waist        smoke          hdl  </span></a>
<a class="sourceLine" id="cb7-56" data-line-number="56"><span class="co">#&gt;    -2.74398     -0.02123      0.72776      0.01977  </span></a>
<a class="sourceLine" id="cb7-57" data-line-number="57"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb7-58" data-line-number="58"><span class="co">#&gt; Degrees of Freedom: 2294 Total (i.e. Null);  2291 Residual</span></a>
<a class="sourceLine" id="cb7-59" data-line-number="59"><span class="co">#&gt; Null Deviance:       687.6 </span></a>
<a class="sourceLine" id="cb7-60" data-line-number="60"><span class="co">#&gt; Residual Deviance: 656.2     AIC: 664.2</span></a>
<a class="sourceLine" id="cb7-61" data-line-number="61"></a>
<a class="sourceLine" id="cb7-62" data-line-number="62"><span class="co"># now we will evaluate MSE in valid1</span></a>
<a class="sourceLine" id="cb7-63" data-line-number="63"><span class="co"># note we can still use the Psi1 function, but just change</span></a>
<a class="sourceLine" id="cb7-64" data-line-number="64"><span class="co"># the model statement</span></a>
<a class="sourceLine" id="cb7-65" data-line-number="65">Psi1_valid2W &lt;-<span class="st"> </span><span class="kw">Psi1</span>(<span class="dt">new_features =</span> valid2, <span class="dt">model =</span> model1_train2)</a>
<a class="sourceLine" id="cb7-66" data-line-number="66"><span class="co"># take a peak</span></a>
<a class="sourceLine" id="cb7-67" data-line-number="67"><span class="kw">head</span>(Psi1_valid2W)</a>
<a class="sourceLine" id="cb7-68" data-line-number="68"><span class="co">#&gt; [1] 0.02256396 0.02497107 0.01480289 0.01905850 0.09273421 0.02891445</span></a>
<a class="sourceLine" id="cb7-69" data-line-number="69"><span class="co"># compute the MSE</span></a>
<a class="sourceLine" id="cb7-70" data-line-number="70">mse_Psi1_valid2 &lt;-<span class="st"> </span><span class="kw">mean</span>((valid2<span class="op">$</span>mi <span class="op">-</span><span class="st"> </span>Psi1_valid2W)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb7-71" data-line-number="71"></a>
<a class="sourceLine" id="cb7-72" data-line-number="72"><span class="co"># average the two to get a cross-validated estimate of MSE</span></a>
<a class="sourceLine" id="cb7-73" data-line-number="73">cv_mse_Psi1 &lt;-<span class="st"> </span>(mse_Psi1_valid1 <span class="op">+</span><span class="st"> </span>mse_Psi1_valid2) <span class="op">/</span><span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb7-74" data-line-number="74">cv_mse_Psi1</a>
<a class="sourceLine" id="cb7-75" data-line-number="75"><span class="co">#&gt; [1] 0.03035721</span></a>
<a class="sourceLine" id="cb7-76" data-line-number="76"><span class="co">#================================================</span></a>
<a class="sourceLine" id="cb7-77" data-line-number="77"><span class="co"># Exercise 3:</span></a>
<a class="sourceLine" id="cb7-78" data-line-number="78"><span class="co">#================================================</span></a>
<a class="sourceLine" id="cb7-79" data-line-number="79"><span class="co"># a. Compute the cross-validated MSE for model2.</span></a>
<a class="sourceLine" id="cb7-80" data-line-number="80">model2_train1 &lt;-<span class="st"> </span><span class="kw">glm</span>(mi <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> train1, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb7-81" data-line-number="81">Psi2_valid1W &lt;-<span class="st"> </span><span class="kw">Psi2</span>(<span class="dt">new_features =</span> valid1, <span class="dt">model =</span> model2_train1)</a>
<a class="sourceLine" id="cb7-82" data-line-number="82">mse_Psi2_valid1 &lt;-<span class="st"> </span><span class="kw">mean</span>((valid1<span class="op">$</span>mi <span class="op">-</span><span class="st"> </span>Psi2_valid1W)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb7-83" data-line-number="83"></a>
<a class="sourceLine" id="cb7-84" data-line-number="84">model2_train2 &lt;-<span class="st"> </span><span class="kw">glm</span>(mi <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> train2, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb7-85" data-line-number="85">Psi2_valid2W &lt;-<span class="st"> </span><span class="kw">Psi2</span>(<span class="dt">new_features =</span> valid2, <span class="dt">model =</span> model2_train2)</a>
<a class="sourceLine" id="cb7-86" data-line-number="86">mse_Psi2_valid2 &lt;-<span class="st"> </span><span class="kw">mean</span>((valid2<span class="op">$</span>mi <span class="op">-</span><span class="st"> </span>Psi2_valid2W)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb7-87" data-line-number="87"></a>
<a class="sourceLine" id="cb7-88" data-line-number="88">cv_mse_Psi2 &lt;-<span class="st"> </span>(mse_Psi2_valid1 <span class="op">+</span><span class="st"> </span>mse_Psi2_valid2) <span class="op">/</span><span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb7-89" data-line-number="89">cv_mse_Psi2</a>
<a class="sourceLine" id="cb7-90" data-line-number="90"><span class="co">#&gt; [1] 0.02743314</span></a>
<a class="sourceLine" id="cb7-91" data-line-number="91"><span class="co"># b. How does it compare to MSE for model1?</span></a>
<a class="sourceLine" id="cb7-92" data-line-number="92">cv_mse_Psi2 <span class="op">&lt;</span><span class="st"> </span>cv_mse_Psi1</a>
<a class="sourceLine" id="cb7-93" data-line-number="93"><span class="co">#&gt; [1] TRUE</span></a>
<a class="sourceLine" id="cb7-94" data-line-number="94"></a>
<a class="sourceLine" id="cb7-95" data-line-number="95"><span class="co"># c. What estimator would cross-validation have us select?</span></a>
<a class="sourceLine" id="cb7-96" data-line-number="96"><span class="co"># Psi2 -- the full logistic regression</span></a></code></pre></div>
<p>What about an ensemble estimator of the two? Recall that a stacked regression (aka a super learner) is a convex combination of multiple models. Here we demonstrate how to determine the weights that minimize cross-validated MSE over all convex combinations.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="co"># we need to define a new machine that takes both model1 and model2 </span></a>
<a class="sourceLine" id="cb8-2" data-line-number="2"><span class="co"># in and returns a weighted combination of their predictions</span></a>
<a class="sourceLine" id="cb8-3" data-line-number="3">Psi_sl &lt;-<span class="st"> </span><span class="cf">function</span>(new_features, model1, model2,</a>
<a class="sourceLine" id="cb8-4" data-line-number="4">                   model1_weight, <span class="dt">model2_weight =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>model1_weight){</a>
<a class="sourceLine" id="cb8-5" data-line-number="5">  <span class="co"># make sure weights approximately sum to 1</span></a>
<a class="sourceLine" id="cb8-6" data-line-number="6">  <span class="kw">stopifnot</span>(<span class="kw">abs</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>model1_weight <span class="op">-</span><span class="st"> </span>model2_weight) <span class="op">&lt;</span><span class="st"> </span><span class="fl">1e-5</span>)</a>
<a class="sourceLine" id="cb8-7" data-line-number="7">  <span class="co"># prediction from model 1 on new data</span></a>
<a class="sourceLine" id="cb8-8" data-line-number="8">  model1_prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(model1, <span class="dt">newdata =</span> new_features, <span class="dt">type =</span> <span class="st">'response'</span>)</a>
<a class="sourceLine" id="cb8-9" data-line-number="9">  <span class="co"># prediction from model 2 on new data</span></a>
<a class="sourceLine" id="cb8-10" data-line-number="10">  model2_prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(model2, <span class="dt">newdata =</span> new_features, <span class="dt">type =</span> <span class="st">'response'</span>)</a>
<a class="sourceLine" id="cb8-11" data-line-number="11">  <span class="co"># weighted combination</span></a>
<a class="sourceLine" id="cb8-12" data-line-number="12">  ensemble_prediction &lt;-<span class="st"> </span>model1_weight <span class="op">*</span><span class="st"> </span>model1_prediction <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb8-13" data-line-number="13"><span class="st">                            </span>model2_weight <span class="op">*</span><span class="st"> </span>model2_prediction</a>
<a class="sourceLine" id="cb8-14" data-line-number="14">  <span class="kw">return</span>(<span class="kw">as.numeric</span>(ensemble_prediction))</a>
<a class="sourceLine" id="cb8-15" data-line-number="15">}</a>
<a class="sourceLine" id="cb8-16" data-line-number="16"></a>
<a class="sourceLine" id="cb8-17" data-line-number="17"><span class="co"># test it out on the first observation using full data models and equal weights</span></a>
<a class="sourceLine" id="cb8-18" data-line-number="18"><span class="co"># should be the same as </span></a>
<a class="sourceLine" id="cb8-19" data-line-number="19"><span class="co"># 0.5 * Psi1(full_data[1,], model = model1) + 0.5 * Psi2(full_data[1,], model = model2)</span></a>
<a class="sourceLine" id="cb8-20" data-line-number="20"><span class="kw">Psi_sl</span>(<span class="dt">new_features =</span> full_data[<span class="dv">1</span>,], <span class="dt">model1 =</span> model1, <span class="dt">model2 =</span> model2,</a>
<a class="sourceLine" id="cb8-21" data-line-number="21">       <span class="dt">model1_weight =</span> <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb8-22" data-line-number="22"><span class="co">#&gt; [1] 0.0177746</span></a>
<a class="sourceLine" id="cb8-23" data-line-number="23"></a>
<a class="sourceLine" id="cb8-24" data-line-number="24"><span class="co"># try different weights</span></a>
<a class="sourceLine" id="cb8-25" data-line-number="25"><span class="kw">Psi_sl</span>(<span class="dt">new_features =</span> full_data[<span class="dv">1</span>,], <span class="dt">model1 =</span> model1, <span class="dt">model2 =</span> model2,</a>
<a class="sourceLine" id="cb8-26" data-line-number="26">       <span class="dt">model1_weight =</span> <span class="fl">0.25</span>)</a>
<a class="sourceLine" id="cb8-27" data-line-number="27"><span class="co">#&gt; [1] 0.01547143</span></a>
<a class="sourceLine" id="cb8-28" data-line-number="28"></a>
<a class="sourceLine" id="cb8-29" data-line-number="29"><span class="co"># We could also apply this to the training data models. e.g., </span></a>
<a class="sourceLine" id="cb8-30" data-line-number="30"><span class="co"># here we use model1 and model2 fit to training data</span></a>
<a class="sourceLine" id="cb8-31" data-line-number="31"><span class="kw">Psi_sl</span>(<span class="dt">new_features =</span> valid1[<span class="dv">1</span>,], <span class="dt">model1 =</span> model1_train1, <span class="dt">model2 =</span> model2_train1,</a>
<a class="sourceLine" id="cb8-32" data-line-number="32">       <span class="dt">model1_weight =</span> <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb8-33" data-line-number="33"><span class="co">#&gt; [1] 0.04770049</span></a>
<a class="sourceLine" id="cb8-34" data-line-number="34"></a>
<a class="sourceLine" id="cb8-35" data-line-number="35"><span class="co"># So, for a given set of weights, we could estimate a cross-validated MSE for </span></a>
<a class="sourceLine" id="cb8-36" data-line-number="36"><span class="co"># the weight combination as follows. </span></a>
<a class="sourceLine" id="cb8-37" data-line-number="37">Psi_sl_valid1W &lt;-<span class="st"> </span><span class="kw">Psi_sl</span>(<span class="dt">new_features =</span> valid1, </a>
<a class="sourceLine" id="cb8-38" data-line-number="38">                          <span class="dt">model1 =</span> model1_train1, </a>
<a class="sourceLine" id="cb8-39" data-line-number="39">                          <span class="dt">model2 =</span> model2_train1,</a>
<a class="sourceLine" id="cb8-40" data-line-number="40">                          <span class="dt">model1_weight =</span> <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb8-41" data-line-number="41"><span class="co"># compute the MSE</span></a>
<a class="sourceLine" id="cb8-42" data-line-number="42">mse_Psi_sl_valid1 &lt;-<span class="st"> </span><span class="kw">mean</span>((valid1<span class="op">$</span>mi <span class="op">-</span><span class="st"> </span>Psi_sl_valid1W)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb8-43" data-line-number="43"></a>
<a class="sourceLine" id="cb8-44" data-line-number="44"><span class="co"># now reverse the roles!</span></a>
<a class="sourceLine" id="cb8-45" data-line-number="45">Psi_sl_valid2W &lt;-<span class="st"> </span><span class="kw">Psi_sl</span>(<span class="dt">new_features =</span> valid2, </a>
<a class="sourceLine" id="cb8-46" data-line-number="46">                       <span class="dt">model1 =</span> model1_train2,</a>
<a class="sourceLine" id="cb8-47" data-line-number="47">                       <span class="dt">model2 =</span> model2_train2,</a>
<a class="sourceLine" id="cb8-48" data-line-number="48">                       <span class="dt">model1_weight =</span> <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb8-49" data-line-number="49"><span class="co"># take a peak</span></a>
<a class="sourceLine" id="cb8-50" data-line-number="50"><span class="kw">head</span>(Psi_sl_valid2W)</a>
<a class="sourceLine" id="cb8-51" data-line-number="51"><span class="co">#&gt; [1] 0.023542851 0.055579467 0.009674798 0.015279893 0.150463410 0.015096541</span></a>
<a class="sourceLine" id="cb8-52" data-line-number="52"><span class="co"># compute the MSE</span></a>
<a class="sourceLine" id="cb8-53" data-line-number="53">mse_Psi_sl_valid2 &lt;-<span class="st"> </span><span class="kw">mean</span>((valid2<span class="op">$</span>mi <span class="op">-</span><span class="st"> </span>Psi_sl_valid2W)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb8-54" data-line-number="54"></a>
<a class="sourceLine" id="cb8-55" data-line-number="55"><span class="co"># average the two to get a cross-validated estimate of MSE</span></a>
<a class="sourceLine" id="cb8-56" data-line-number="56">cv_mse_Psi_sl &lt;-<span class="st"> </span>(mse_Psi_sl_valid1 <span class="op">+</span><span class="st"> </span>mse_Psi_sl_valid2) <span class="op">/</span><span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb8-57" data-line-number="57"></a>
<a class="sourceLine" id="cb8-58" data-line-number="58"></a>
<a class="sourceLine" id="cb8-59" data-line-number="59"><span class="co"># Let's wrap all of these commands up in a function that computes</span></a>
<a class="sourceLine" id="cb8-60" data-line-number="60"><span class="co"># the cross-validated MSE for a given choice of model weights</span></a>
<a class="sourceLine" id="cb8-61" data-line-number="61"><span class="co"># Note: this is technically bad form for function writing, since I'm </span></a>
<a class="sourceLine" id="cb8-62" data-line-number="62"><span class="co"># relying on model1 and model2 being available in the global </span></a>
<a class="sourceLine" id="cb8-63" data-line-number="63"><span class="co"># environment and if not the function will break; however, for simplicity</span></a>
<a class="sourceLine" id="cb8-64" data-line-number="64"><span class="co"># I will ignore this issue. </span></a>
<a class="sourceLine" id="cb8-65" data-line-number="65"></a>
<a class="sourceLine" id="cb8-66" data-line-number="66">compute_cv_mse &lt;-<span class="st"> </span><span class="cf">function</span>(model1_weight){</a>
<a class="sourceLine" id="cb8-67" data-line-number="67">  Psi_sl_valid1W &lt;-<span class="st"> </span><span class="kw">Psi_sl</span>(<span class="dt">new_features =</span> valid1, </a>
<a class="sourceLine" id="cb8-68" data-line-number="68">                            <span class="dt">model1 =</span> model1_train1, </a>
<a class="sourceLine" id="cb8-69" data-line-number="69">                            <span class="dt">model2 =</span> model2_train1,</a>
<a class="sourceLine" id="cb8-70" data-line-number="70">                            <span class="dt">model1_weight =</span> model1_weight)</a>
<a class="sourceLine" id="cb8-71" data-line-number="71">  <span class="co"># compute the MSE</span></a>
<a class="sourceLine" id="cb8-72" data-line-number="72">  mse_Psi_sl_valid1 &lt;-<span class="st"> </span><span class="kw">mean</span>((valid1<span class="op">$</span>mi <span class="op">-</span><span class="st"> </span>Psi_sl_valid1W)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb8-73" data-line-number="73"></a>
<a class="sourceLine" id="cb8-74" data-line-number="74">  <span class="co"># now reverse the roles!</span></a>
<a class="sourceLine" id="cb8-75" data-line-number="75">  Psi_sl_valid2W &lt;-<span class="st"> </span><span class="kw">Psi_sl</span>(<span class="dt">new_features =</span> valid2, </a>
<a class="sourceLine" id="cb8-76" data-line-number="76">                         <span class="dt">model1 =</span> model1_train2,</a>
<a class="sourceLine" id="cb8-77" data-line-number="77">                         <span class="dt">model2 =</span> model2_train2,</a>
<a class="sourceLine" id="cb8-78" data-line-number="78">                         <span class="dt">model1_weight =</span> model1_weight)</a>
<a class="sourceLine" id="cb8-79" data-line-number="79">  <span class="co"># take a peak</span></a>
<a class="sourceLine" id="cb8-80" data-line-number="80">  <span class="kw">head</span>(Psi_sl_valid2W)</a>
<a class="sourceLine" id="cb8-81" data-line-number="81">  <span class="co"># compute the MSE</span></a>
<a class="sourceLine" id="cb8-82" data-line-number="82">  mse_Psi_sl_valid2 &lt;-<span class="st"> </span><span class="kw">mean</span>((valid2<span class="op">$</span>mi <span class="op">-</span><span class="st"> </span>Psi_sl_valid2W)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb8-83" data-line-number="83"></a>
<a class="sourceLine" id="cb8-84" data-line-number="84">  <span class="co"># average the two to get a cross-validated estimate of MSE</span></a>
<a class="sourceLine" id="cb8-85" data-line-number="85">  cv_mse_Psi_sl &lt;-<span class="st"> </span>(mse_Psi_sl_valid1 <span class="op">+</span><span class="st"> </span>mse_Psi_sl_valid2) <span class="op">/</span><span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb8-86" data-line-number="86">  <span class="kw">return</span>(cv_mse_Psi_sl)</a>
<a class="sourceLine" id="cb8-87" data-line-number="87">}</a>
<a class="sourceLine" id="cb8-88" data-line-number="88"></a>
<a class="sourceLine" id="cb8-89" data-line-number="89"><span class="co"># Now, we can compute the MSE for a grid of model1_weight values</span></a>
<a class="sourceLine" id="cb8-90" data-line-number="90">many_different_weights &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length =</span> <span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb8-91" data-line-number="91">mse_for_each_weight &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb8-92" data-line-number="92"><span class="cf">for</span>(i <span class="cf">in</span> <span class="kw">seq_len</span>(<span class="dv">1000</span>)){</a>
<a class="sourceLine" id="cb8-93" data-line-number="93">  mse_for_each_weight[i] &lt;-<span class="st"> </span><span class="kw">compute_cv_mse</span>(many_different_weights[i])</a>
<a class="sourceLine" id="cb8-94" data-line-number="94">}</a>
<a class="sourceLine" id="cb8-95" data-line-number="95"><span class="co"># take a peak </span></a>
<a class="sourceLine" id="cb8-96" data-line-number="96"><span class="kw">head</span>(mse_for_each_weight)</a>
<a class="sourceLine" id="cb8-97" data-line-number="97"><span class="co">#&gt; [1] 0.02743314 0.02743176 0.02743039 0.02742903 0.02742768 0.02742633</span></a>
<a class="sourceLine" id="cb8-98" data-line-number="98"><span class="co"># determine which weight led to the smallest cross-validated MSE</span></a>
<a class="sourceLine" id="cb8-99" data-line-number="99">min_idx &lt;-<span class="st"> </span><span class="kw">which.min</span>(mse_for_each_weight)</a>
<a class="sourceLine" id="cb8-100" data-line-number="100">opt_model1_weight &lt;-<span class="st"> </span>many_different_weights[min_idx]</a>
<a class="sourceLine" id="cb8-101" data-line-number="101"></a>
<a class="sourceLine" id="cb8-102" data-line-number="102"><span class="co"># plot </span></a>
<a class="sourceLine" id="cb8-103" data-line-number="103"><span class="kw">plot</span>(mse_for_each_weight <span class="op">~</span><span class="st"> </span>many_different_weights, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb8-104" data-line-number="104">     <span class="dt">bty =</span> <span class="st">&quot;n&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;Model 1 weight&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;CV-MSE&quot;</span>)</a>
<a class="sourceLine" id="cb8-105" data-line-number="105"><span class="co"># add a line at the minimum value</span></a>
<a class="sourceLine" id="cb8-106" data-line-number="106"><span class="kw">abline</span>(<span class="dt">v =</span> opt_model1_weight, <span class="dt">lty =</span> <span class="dv">3</span>)</a></code></pre></div>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAqAAAAHgCAYAAAB6jN80AAAEGWlDQ1BrQ0dDb2xvclNwYWNlR2VuZXJpY1JHQgAAOI2NVV1oHFUUPrtzZyMkzlNsNIV0qD8NJQ2TVjShtLp/3d02bpZJNtoi6GT27s6Yyc44M7v9oU9FUHwx6psUxL+3gCAo9Q/bPrQvlQol2tQgKD60+INQ6Ium65k7M5lpurHeZe58853vnnvuuWfvBei5qliWkRQBFpquLRcy4nOHj4g9K5CEh6AXBqFXUR0rXalMAjZPC3e1W99Dwntf2dXd/p+tt0YdFSBxH2Kz5qgLiI8B8KdVy3YBevqRHz/qWh72Yui3MUDEL3q44WPXw3M+fo1pZuQs4tOIBVVTaoiXEI/MxfhGDPsxsNZfoE1q66ro5aJim3XdoLFw72H+n23BaIXzbcOnz5mfPoTvYVz7KzUl5+FRxEuqkp9G/Ajia219thzg25abkRE/BpDc3pqvphHvRFys2weqvp+krbWKIX7nhDbzLOItiM8358pTwdirqpPFnMF2xLc1WvLyOwTAibpbmvHHcvttU57y5+XqNZrLe3lE/Pq8eUj2fXKfOe3pfOjzhJYtB/yll5SDFcSDiH+hRkH25+L+sdxKEAMZahrlSX8ukqMOWy/jXW2m6M9LDBc31B9LFuv6gVKg/0Szi3KAr1kGq1GMjU/aLbnq6/lRxc4XfJ98hTargX++DbMJBSiYMIe9Ck1YAxFkKEAG3xbYaKmDDgYyFK0UGYpfoWYXG+fAPPI6tJnNwb7ClP7IyF+D+bjOtCpkhz6CFrIa/I6sFtNl8auFXGMTP34sNwI/JhkgEtmDz14ySfaRcTIBInmKPE32kxyyE2Tv+thKbEVePDfW/byMM1Kmm0XdObS7oGD/MypMXFPXrCwOtoYjyyn7BV29/MZfsVzpLDdRtuIZnbpXzvlf+ev8MvYr/Gqk4H/kV/G3csdazLuyTMPsbFhzd1UabQbjFvDRmcWJxR3zcfHkVw9GfpbJmeev9F08WW8uDkaslwX6avlWGU6NRKz0g/SHtCy9J30o/ca9zX3Kfc19zn3BXQKRO8ud477hLnAfc1/G9mrzGlrfexZ5GLdn6ZZrrEohI2wVHhZywjbhUWEy8icMCGNCUdiBlq3r+xafL549HQ5jH+an+1y+LlYBifuxAvRN/lVVVOlwlCkdVm9NOL5BE4wkQ2SMlDZU97hX86EilU/lUmkQUztTE6mx1EEPh7OmdqBtAvv8HdWpbrJS6tJj3n0CWdM6busNzRV3S9KTYhqvNiqWmuroiKgYhshMjmhTh9ptWhsF7970j/SbMrsPE1suR5z7DMC+P/Hs+y7ijrQAlhyAgccjbhjPygfeBTjzhNqy28EdkUh8C+DU9+z2v/oyeH791OncxHOs5y2AtTc7nb/f73TWPkD/qwBnjX8BoJ98VQNcC+8AAEAASURBVHgB7N0JvIx1///xj4RUKKRCiNJyRyWhEpUkdYtCyhHuNmt7FG0obbTRnbQvVAp1l6WIytpGtlK6lZwQElmSdf7z/t7/Ob+zzHHOmTNzneuaeV2PxzBzzTXX9f0+rzkzn/le3+/nWywUXowFAQQQQAABBBBAAAGPBPbz6DgcBgEEEEAAAQQQQAABJ0AAyhsBAQQQQAABBBBAwFMBAlBPuTkYAggggAACCCCAAAEo7wEEEEAAAQQQQAABTwUIQD3l5mAIIIAAAggggAACBKC8BxBAAAEEEEAAAQQ8FSAA9ZSbgyGAAAIIIIAAAggQgPIeQAABBBBAAAEEEPBUgADUU24OhgACCCCAAAIIIEAAynsAAQQQQAABBBBAwFMBAlBPuTkYAggggAACCCCAAAEo7wEEEEAAAQQQQAABTwUIQD3l5mAIIIAAAggggAACBKC8BxBAAAEEEEAAAQQ8FSAA9ZSbgyGAAAIIIIAAAggQgPIeQAABBBBAAAEEEPBUgADUU24OhgACCCCAAAIIIEAAynsAAQQQQAABBBBAwFMBAlBPuTkYAggggAACCCCAAAEo7wEEEEAAAQQQQAABTwUIQD3l5mAIIIAAAggggAACBKC8BxBAAAEEEEAAAQQ8FSAA9ZSbgyGAAAIIIIAAAggQgPIeQAABBBBAAAEEEPBUgADUU24OhgACCCCAAAIIIEAAynsAAQQQQAABBBBAwFMBAlBPuTkYAggggAACCCCAAAEo7wEEEEAAAQQQQAABTwUIQD3l5mAIIIAAAggggAACBKC8BxBAAAEEEEAAAQQ8FSAA9ZSbgyGAAAIIIIAAAggQgPIeQAABBBBAAAEEEPBUgADUU24OhgACCCCAAAIIIEAAynsAAQQQQAABBBBAwFMBAlBPuTkYAggggAACCCCAAAEo7wEEEEAAAQQQQAABTwUIQD3l5mAIIIAAAggggAACBKC8BxBAAAEEEEAAAQQ8FSAA9ZSbgyGAAAIIIIAAAggQgPIeQAABBBBAAAEEEPBUgADUU24OhgACCCCAAAIIIEAAynsAAQQQQAABBBBAwFMBAlBPuTkYAggggAACCCCAAAEo7wEEEEAAAQQQQAABTwUIQD3l5mAIIIAAAggggAACBKC8BxBAAAEEEEAAAQQ8FSAA9ZSbgyGAAAIIIIAAAggQgPIeQAABBBBAAAEEEPBUgADUU24OhgACCCCAAAIIIEAAynsAAQQQQAABBBBAwFMBAlBPuTkYAggggAACCCCAAAEo7wEEEEAAAQQQQAABTwUIQD3l5mAIIIAAAggggAACBKC8BxBAAAEEEEAAAQQ8FSAA9ZSbgyGAAAIIIIAAAggQgPIeQAABBBBAAAEEEPBUgADUU24OhgACCCCAAAIIIEAAynsAAQQQQAABBBBAwFMBAlBPuTkYAggggAACCCCAAAEo7wEEEEAAAQQQQAABTwUIQD3l5mAIIIAAAggggAACBKC8BxBAAAEEEEAAAQQ8FSAA9ZSbgyGAAAIIIIAAAggQgPIeQAABBBBAAAEEEPBUgADUU24OhgACCCCAAAIIIEAAynsAAQQQQAABBBBAwFMBAlBPuTkYAggggAACCCCAAAEo7wEEEEAAAQQQQAABTwUIQD3l5mAIIIAAAggggAACBKC8BxBAAAEEEEAAAQQ8FSAA9ZSbgyGAAAIIIIAAAggQgPIeQAABBBBAAAEEEPBUgADUU24OhgACCCCAAAIIIEAAynsAAQQQQAABBBBAwFMBAlBPuTkYAggggAACCCCAAAEo7wEEEEAAAQQQQAABTwUIQD3l5mAIIIAAAggggAACBKC8BxBAAAEEEEAAAQQ8FSAA9ZSbgyGAAAIIIIAAAggQgPIeQAABBBBAAAEEEPBUgADUU24OhgACCCCAAAIIIEAAynsgqQSmTp1qaWlpSVUnKoMAAggggECyCRCAJtsZTfH61K5d2zp16pTiClQfAQQQQAABfwsUC4UXfxeR0iGAAAIIIIAAAggkkwAtoMl0NqkLAggggAACCCAQAAEC0ACcJIqIAAIIIIAAAggkkwABaDKdTepiS5YssREjRiCBAAIIIIAAAj4WIAD18cmhaAUX2Lp1q6Wnpxf8hbwCAQQQQACBIhLYu3dvER256A7LIKSis+fICCCAAAIIIJDCAhoH3q5dO5sxY4Z99913dthhh6WMBi2gKXOqqSgCCCCAAAII+EngoYcesvHjx5sC0RIlSvipaAkvCy2gCSfmAAgggAACCCCAQFaBTz75xJo3b266/D5p0iS78MILs26Q5I9oAU3yE5xq1duwYYMtXrw41apNfRFAAAEEAiSwevVqu+KKK2zPnj129913p1zwqVNFABqgNyxFzVtg7ty51q9fv7w3ZAsEEEAAAQSKQGD37t3WoUMHW7dunZ1//vk2YMCAIihF0R+SS/BFfw4oQRwFdu3aZdu3b7eyZcvGca/sCgEEEEAAgfgI3HrrrfbEE09Y1apVbf78+Sk18CizIAFoZg3uI4AAAggggAACCRIYO3astW/f3g040sj3Ro0aJehI/t8tl+D9f44oIQIIIIAAAggEXOCHH36wq6++2tXiscceS+ngUwi0gAb8DU3xEUAAAQQQQMDfAtu2bbMGDRq4XJ9XXnmlvfHGG/4usAelowXUA2QO4Z3A1KlTLS0tzbsDciQEEEAAAQTyELj22mtd8PmPf/zDnn/++Ty2To2nCUBT4zynTC1r165tnTp1Spn6UlEEEEAAAX8LPPXUU/bWW29ZmTJlbNy4cXbQQQf5u8AelY5L8B5BcxgEEEAAAQQQSC2BWbNm2XnnnWfK0KIBSG3btk0tgH3UlhbQfeDwFAIIIIAAAgggEIvAb7/9ZpdffrkLPvv06UPwmQ2RFtBsIDxEAAEEEEAAAQQKI6Bk82r5nDlzpp177rmm8QnFixcvzC6T7rW0gCbdKU3tCi1ZssRGjBiR2gjUHgEEEECgSAVuv/12F3xWqVLF9f8k+Mx5OghAc5qwJsACW7dutfT09ADXgKIjgAACCARZ4M033zQNPCpZsqTr91mpUqUgVydhZecSfMJo2TECCCCAAAIIpJLA4sWLXYL5v/76y12N6969eypVv0B1JQAtEBcbI4AAAggggAACOQU2bdpk9evXt+XLl9u//vUve+mll3JuxJoMAQLQDAruIIAAAggggAACBRfYu3evtWrVyiZNmmSnnXaaKf3SAQccUPAdpdAr6AOaQic7Faq6YcMG0yUQFgQQQAABBLwSGDBggAs+K1as6JLNE3zmLU8AmrcRWwRIYO7cudavX78AlZiiIoAAAggEWeD999+3Bx54wKVZ0oxH1atXD3J1PCs7l+A9o+ZAXghotont27db2bJlvTgcx0AAAQQQSGGBH374wRo0aGCbN2+2Rx991JRwniV/AgSg+XNiKwQQQAABBBBAIENgy5YtLvj8/vvv3YxHY8aMyXiOO3kLEIDmbcQWCCCAAAIIIIBAhkAoFLLLLrvM3nvvPatTp46p+9dBBx2U8Tx38hagD2jeRmyBAAIIIIAAAghkCKjPp4LPQw891N59912CzwyZ/N8hAM2/FVsGQEDz7aalpQWgpBQRAQQQQCCIAh988IHdd999tt9++5lmPapVq1YQq1HkZd6/yEtAARCIo0Dt2rWtU6dOcdwju0IAAQQQQOB/Ahp0pO8YXYJ/6KGHrEWLFtDEKEAf0BjheBkCCCCAAAIIpI6ARro3bNjQGHQUn3NOABofR/aCAAIIIIAAAkkqoBbP1q1bmy6/161b1+bMmUO/z0Kea/qAFhKQlyOAAAIIIIBAcgvce++9LvisUKGCG3zEiPfCn28C0MIbsgcfCSxZssRGjBjhoxJRFAQQQACBIAuMGzfOBg8e7GY6Uq7Po48+OsjV8U3ZCUB9cyooSDwEtm7daunp6fHYFftAAAEEEEhxgcWLF1uXLl3coKOhQ4das2bNUlwkftWnD2j8LNkTAggggAACCCSJwIYNG+z000+3n3/+2Tp37myvvvpqktTMH9UgAM12HhYtWuT6eWRbnePh/PnzrV+/fla/fv0cz7ECAQQQQAABBIIrsHv3brvgggvsk08+cdNtzpgxw0qVKhXcCvmw5OQBzXZS9Kbbvn17trU5H37xxRe2evXqnE+wBgEEEEAAAQQCLXDLLbe44PPII490Mx0RfMb/dBKAZjOtV6+e6ZbXMm3aNKtUqVJem/G8xwK6ZKIfBpqblwUBBBBAAIGCCrzwwgv29NNPuxbP8ePHW+XKlQu6C7bPhwCDkPKBxCbBEZg7d67rGhGcElNSBBBAAAG/CMyaNct69erlijNy5Ehr1KiRX4qWdOWgBTTpTmlqV0jTojVp0iS1Eag9AggggECBBVauXGlt27a1nTt32q233upGvxd4J7wg3wIEoPmmYsMgCJQoUcJ0Y0EAAQQQQCC/Atu2bXMzHa1bt87N7/7oo4/m96VsF6MAl+BjhONlCCCAAAIIIBB8AU2zqVyfCxYssNq1a9tbb73lks4Hv2b+rgEBqL/PD6VDAAEEEEAAgQQKDBgwwDTb0SGHHOLSMOp/lsQLEIAm3pgjeCgwdepUS0tL8/CIHAoBBBBAIKgCb7/9tg0aNChjmk21gLJ4I0AA6o0zR/FIQB8enTp18uhoHAYBBBBAIKgC8+bNs65du7riP/bYYy7xfFDrEsRyMwgpiGeNMucqUL16ddONBQEEEEAAgdwE1qxZ4wYdaeKZa6+91m666abcNmV9ggRoAU0QLLtFAAEEEEAAAf8JKOhs3bq1rVq1yqXte+aZZ/xXyBQoEQFoCpxkqogAAggggAAC/xP417/+ZV999ZXVrFnTDT4idV/RvDMIQIvGnaMmSGDJkiU2YsSIBO2d3SKAAAIIBFlg4MCBNmbMGCtbtqwb8V6xYsUgVyfQZScADfTpo/DZBbZu3Wrp6enZV/MYAQQQQCDFBTTiXQFo8eLFXa7PE088McVFirb6DEIqWn+OHmcBzdvL3L1xRmV3CCCAQMAFdMldI96VdF4j3lu2bBnwGgW/+LSABv8cUgMEEEAAAQQQyEVAV8U06EiDj66//npGvOfi5PVqAlCvxTkeAggggAACCHgioG5ZrVq1MqVdatasmf373//25LgcJG8BAtC8jdgiQAIbNmywxYsXB6jEFBUBBBBAIBECe/fudTPjLVy40I477jh75513bP/96XmYCOtY9kkAGosar/GtwNy5c61fv36+LR8FQwABBBDwRqBPnz72/vvvW/ny5W3ChAl26KGHenNgjpIvAX4K5IuJjYIi0KJFC5dYOCjlpZwIIIAAAvEXeO655+zxxx+3kiVL2vjx4+2YY46J/0HYY6EECEALxceL/SaghMIkFfbbWaE8CCCAgHcCH3/8sfXq1csdcOTIkda0aVPvDs6R8i3AJfh8U7EhAggggAACCPhZ4LvvvrN27drZ7t27XXcspV5i8adA0gSgf/31l82bN89+/PFH27Nnjz+1KRUCCCCAAAIIJERg3bp1dvHFF9uff/5p7du3t8GDByfkOOw0PgKBC0CVQPaee+7JUvuHHnrIdTKuX7++1a5d2412mzJlSpZteJAaAlOnTnWjHlOjttQSAQQQQEACf//9t8v1uWLFCmvYsKG9+uqrVqxYMXB8LBC4PqCLFi2y9evXZ5C+/PLL1r9/f5ffq2PHjrZ582Z78803rU2bNjZnzhw75ZRTMrblTvIL6AdIp06dkr+i1BABBBBAwAlodqPOnTvb559/bjVq1HAj30uXLo2OzwUCF4Bm93z++efd1IvqdBxZbr75ZqtXr549+eST9sorr0RW838KCFSvXt10Y0EAAQQQSA0Bpd5Tjs9y5crZxIkTrVKlSqlR8YDXMnCX4LN7b9q0KWqL13XXXWdKPsuCAAIIIIAAAskpoEaoRx55xGU/GTdunJ144onJWdEkrFUgA1DN57pr1y53OjS/66pVq3KcGg1IqlixYo71rEAAAQQQQACB4At89NFH1rNnT1eRZ5991nXFC36tUqcGgQtA1an4008/tTJlyliDBg3cyPdhw4bZN998487ar7/+aj169LDXX3/dLr/88tQ5k9TUCSxZssRGjBiBBgIIIIBAEgvoOz+Sbumuu+6yq6++Oolrm5xVC1wAqtkN9MbTr50zzjjDduzY4eZ2Xb58uTtD6v+h53QJ/pprrknOs0atchXYunWrpaen5/o8TyCAAAIIBFtAn/FqgNLn/ZVXXmn3339/sCuUoqUvFh49FkqGuivp7P7772+rV6+2vXv3WtWqVRNaLQW/TzzxhBsAldADsXMEEEAAAQQQcAJbtmyxxo0bmzLiHHbYYa7BoVSpUugEUCDQo+DVD3TNmjUu6ewBBxzgcoFWrlw5gKeBIiOAAAIIIIDAvgTU0KQE8wo+jzvuOJdqkeBzX2L+fi5wl+DFqVkO1Ox+yCGHuJQ7devWdQnoNeioWrVqNmjQIGZD8vf7jtIhgAACCCBQIIHu3bubBh4pzdLkyZNdo1OBdsDGvhIIXAuoRrw3a9bMBZjK97lz504bO3asHXPMMW40nPqHvvDCC/bhhx+6ZLSMhPfV+y3hhdmwYYPrhlGnTp2EH4sDIIAAAgh4I6B+ni+++KIdeOCB9sEHH9jRRx/tzYE5SsIEAtcCqtHtutyuOd81z+uQIUNs2bJlptHPmg9erZ/ffvutC0w1IxJLagnMnTvXlJSYBQEEEEAgOQRee+01u/fee6148eJupkMNQGIJvkDgAlA1v2vKrcxLiRIlXMql//znP261UjR169bNtYBm3o77yS/QokULe+ONN5K/otQQAQQQSAEBzXJ47bXXupoq5eIll1ySArVOjSoGLgDVVFua7SD7ojepRr9HFqVpKF++fOQh/6eIgH6MlC1bNkVqSzURQACB5BXQbIZt27Z1E8/07ds3I+l88tY4tWoWuABUrZ9z5sxxI+Hee+89U+CpAUnfffedawVVn9B77rnHzQPfoUOH1Dqb1BYBBBBAAIEkEFi5cqVddNFFtnnzZvcd//DDDydBrahCZoHADUK67LLLXL9PBZkafKSlZMmS9sADD7gAVP1AR40aZUOHDqWpPvOZ5j4CCCCAAAIBENi4caO1bNnSDSg999xz7ZVXXjHNgsiSXAKBTUT/xx9/2OLFi91oeKVhyjzaPZKUPpGnikT0idSNfd9Tp051H1ajR4+OfSe8EgEEEECgSAQ0u2Hz5s1t5syZdtJJJ9msWbNMXe9Ykk8gcC2gkVOg/p1NmjSJ+qtIMyJt377dbVq6dOnIS/g/BQRq165tnTp1SoGaUkUEEEAguQQ0jiMtLc0Fn5rNULk+CT6T6xxnrk3g+oCq8ErJoBxgSseklsjZs2dnrpO737FjR+vSpUuO9axIboHq1au7SzfJXUtqhwACCCSfgHJ7a5CxJplRLu9ET6mdfILBqlHgAlBdYlVgqUCjT58+tn79etcS+vTTTwdLntIigAACCCCAgBPQIKPhw4ebptZUSsV//OMfyCS5QOAuwY8cOdKU61G/jrRodoT77rvPbrjhBlP+T1o9k/wdS/UQQAABBJJK4NVXX3UTiOy3335uELG617Ekv0DgAtBffvklS5CpkXGRud+vu+46q1Klip1//vnJf+aoYVQBzYilzus9evSI+jwrEUAAAQT8I6B+npFE80899ZS1a9fOP4WjJAkVCFwAWrlyZZs+fbr17t07C4ym5VTyeb15Z8yYkeW5gjzQXOI///xzni/ZunVrxkCnPDdmA88EdF70PmBBAAEEEPC3wJdffulyeitzjaZQzv697u/SU7rCCgQuANXgIo1yVmtnz5497dRTT80weOmll1wA2rRpU6tQoYLVq1cv47n83lGSe7Wo5rUoSF29enVem/G8xwKNGjUy3VgQQAABBPwr8MMPP9jFF19s27Zts3/961/24IMP+rewlCwhAoELQDW70bJly0wtnurzmTkAVfqlMWPGWPfu3V0uyFgC0FatWplueS0afV+rVq28NuN5BBBAAAEEEMgkoMYbjeX4/fffXRD63HPPZXqWu6kiENhE9H///bdt2rTJjjjiiKjn6osvvrC1a9cmbDYkEtFHZWclAggggAACuQroe1uDjDSRjL5HNZ32gQcemOv2PJG8AoFrAY2cCuUAVfAZCoXcr6jixYubktNHloYNG0bu8n8KCagPr35d16lTJ4VqTVURQAAB/wtoghhdYVTweeKJJ9qECRMIPv1/2hJWwsDlAZXEqlWr7I477rAaNWq4eeArVark+nxqxoSTTz7ZbrvtNtNgFJbUE5g7d67rzJ56NafGCCCAgH8FNNBIXeg0teZRRx1lH330UZZGI/+WnJIlSiBwLaBKw9S4cWM3BWf79u2tZs2a7k2sdEyaH16Dg8aOHetmU5g2bRr9NBP1zvHpftWviBxyPj05FAsBBFJSQFcqNXD4gw8+cI1FU6ZMYZajlHwnZK104ALQIUOGuJZP9RvRjAnRFo2ma9mypZuyc+DAgdE2YV2SCpQoUcJ0Y0EAAQQQ8IdA37593cDggw46yCZNmmTHH3+8PwpGKYpUIHCX4BcsWGCdO3fONfiUpgKQrl27ZsyWVKTCHBwBBBBAAIEUFXjkkUds6NChrrvc+PHjrUGDBikqQbWzCwQuAD3zzDNt9uzZ2euR47GS1WtWJBYEEEAAAQQQ8F7ghRdesDvvvNM0xeZrr71mF1xwgfeF4Ii+FQjcJXglolcQqhRLaWlpro+nks7rDa4+oCtWrLDRo0e7Zn5dpmdJLYGpU6e6Sz16D7AggAACCBSNwLhx41xObh396aefdgOQiqYkHNWvAoELQE855RRbtGiRdevWzc0Jv3fv3hy2mgtenZw1IxJLagnUrl3bzZSVWrWmtggggIB/BNT4o8aiPXv22P333289evTwT+EoiW8EAheASu6YY44xjXDfuXOnrVy50rV67tq1yzRPfNWqVd0oO98IUxBPBapXr266sSCAAAIIeC+gSWDatGnjvp9vueUWu/vuu70vBEcMhEAgA9CIbMmSJV0wqoA0+7JlyxbT1JylS5fO/hSPEUAAAQQQQCDOAkuWLHEZaDS/uwYCP/bYY3E+ArtLJoHADULKL361atXcJfr8bs92CCCAAAIIIBCbwPLly90go40bN9qll15qGoCk/NwsCOQmkLQB6A033OCm/Mqt4qxPTgH9Ah8xYkRyVo5aIYAAAj4U0OyEzZs3tzVr1lizZs3szTffNE2PzYLAvgQCfQl+XxUbNGjQvp7muSQV0BSs6enpSVo7qoUAAgj4S+D33393wadmIWzUqJH95z//2Weebn+VntIUpUDgA1BN8aU/AP3aKl++fFFacmwfCOgDUDcWBBBAAIHECmzevNk0/fHSpUutbt26Lv2hZjtiQSA/AoG8BK/m/jvuuMNNyamBSJUqVXIj38uVK2cnn3yy3XbbbaaWMBYEEEAAAQQQiL/AX3/9ZRdffLHNnz/fjj32WJf68NBDD43/gdhj0goErgX0l19+scaNG7vOze3bt7eaNWu6lk91dlYiel0GGDt2rCkJrlI11apVK2lPHhVDAAEEEEDAawGlQNRAo1mzZtlRRx1lyvt5+OGHe10MjhdwgcAFoEOGDHEtn3rDlypVKir/gw8+6FJBaOqvgQMHRt2GlckpsGHDBlu9erXVqVMnOStIrRBAAIEiFNi9e7eb1UiTvSjoVEOPss6wIFBQgcBdgl+wYIF17tw51+BTACVKlHA5yD788MOCerB9wAXmzp1r/fr1C3gtKD4CCCDgPwHNPNilSxd777333JVHTX2sy+8sCMQiELgAVPPAz549O8+6Tp8+3apUqZLndmyQXALqEP/GG28kV6WoDQIIIFDEAhrwqymw9flapkwZUwMPV5qK+KQE/PCBuwSv+WUVhK5du9bS0tJcH88KFSrYfvvt5/qArlixwkaPHu1G4+kyPUtqCaj1WzcWBBBAAIH4Cdx8880uufyBBx5oEydOtNNPPz1+O2dPKSkQuAD0lFNOsUWLFrlfYroUoEsC2Zfzzz/fjchr2rRp9qd4jAACCCCAAAIFEFC3pmHDhrmub7r8fvbZZxfg1WyKQHSBwAWgqobmflfHZ43EW7lypanVc9euXVa5cmWrWrWqS8kUvbqsRQABBBBAAIH8CmhSl4cffthdWXrnnXdc0vn8vpbtENiXQCAD0EiFlANUwahuLAhIQJ3iX3nlFdcNAxEEEEAAgdgFlHXmvvvucxO9qGtbq1atYt8Zr0Qgm0DgBiFlKz8PEcgiULt2bevUqVOWdTxAAAEEECiYgC659+3b142vePnll015t1kQiKdAoFtA4wnBvpJDoHr16qYbCwIIIIBAbAIjR460m266yU34ovtXXXVVbDviVQjsQ4AW0H3g8BQCCCCAAAKpJKDWzh49ergqDx8+3K699tpUqj519VCAANRDbA6FAAIIIICAXwVGjRrlAk7l/Hz88cetV69efi0q5UoCAQLQJDiJVOH/BJYsWWIjRoz4vxXcQwABBBDIU+Ctt95yMwgqtaFGvd9yyy15voYNECiMQNQA9LPPPrP7778/y343btxo69aty7Ju8uTJprycLAj4RWDr1q2Wnp7ul+JQDgQQQMD3AkqvpMGbe/bscd/9d9xxh+/LTAGDLxA1AP36669ztCL179/fLr/88iw13rRpky1cuDDLOh4gUJQCjRo1sgcffLAoi8CxEUAAgcAIjB8/3jTDoILPe++91+6+++7AlJ2CBlsgagAa7CpRegQQQAABBBDIS0CzGl1xxRW2e/duUyPTwIED83oJzyMQNwEC0LhRsiMEEEAAAQSCIfD++++7q5qaRVCX3AcPHhyMglPKpBEgAE2aU0lFJLBhwwZbvHgxGAgggAACuQh88MEHLrG8gs8+ffq4QUe5bMpqBBImQACaMFp2XBQCc+fOtX79+hXFoTkmAggg4HsBBZ/t2rWznTt32m233WaPPvqo78tMAZNTgJmQkvO8pmytWrRoYU2aNEnZ+lNxBBBAIDeBd9991/X5jASfQ4cOzW1T1iOQcIFcA9Dff//dNKI4svz888/2999/Z1mny50sCPhJoESJEqYbCwIIIIDA/wk888wzGYnl1fJJ8Pl/NtwrGoGoAWi1atWsadOmWUpUt27dLI/1oEyZMlajRo0c61mBAAIIIIAAAv4Q+M9//uPmdldpzjvvPIJPf5yWlC9F1AC0ffv2roNyyusAgAACCCCAQIAFlOczkmpJA47o8xngk5lkRWcQUpKd0FSvztSpUy0tLS3VGag/AgggYGPHjrUOHTpYJNUSwSdvCj8J7DMAXbNmjU2cODGjvJopQf1GmjVrZtdee63NmTMn4znuIOAHgdq1a7sp5fxQFsqAAAIIFJWA5na/8sorM5LMa353FgT8JJBrAPrKK69YlSpVXJqGSIHvvPNO69u3r/s19fnnn9v5559vmraTBQG/CFSvXt1atmzpl+JQDgQQQMBzgVGjRrkf4prhSNNrkmTe81PAAfMhEDUA/eGHH6x79+4uV5g6L2tZunSpa/3s2bOnzZgxwyX7bty4sdsuH8dhEwQQQAABBBBIsMDLL79sXbp0cXO7Dxo0iOk1E+zN7mMXiBqAfvLJJ+7N++KLL9pxxx3n9h4JRNUKqqVYsWLWrVs3W7RokUvP5FbyDwIIIIAAAggUicDIkSPtmmuusb1797rZje65554iKQcHRSA/AlEDUE1lePrpp7s0S5GdKChVMFq1atXIKlO6JnVuTk9Pz1gX9DtvvPGGVahQIc/bV1995VqFg17fZCv/kiVLbMSIEclWLeqDAAII7FNg2LBh7opkKBSyxx9/3M3vvs8X8CQCRSwQNQ3TIYccYqtXr84omhLQz5w5066++uqMdbrz/fffu6Tf6neXLIumKLvwwgvzrI5m3NGAFxZ/CWzdujWpfhD5S5fSIICAHwU0uv2OO+5wVyaHDx+ekXDej2WlTAhEBKIGoKeccoo9+OCDrp9nnTp1XCqH7du3W6tWrSKvM/3KUkdnBWElS5bMWB/0O6pL+fLl86zG/vvvb8WLF89zOzbwVkCzd2Wewcvbo3M0BBBAwFuBgQMH2oABA2y//faz5557zl2C97YEHA2B2ASiBqBt2rSxs846y12G10Cjzz77zI14b968uTuK0i/pV5ZyLirVAwsCCCCAAAIIeCugVk+1fqoxRJlrOnXq5G0BOBoChRCI2gdUc2mPGzfOTd2lls/evXu7x/qFpeWuu+6y6dOn22OPPWaXX355IQ7PSxFAAAEEEECgIAK6AnnDDTe44FPf12oIIvgsiCDb+kEgaguoCnb44YfbI488ErWM+qV11FFHuSb/qBuwEoEiEtiwYYPrv6yuIywIIIBAsglohPt1111nL730kpUqVcp1kfvnP/+ZbNWkPikgEDUA3bJli23cuDHX6isF06+//prxvEbDsyDgB4G5c+fas88+axMmTPBDcSgDAgggEDcBZZ256qqrbMyYMXbQQQeZ0iNqZkIWBIIoEDUAVUfm22+/Pd/10eUAFgT8IKDsBE2aNPFDUSgDAgggEDcBZaNp3769+3Fdrlw5N022xmqwIBBUgagBaKSvp97kl156qfuFpX4mLAj4XUDvU96rfj9LlA8BBAoioPRyrVu3dmMvKlasaB999JHVq1evILtgWwR8JxA1AL3pppvcm1sdm8eOHet+aemX15VXXulGx+sSPAsCCCCAAAIIJFZA3eFatmxpX3zxhVWuXNllnznxxBMTe1D2joAHAlFHwasFtGnTpm5GmTVr1thrr71m27ZtM3V0VtL5Pn362Pz58z0oHodAAAEEEEAgNQV+++03912s4PPoo492E8IQfKbmeyEZax01AM1cUSVc18xAGvm+du1a03RfmnpT/ew0NacS4LIg4BcB5aZNS0vzS3EoBwIIIBCTwIoVK+zss892E8KccMIJLvisWbNmTPviRQj4USDPADRzoZXyQUnqH374YTftl0bCaxYGFgT8IqCZuciH55ezQTkQQCAWgaVLl5omgfnvf/9rp512ms2YMcOqVKkSy654DQK+FYjaBzRaafVr7J133nG3r776yuUB7dGjh3Xo0CHa5qxDoEgE1EVENxYEEEAgiAL6flWfT+U0Vle4Dz74wMqUKRPEqlBmBPYpsM8A9JdffnEB59tvv236ozjyyCNdGognn3zSzjjjDGMw0j5teRIBBBBAAIF8C2iGQY1216j3Vq1amb57DzjggHy/ng0RCJJA1ABUc7/37dvXvvzyS6tUqZK1bdvWhgwZ4vqjRFI0BamSlBUBBBBAAAE/C4wfP946duxoO3bscMnmNdORxmCwIJCsAlHf3V9//bULPo844gg32OjPP/80JafXLdoyevToaKtZh4DnAkuWLHGd9dU9hAUBBBAIgsALL7xg3bt3tz179pjSID7xxBNcYQzCiaOMhRKIGoAedthhdsopp7gdL1u2rFAH4MUIeCmgS1fK0sCCAAIIBEHgoYcesv79+7ui3n///Xb33XcHodiUEYFCCxQLT6PJPJoxMKoPrH6lNmrUKIZX8xIEEEAAgVQW0FfvrbfeahpToa5t//73v10raCqbUPfUEojaAppaBNQWAQQQQAAB7wR27dplXbt2tTfeeMNKlixp6sbWrl077wrAkRDwgUCB8oCqvJoN6ZFHHvFB0SkCAggggAACwRJQNyF9jyr4VHqlyZMnE3wG6xRS2jgJFDgA/fHHH03Tc7Ig4EcB5c5bvHixH4tGmRBAIMUF1q9fb+eee65NmTLFDj/8cFPGmfPOOy/FVah+qgoUOABNVSjqHQyBuXPnWr9+/YJRWEqJAAIpI/DTTz/ZmWeeacoyU6tWLZs9e7adeuqpKVN/KopAdoGk6QP6119/maYvK1u2rGm+3OLFi2evK49TQKBFixYudVgKVJUqIoBAQATmz59vF110ka1du9ZNrTlp0iSXYzsgxaeYCCREIGoLqGY9Uj7FaMuNN97o/pCiPefFuscee8zuueeeLIdSGovy5ctb/fr1TXOBH3fcce4SR5aNeJASAiVKlHA/QlKislQSAQR8L6DL7ZpSU8HnBRdcYJ9++inBp+/PGgX0QiBqADpjxgyrU6eOSzH04osvumnBIoXp1auX+yOKPPb6/0WLFtm8efMyDvvyyy+7HGqNGzc2lVWpkSpUqGBt2rSxBQsWZGzHHQQQQAABBLwUeO2119yAIw086tSpk02YMMEOPvhgL4vAsRDwrUDUALRnz54uLUS5cuXs+uuvd3PAX3fddfbFF1/4riLPP/+8C5Q//vhju/rqq+3mm2925Tz++ONdfjXfFZgCIYAAAggkvcDgwYOtS5cuppRLd9xxhykY1RUaFgQQ+J9A1AC0dOnSbk7ajz76yFauXGl33XWXzZo1ywV6devWtWHDhtkff/zhC8NNmza5X5bZC6OAeeHChdlX8zjJBaZOnWppaWlJXkuqhwACfhXQdJrdunVzMxopwfzTTz9tDz/8MFNr+vWEUa4iE4gagGYuTZUqVezOO+90A3zUAnr22WfbgAEDrHLlyi5InT59eubNPbm/fft296tSB2vdurWtWrUqx3F1mb5ixYo51rMiuQXUB1iXulgQQAABrwW2bdvmvpOee+45U0POuHHjTN3WWBBAIKdAngFo5pc0aNDATRf222+/2dtvv+0GKjVr1izzJgm/X6xYMdeJWwl8VR4FmmqR/eabb9yxf/31V+vRo4e9/vrrdvnllye8PBzAXwLVq1e3li1b+qtQlAYBBJJeQN+LGmw0ceJE1/ihxhmNRWBBAIHoAgUKQLULpZNQi2jv3r1dq6jXf2D6Zalg89lnnzXNx75jxw7bf//9bfny5a6G+uPXc7oEf80110SvNWsRQAABBBCIk4BSADZq1Mg1iBxzzDGmfMR6zIIAArkLFAuFl9yf/t8zP//8s5s2bNSoUfb999+7NEcK7jp37uxmc8jr9V48v3v3bheIrl692vbu3WtVq1ZN6GEV/GrEPR8yCWVm5wgggICvBT755BO77LLLTOMR9L3w/vvv0/3L12eMwvlFINdE9JrS8J133jEFnXPmzLEDDzzQ2rdvbxp1rpRHflvUCqrAU/1DdRmWJTUFlL925syZrhtGagpQawQQ8EpAI9t1tW3nzp3Wtm1b1/VLfT9ZEEAgb4Gol+BHjx7tUi+pL6VSSIwcOdLN/66cm34IPhVkdO/e3aVd0ly6WpSg/ogjjjBd/jj00ENNl+pZUk9A+fbS09NTr+LUGAEEPBW47777XJolBZ+33Xaba7Ah+PT0FHCwgAtEbQHVH5RG7uky+0knneSrKir4PP30061kyZLuMsdbb71lTz31lBuZf8UVV5gGRanlVsHz0Ucfbc2bN/dV+SlMYgXUJYJuEYk1Zu8IpLKAxh3ou1ENNZryefjw4VxxSeU3BHWPWSBffUBj3nsCXqgUOz/99JMp36O6BfTt29eGDh1q+jU6IJweKrJcfPHFLkh99913I6vi+j99QOPKyc4QQAAB3wv8/vvvdumll7q82MrEMmbMGLJu+P6sUUC/CkS9BB8p7ObNm93l98jjyP/q8/Loo4/aX3/9FVnl2f/Lli1z+UcPOuggl9j3qquucsdW/9TMS7t27Vygmnkd9xFAAAEEEIhFQANwdXVFk7IcddRR7n9SvsUiyWsQ+J9ArgGoWhh1+V2zIGUfKP/ll1+6qcXOOecc02AlLxclwM+c/D5y/9NPP81SDF2qT/RI+CwH5IEvBPR+XLx4sS/KQiEQQCA5BKZNm+ZGuCvdX/369d10z5oVkAUBBGIXiBqAKpXRJZdc4gb0fP755zmmEPv6669dvxflPrv77rtjP3oMr9TgI11WVz9Q/frUJfhbb73VNO+u+oJ+++237pK87qtPKEtqCSj/Xr9+/VKr0tQWAQQSJqC80hdeeKFLs6R0Sxr4euSRRybseOwYgVQRiDoISZ2rlVdz/Pjxdsghh+SwKFGihEtEr2DvpZdecsGo0iB5seiDQLMwKcD8888/3Wj3rl272tq1a+2WW25xrbWaLUn3I5fnvSgXx/CHQIsWLaxJkyb+KAylQACBwApoTveLLrrIpkyZ4uqgCVgefPDBHA0yga0gBUegiAWiDkLq1q2bSzgfSXGUWxl12fvcc8+1H3/80bWW5radV+vXrFnjZmpS14FE5wJlEJJXZ5XjIIAAAt4KaPyDrqBNnjzZHVhd0R544AFvC8HREEhygajNljVq1LAZM2bkWXX1DVVraFFdjtDx1doZWVQOjX7XooT0WsjL5hj4BwEEEEAgHwLKstKqVSv77rvv7LDDDnNXAv2Q/zofRWcTBAIlELUPqAYXacTfihUr9lmZDz/80HXI1oh0LxfNPqEcnwcccIDrGD579uwch+/YsaNLEpzjCVYggAACCCAQRUBX9Ro0aOCCT11J04Bbgs8oUKxCIA4CUQNQjfJTmgldgtA88NGWESNGuLnQzz///GhPJ2ydRud36dLFXWLv06ePrV+/3vX5e/rppxN2THYcHAG9P9LS0oJTYEqKAAK+ENBgI01cokwa//znP90U1LoayIIAAokRiHoJXpfVdQleswqdeuqpbkT8iSeeaEq8q5Hv33zzjfvj1Ij0e+65JzEly2WvmhZUA03U+qrl/vvvd0nob7jhBlc+BacsqStQu3Zt02QFLAgggEB+BDTg9qabbrJnnnnGba7MKg899JDtt1/U9pn87JJtEEAgHwJRA1C9LtIPVDMMKbXNqFGj3AjzcuXKuaBUo9//9a9/5eMQ8d3kl19+yXJpXX1ABw0aZBqxqAT5VapUMa9bZeNbQ/ZWGAENPkv0ALTClI/XIoCAfwQ0s5EmMdGld3Xpev755/kB65/TQ0mSXCDXAFT1VjD3wgsvOAKlPNKlCfW9zDzwx2ufSCL63r17Zzm08oCmp6ebZkDKzwCqLC/O9EAj/9XKmteikf86HvOO5yXF8wgggID/BBYtWmStW7d2Yx30vaL80ur/yYIAAt4I7DMAzVwEtXzqVtSLBhfpEqtaO3v27OlaYyNlUqusAtCmTZtahQoVrF69epGn8v1/tWrV3AjIvF7w1VdfWdmyZfPajOcRQAABBHwm8M4777greNu2bbOGDRu64LOosrn4jIbiIOCZQL4DUM9KlMeBOnToYJoPXi2e6pOqPqqRRcnwx4wZY+qb+sorr8QUgKqFV7e8lmHDhvkiIM+rnKn2vKZgnTlzpvXo0SPVqk59EUAgD4G9e/e6cQtKKK9FYwZ0xatUqVJ5vJKnEUAg3gKBC0AFoIFPGgG/adMm1y9V/XiKFy9u5cuXdx8kL7/8sgtCNTsSS2oJbN261XWNSK1aU1sEEMhLQN8XypAxadIkU2PF0KFD3eCjvF7H8wggkBiBQAagq1atMrVAqrVT9zWKUYsuiWvwlAYhDRw40F1aSQwbe/WrgPrk0i/Xr2eHciFQNAKaNrpNmzb23//+1ypWrOimc9YsfiwIIFB0AoELQDUKXomBNRBKoxdr1qzpWj71+I8//nB5S8eOHWvjxo2zadOmWa1atYpOlyMjgAACCBSpgL4PlLFFV0fUZUuDjciUUaSnhIMj4AQCF4AOGTLEtXJ+/PHHufbbUf+eli1bmmZMUksoCwIIIIBAagkoNV///v3t0UcfdRXX4NXnnnuO6ZlT621AbX0sELhMuwsWLLDOnTvnGnzKWon0u3btmpGs3sf+FC3OAkoVtnjx4jjvld0hgECQBDQuQBOWKPhUf8+nnnrKXn/9dYLPIJ1Eypr0AoELQM8880yLNvd79jM1ffp0l8c0+3oeJ7eAJk3o169fcleS2iGAQK4CSpF32mmnuS5Yhx9+uOm74MYbb8x1e55AAIGiEQjcJXjlAVUQqhHuGtGoPp7K+alp09QHdMWKFTZ69Gg30lGX6VlSS0CtHk2aNEmtSlNbBBBwArrErmBzx44d7ntC+T6VZJ4FAQT8JxC4APSUU04xzWDRrVs3l8NNed2yLxoFP2XKFJeQPvtzPE5uAXW/0I0FAQRSR2D79u1uYhLlf9aimfIef/xxPgucBv8g4E+BwAWgYjzmmGPc5ZWdO3faypUrXavnrl273C/dqlWruhZRf3JTKgQQQACBeAootZJmwFu4cKEdeOCBbqCRro6xIICAvwUCGYBGSEuWLOmCUQWkLAgggAACqSWglEpKsfTnn39a7dq1Xfq9k046KbUQqC0CARUI3CCk/Dpv2bLFdFmGJbUEpk6d6voGp1atqS0CqSWgyUduu+02u+yyy1zwqRbQr7/+2gg+U+t9QG2DLZC0AWi1atVcH9Fgnx5KX1ABtYIo3x8LAggkp8Cvv/7q+vdH+ng+8cQTpsFGZcqUSc4KUysEklQg0Jfg93VObrjhBjv22GP3tQnPJaGAZjhhlpMkPLFUCYGwwIcffmhXXXWVKc/nUUcd5aZjPuOMM7BBAIEACiRtADpo0KAAng6KjAACCCCQXUCzGt1zzz328MMPWygUcjPdKbG8UvCxIIBAMAUCH4Dqw0i/hosXL+7mhA/maaDUCCCAAALRBHTJ/corr7RZs2a5z/n777/f7rzzTitWrFi0zVmHAAIBEQhkH9BVq1bZHXfc4eaE10j4SpUquV/C5cqVs5NPPtl1Tt+6dWtATgHFjKfAkiVLbMSIEfHcJftCAIEiEpg4caIp97OCzypVqtgnn3ziZjoj+CyiE8JhEYijQOBaQH/55Rdr3Lix+/Xbvn17q1mzpmv51AeSZkL6+eefbezYsS4dx7Rp09xMSXH0Ylc+F9APj/T0dJ+XkuIhgMC+BJTXWVPqaqBR5JL7a6+9ZhUrVtzXy3gOAQQCJFAs/McdClB53QwXSjisaTZLlSoVtej68GrZsqWdddZZNnDgwKjbFHalOr5r9GWjRo0KuytejwACCCDw/wV++uknu+KKK0xzumtWs8GDB9vtt9/OJXfeIQgkmUDgLsEvWLDAOnfunGvwqfOjD62uXbu6EZNJdr6oDgIIIJC0Am+++aadeuqpLvisUaOGzZw50/r06UPwmbRnnIqlskDgAtAzzzzTZs+enec5mz59uuszlOeGbIAAAgggUKQC27ZtczMadezY0TZv3mzqXqXGhoYNGxZpuTg4AggkTiBwfUD1AaUgdO3atW7Gm1q1arkBSPvtt5/rA7pixQobPXq0TZo0yV2mTxwde/ajwIYNG2z16tVWp04dPxaPMiGAQDaBefPmmT7Xly1b5uZyf/LJJ+26667LthUPEUAg2QQCF4BqROSiRYusW7dubqajvXv35jgn559/vk2ZMsXNlpHjSVYktcDcuXPt2WeftQkTJiR1PakcAkEX0PCDoUOH2l133WXqt1+3bl1766237IQTTgh61Sg/AgjkQyBwAajqdMwxx5hGuO/cudNWrlxpavXUB1jlypWtatWqJCfOx4lP1k1atGhhTZo0SdbqUS8EkkJAVynUl1+f41puvPFGe/TRR/fZtz8pKk4lEEAgQyCQAWik9MoBqmBUNxYEJKABaLqxIICAPwXGjx9v119/vam7jHI4v/zyy3bRRRf5s7CUCgEEEiYQuEFICZNgxwgggAACCRNQjt5rrrnG2rZt64JPBZ2LFy8m+EyYODtGwN8CBKD+Pj+UDgEEEAi8gPpmq//+Sy+9ZKVLl7ann37aNMuRWkBZEEAgNQUIQFPzvCdtradOneqyIyRtBakYAgESUN/8e+65x84++2xbvny5y/GpUe+9evUKUC0oKgIIJEIg0H1AEwHCPoMtULt2bevUqVOwK0HpEUgCgaVLl7q/xfnz55vS5N155502aNAg+mgnwbmlCgjEQ4AANB6K7MM3AtWrVzfdWBBAoGgElF5JuTz79+9vf//9tx199NGmedwbN25cNAXiqAgg4EsBAlBfnhYKhQACCARPQCnxzjrrLDcZhEqvQUcKRg8++ODgVYYSI4BAQgXoA5pQXnaOAAIIpIbA888/72YgU47P4sWLm+Z1f+GFFwg+U+P0U0sECixAAFpgMl7gZ4ElS5bYiBEj/FxEyoZAUgn8+uuvduGFF7rcnkq1dPnll7upkq+44oqkqieVQQCB+AoQgMbXk70VsYC+ANPT04u4FBwegdQQUBL5k046yT766CM3A52m0hwzZgyz0aXG6aeWCBRKgD6gheLjxX4TaNSokenGggACiRNQq6dmM5o8ebI7SOvWrW3kyJF2+OGHJ+6g7BkBBJJKgBbQpDqdVAYBBBBIrMCLL77oWj0VfJYvX95GjRpl7733HsFnYtnZOwJJJ0ALaNKdUiqEAAIIxF9AI9zV6qnJHrS0adPG9bc+4ogj4n8w9ogAAkkvQAto0p/i1Krghg0b3PzSqVVraotA4gT27t1rw4cPdyPcFXxWrFjRjXB/9913jeAzce7sGYFkFyAATfYznGL105zT/fr1S7FaU10EEiOg2Yw0jeaNN95oGuDXoUMH++6774wR7onxZq8IpJIAl+BT6WynQF1btGhhTZo0SYGaUkUEEiegOdwffvhhGzx4sO3YscMqV65szzzzjGmwEQsCCCAQDwEC0Hgosg/fCJQoUYK5pn1zNihIEAV0FeG6666zb7/91ooVK+buDxkyxMqVKxfE6lBmBBDwqQCX4H16YigWAggg4KXA5s2brVevXm7OdgWftWvXtk8++cSee+45gk8vTwTHQiBFBAhAU+REU00EEEAgN4Fx48bZCSec4C6zaxrNu+66yxYuXGhNmzbN7SWsRwABBAolQABaKD5e7DcBjdJNS0vzW7EoDwK+FPjll1+sVatW1q5dO9Mc7meeeabNnz/fHnjgATvggAN8WWYKhQACySFAH9Bs53H58uU2e/bsbGtzPly/fr1t2rQp5xOsKVIBXTbs1KlTkZaBgyPgdwENMnriiSds4MCB9tdff9khhxxiDz30kHXr1s31+/R7+SkfAggEX4AANNs5VCvAtGnTsq3N+fDPP/90aUlyPsOaohSoXr266caCAALRBWbOnGk9evRwg4y0xZVXXmmPP/44OT2jc7EWAQQSJEAAmg1WOe90y2s544wzrGrVqnltxvMIIICALwTWrVtnffr0sddee82V59hjj7V///vf1rx5c1+Uj0IggEBqCdAHNLXON7VFAIEUE9izZ48LNI877jgXfKpvpy69L168mOAzxd4LVBcBPwkQgPrpbFCWQgssWbLEzU9d6B2xAwSSQGDOnDlWv3596927t+uzftFFF7lL7/fee6+VKlUqCWpIFRBAIKgCBKBBPXOUO6qApgtMT0+P+hwrEUgVgd9++826dOnicnouWLDAatSoYe+9955NnDjRatasmSoM1BMBBHwsQB9QH58cilZwgUaNGpluLAikooBGtz/11FM2aNAg27Jli0ul1LdvX7vzzjutdOnSqUhCnRFAwKcCBKA+PTEUCwEEECiIwKRJk+yWW26xZcuWuZdp3nalWjr66KMLshu2RQABBDwRIAD1hJmDIIAAAokR+OGHH1zgOXnyZHeA448/3p588klr0aJFYg7IXhFAAIE4CNAHNA6I7MI/Ahs2bHCje/1TIkqCQGIENm7caDfffLPVqVPHFHyWK1fO5fNctGgRwWdiyNkrAgjEUYAANI6Y7KroBebOnWv9+vUr+oJQAgQSJLB7924bPny4HXPMMa6/5969e90MRj/++KNrCS1RokSCjsxuEUAAgfgJcAk+fpbsyQcCuuzYpEkTH5SEIiAQf4H333/fNKhIl921NGvWzLV61q1bN/4HY48IIIBAAgUIQBOIy669F1DrDy1A3rtzxMQKzJs3z26//Xb79NNP3YGUVH7IkCHWqlWrxB7R4plaAAAsHElEQVSYvSOAAAIJEuASfIJg2S0CCCBQWIEVK1ZYp06d7PTTT3fBZ4UKFWzYsGGmCRcIPgury+sRQKAoBWgBLUp9jo0AAghEEfjjjz9s8ODBbgrNHTt2uHyeN954o/Xv398NNoryElYhgAACgRKgBTRQp4vC5iUwdepUS0tLy2sznkfAlwLbt2+3hx9+2M1W9Pjjj9vOnTvtqquucn0+H3nkEYJPX541CoUAArEI0AIaixqv8a1A7dq13SVL3xaQgiEQRUAj21988UU3g9Hq1avdFhdccIEp6DzllFOivIJVCCCAQLAFCECDff4ofTaB6tWrm24sCARBIBQK2ZtvvmlXX3216VK7lvr167vA87zzzgtCFSgjAgggEJMAl+BjYuNFCCCAQOEElFJJrZvqMqLg88ADD7R33nnHvvrqKyP4LJwtr0YAAf8LEID6/xxRQgQQSCKBKVOmWMOGDU1ztWvWomrVqrnL75s3b7Z27dolUU2pCgIIIJC7AAFo7jY8E0ABpacZMWJEAEtOkZNd4JNPPrGzzz7bTZP55Zdf2uGHH+5mMlq2bJm7BF+8ePFkJ6B+CCCAQIYAfUAzKLiTDAJbt2619PT0ZKgKdUgSgc8++8wGDBiQkUReuTw1m1Hv3r3dZfckqSbVQAABBAokQABaIC429rtAo0aNTDcWBIpaQLMWDRw4MCPwPPTQQ+22224z5fMsU6ZMUReP4yOAAAJFKpA0Aehff/1lS5cutbJly7ocelzOKtL3FQdHIGUFlIv2/vvvt5kzZzoDBZ633HKL3XTTTe7zKWVhqDgCCCCQSSBwfUAfe+wxu+eeezJVweyhhx6y8uXLu/QlygOpeZLV0Z8FAQQQ8EpgwoQJrvVd+TsVfOozSYGoptPUZ5Z+HLMggAACCPxPIHAtoBo1un79+ozz9/LLL7vp6Zo1a2YdO3Y0jSRVXr02bdrYnDlzSOKcIZUadzZs2GBK5F2nTp3UqDC1LFKBvXv3utRJ+hG8cOFCV5bDDjvMXWrv2bMnl9qL9OxwcAQQ8LNA4ALQ7JjPP/+8a3X4+OOPM566+eabrV69evbkk0/aK6+8krGeO8kvMHfuXHv22WdNrVEsCCRKQHk7X3vtNRsyZIj9+OOP7jBVqlSx22+/3a6//noGFyUKnv0igEDSCAQ+AN20aZP16tUrxwm57rrr7LnnnsuxnhXJLdCiRQtr0qRJcleS2hWZgK6w6AeOftyuWbPGlaNWrVp2xx13WJcuXaxkyZJFVjYOjAACCARJIJAB6Pbt223Xrl1WokQJl8x51apVOcznzZtnFStWzLGeFcktoPeEbiwIxFNAnzFPPfWUjRw50nXz0b41i5ECz/bt2xuDHuOpzb4QQCAVBAIXgBYrVsylNVEak7p169ohhxzi+nrqS+DUU0+1X3/91QYPHmyvv/66Pf3006lwDqkjAggkSEB9zjXwUf3K9aNXy7nnnusCT7W2syCAAAIIxCYQuFHwuqz+zTffuMtgZ5xxhptDef/997fly5c7gYkTJ7rndAn+mmuuiU2FVyGAQMoKhEIhmzx5sjVv3txOPvlk19dTg406dOjg5mmfPn26m80oZYGoOAIIIBAHgWLhD9tQHPZT5LvYvXu3KRDVCGh9WVStWjWhZVLw+8QTT5D0PKHKBd+5cjC+Eh54Nnr06IK/mFektIByCWtgkS61f//9987i4IMPdj9kNbCxRo0aKe1D5RFAAIF4CgTuErwusau/1ZFHHpnFQcGnlsqVK2dZz4PUElAe2E6dOqVWpaltoQSUp/OZZ56xF154wTZu3Oj2Va1aNbvhhhtMV1LKlStXqP3zYgQQQACBnAKBuwTfr18/N9ORRqEmSeNtzrPCmpgFqlevbi1btoz59bwwdQSmTZvm8gVrFLvSKSn4PPPMM23MmDGuS49SKhF8ps77gZoigIC3AoELQMVz0EEHWd++fU0zjkQbAe8tIUdDAIGgCPz55582fPhwO+GEE+z888+3//znP67rzlVXXeX6d86ePdsuv/xyty4odaKcCCCAQBAFAhmANmjQwH1ZaEYkXXLVZbIFCxYE0Z8yI4CABwLz5893CeKVLP7GG290fTzVT1xTZaanp7u+n/Xr1/egJBwCAQQQQEACgQxAVXCNTv3qq69cS+i4ceNcCqazzjrLNDXnkiVLbOfOndqMJcUEdO5HjBiRYrWmutEEtm3b5vp16gfraaedZpo1TQONNG2vPjPU9/Puu++2SpUqRXs56xBAAAEEEigQ2ABUJko4ft9997mR76NGjXKPr776ajcPuC7TaxABS2oJbN261bVopVatqW1mga+//tq6d+/uBirq6oh+qJYvX95uueUW1/KpaXsvu+wyksdnRuM+Aggg4LFA4EbBR/M54IADLC0tzd00Sn7x4sX23XffMYAgGlaSr2vUqBGpsZL8HEer3h9//OFSb7344ou2cOHCjE0aN27sLr1rogp9TrAggAACCPhDICkC0MyU6telGyOhM6twH4HkE9izZ4999NFHLu/r+++/7yalUC01BW/nzp3t2muvdYONkq/m1AgBBBAIvkDgAlD12YpMiRd8fmqAAAIFFdAVDk2z+9JLL5kmoNCi3MD60akuOJdccomVLFmyoLtlewQQQAABDwUCF4Aed9xxGTzKA6q54aMt27dvd6tLly4d7WnWJanAhg0bXJ/gOnXqJGkNU7Naa9assTfeeMPU1ztzxgv17ezTp48pjZJGuLMggAACCARDIJCDkDRd3tFHH+36dGlKTOXuy7507NjRunTpkn01j5NcYO7cuabJCliCL6CcncpqoXyd6lajxPAKPhV09ujRwz799FPTD44777yT4DP4p5saIIBAigkErgVUc30rsGzatKkbdPTWW29ZkyZN3PzNvXv3TrHTR3WzC7Ro0cK9H7Kv53EwBJQ6acKECaa/68mTJ2f06yxVqpRdfPHFbppV/c8l9mCcT0qJAAII5CYQuAB05MiRpiDjww8/dHVSImmlYlLKpTJlytDqmduZTpH1Ss2lG0twBJSbc9KkSfb222/bxIkTXa5OlX6//fZzOTt1NaNt27ZktQjOKaWkCCCAQJ4CgQtAf/nllyxBpvqADho0yDQiVjn/1A9Ml+xYEEDAvwJbtmxxwaYSwiv4VBCqRX/Pmo/9iiuuMKVOOuKII/xbCUqGAAIIIBCzQOAC0MqVK9v06dMt++X2wYMHuwTk7dq1sxkzZsQM8vfff5v6nuW1aKalyAjcvLbleQQQMNPUuUqX9O6775qSwe/YscOxKOhU/lbNwa6/36OOOgouBBBAAIEkFwhcAKrLcZ06dXKtnT179nRTcEbOkdKy6AtM/UMrVKhg9erVizyV7//fe+89u/nmm/PcfuPGjabWWCW6ZvGPgPoIv/LKKy4puX9Klbol+eGHH1zQqcBzzpw5tnfvXoehy+vqu61L65qVSIOMWBBAAAEEUkcgcAFohw4dbNmyZaYWT/X5PPXUUzPO1v77729jxoxx0/ApCIklANWlP91YgilQu3Zt9wMlmKUPfqmVo3fmzJluIJEGE/34448ZldJAIs3D3qZNG2vdujVzsGfIcAcBBBBIPYFi4VyaoSBWW5fKN23alGsfsS+++MLWrl3rklIHsX6UGYGgCGj6Ww0KVF9OXVpX/87IoisRF110kfs7vPDCC+3ggw+OPMX/CCCAAAIpLBDYADRyzhQ///77724mFOUHZEEAgcQKaMCQ+llPmTLFTYX53XffZTmgJgFQqiTdlKdXsxSxIIAAAgggkFkgcJfgVfhVq1bZsGHD3OV23Y8MBipbtqzVqFHDjYIfOHAgrS2ZzzT3EYhRQBkmvv76a5s2bZpr4VRfzsgAIu1SXWF0aV1TYerGIKIYoXkZAgggkEICgWsBjQz80chZpWmpWbOmmxlFj//44w/7+eefbezYsaaWUX1h1qpVKxCnc/ny5TZv3jyXgoYBGbGfsiVLlrg+iJophyU2AQWc33zzjZtpSLMNqbUz82V1DSA67bTT7IILLnA3tXKSezU2a16FAAIIpKpA4FpAhwwZ4lo51ddMgxqiLQ8++KBridGUnWoJDcJy/fXXu/RSKqumGdUI4bPPPtvdNLCGJX8CW7dudem48rc1W0lA/am/+uormzVrlgs21cK5efPmLDjHHXecnXfeea6lU/8feuihWZ7nAQIIIIAAAgURCFwLqNIeaSpOJZ3f1zJq1CgbPny4aTBSEBa11j755JMuCNDgqszLYYcd5lpGlaBbrU3169e30qVLZ96E+wjkW2DNmjU2d+5cd5s9e7ZreVde28zLMcccY+ecc467nXvuuab8uywIIIAAAgjESyBwAWjfvn1t3bp1LtfjvhCuvvpqN0p+/Pjx+9rMd88pT+KiRYtcS5TS2ShAUMCQeVG6qbp161rDhg2tQYMG7nb88ce7qQszb8d9BNQiPH/+fPvyyy/tgw8+sM8//9yyB5u6pK6BQ/pxp1Z3tb4feeSR4CGAAAIIIJAwgcAFoAsWLHCtgUo2n5aW5vp4KtWLvkTVB3TFihUuCXkkJYy2C/ry008/uSTeujSqlqvFixe7qUcz10vpbZQTVX3zlP9UNwWljEDOrJTc93XZXH8f6r+p/sS6ff/99xnJ3yO1P/DAA+2ss85yremRVnUN4GNBAAEEEEDAK4HABaCC+e9//2vdunVzgyQiM6tkBtNc8P379zddOkzGZdu2bS64UPcCtWyp/54GZ2VfDjjgADvppJPs5JNPdje1cummgD1Zlw0bNtjq1atdPZO1jnrP60eJfoiotVw3BZ4agJc9rW/JkiWdxemnn+5ayjUoT62cGrTHggACCCCAQFEJBDIAjWDpUuLKlStdq6dmYFE/NY0gT+YAK1L37P8rF2qk1UuXXNUKFi0g0euOOOII+8c//mEnnniiu51wwgmutfTwww/PvtvAPdbsO88++6ybiSdwhc9WYKUXU6CpVkzl2ly6dKl9++237n/l4sy+RH5wRFrA1RquHxy5DdbL/noeI4AAAggg4JVAoAPQfSEpbYz6SqbyYJ0///zTtY4tXLjQ/a8WMwUwmVPqZDYsV66cabTzscce624aiKKbUl1pIFQQFv0Q2b59uwXlkrKCzPT0dFMaLrXsa+pK3TTdrIJP1Sfaoh9akRbtSAu3zp3e8ywIIIAAAgj4XSBpA1CliWnevLm9/fbbfj8HnpZPl2jVaqxAVK1quqmFTbeNGzfmWhb1MVV6KN2qV6/ubtWqVXNJxxUMadAK/U1z8qm7hKaq1E3uuqm7hG5qoVbwGZlIIfurdZlc1urLq1Zq3dRyrZt+LLAggAACCCAQVIGkDUDvvfde14p31VVXBfXceF7u9evXu5Y3tb6pFS7SKqeWuOypobIXToPAdAlf3SAUdKnF9JxwGh+tq1SpknusdeoeoVuQE5drZLn6mqrbg8yUlUG3tWvX2m+//eayFihzgWbpUiv0vha5ValSxbUyR1qc1QKt3K96nMot+Pty4zkEEEAAgWALJG0AGuzT4r/Sq3VUGQYit0hrnlrw1Lqn4CvagLDcaqLpG9VKrZta8yI3rddNLa4HHXSQuykI0019HNWfUTcNrtHlZgWyannVTS2GkZtaenXTrD4ql1oZdVO/4chNCdh10yV79alU4KybuijoplHlaiFWUFm+fHkXTMohexqj3Oqo9SqzAkxNT6mbWo0jLciR1mTVhQUBBBBAAIFUEgh8AKogQy1RCkAUJLAUjYCCOwVqGoGu3KUK4HRuFJiqdVAthTpPuildVm6XnYum9AU7qtIYqRW3YsWKrmVXLby6qbVXA7x0U0uwbrwnC2bL1ggggAACqSEQyABUlzaHDRtmY8aMcZc5I8GMBp7UqFHDlIZJU3CqFY3FnwJqXVRrom66vK/HulwdaX3UZW61RqplUrdIa6X+j7RgaoCOzr1aOSMtnVqnbdSKqtZQXeLWjxO1lkZaTNXiqFZUtU7qptZVBZW66T2jm16v95NeqxZUpbNSa60CSkaV+/M9RakQQAABBIIjELgAVIM3NGOLgov27du7vnMKCvRYLWsa2DF27FjX+qbpLZX3kAUBBBBAAAEEEEDAPwKBC0B79+5tSiv08ccf59oSpVawli1butle1BLKggACCCCAAAIIIOAfgf38U5T8lUQzvnTu3DnX4FN70cCUrl272ocffpi/nbIVAggggAACCCCAgGcCgQtANXe1BrnktUyfPt2NPs5rO55PLoElS5bYiBEjkqtS1AYBBBBAAIEkEwjctCkdO3Y0BaEaXZ2Wlub6eGpEsgabqA/oinCqoNGjR9ukSZPcZfokO19UJw8BDV5SaigWBBBAAAEEEPCvQOD6gIpSUxZ269bNPv3006i5JzUKvn///nbuuef6V56SIYAAAggggAACKSoQyAA0cq6UjkcJ0dXqqYFHyruoaSHVIsqCAAIIIIAAAggg4E+BQAeg/iSlVAgggAACCCCAAAL7EgjcIKR9VYbnENAc7YsXLwYCAQQQQAABBHwsELhBSD62LFTRNLJ/1KhRbsadQu0oxV+s4HPWrFnWo0ePuEl8/vnnVq9ePTf/fNx2yo4KLaBJKbRUr1690PtiB/ETUNeo+fPnW6NGjeK3U/YUFwFlCWGK4LhQxnUnGkCt2fwGDBgQ1/36fWcEoD45Q8pvOnnyZDf1o0+KFMhiaLrNpk2b2tKlS+NW/vHjx7tpPA866KC47ZMdFV7gyy+/dDtp0KBB4XfGHuImoCl09TdTrly5uO2THcVHQN8xmla4RnjKahb/CGgci8azpFoASh9Qn7wHJ0yYYCNHjrQPPvjAJyWiGBEBtRjMmzfPjjzyyMgq/veBQGSWs/vuu88HpaEIEYE1a9bYaaedZqtXr46s4n+fCLRq1cplkPnnP//pkxJRDAmk6vc/fUB5/yOAAAIIIIAAAgh4KkAA6ik3B0MAAQQQQAABBBAgAOU9gAACCCCAAAIIIOCpAAGop9wcDAEEEEAAAQQQQIAAlPcAAggggAACCCCAgKcCBKCecnMwBBBAAAEEEEAAAQJQ3gMIIIAAAggggAACngoQgHrKzcEQQAABBBBAAAEESETvk/fAli1bTPOYM0OFT05IpmJoVqVjjz3WzYaUaTV3i1hg3bp1rgSVKlUq4pJw+MwCu3fvth9//NFOOOGEzKu57wMBzbhToUIFK1OmjA9KQxEiAqn6/U8AGnkH8D8CCCCAAAIIIICAJwJcgveEmYMggAACCCCAAAIIRAQIQCMS/I8AAggggAACCCDgiQABqCfMHAQBBBBAAAEEEEAgIkAAGpHgfwQQQAABBBBAAAFPBAhAPWHmIAgggAACCCCAAAIRAQLQiAT/I4AAAggggAACCHgiQADqCTMHQQABBBBAAAEEEIgIEIBGJPgfAQQQQAABBBBAwBMBAlBPmDkIAggggAACCCCAQESAADQiwf8IIIAAAggggAACnggQgHrC/H8HCYVC//cgn/dieU0+d81m/18gVuO9e/dimGCBWM9NgouV8ruP9bzE+rqUBy8AQCzGfJYVALgQm27fvr1Ar47lXBboAEW4MQGoR/ivvvqqnXPOOXbggQdagwYN7NNPP83zyN98842lpaXZoYceajVr1rT7778/z9ewQcEEYjH+7rvv7KKLLrKyZcu681m/fn2bOnVqwQ7M1vsU2Lp1q91xxx127LHHWvny5e2yyy6zDRs27PM1mZ/ctm2b1apVy3r37p15NffjIBDLZ9lvv/1mbdu2tQoVKliNGjWsT58+tmrVqjiUhl1EBGL5m1HQOWjQIKtcubKVKFHCjjvuOHvjjTciu+T/OAu89NJLVrFixXztNZbvpnzt2E8bhaNrlgQLfPbZZ6GSJUuGhg8fHgq/qULdu3cPHXDAAaGFCxfmeuTwF2goHHSGrrzyytD8+fNDL7/8cigcvIYeeOCBXF/DEwUTiMU4HASFqlSpEqpXr15o9OjRoY8++ih08cUXh8If3qF58+YVrABsnavADTfcEAoHkKFwYB/S38/JJ58cOuWUU0LhL8xcX5P5iZ49e+pSQ6hXr16ZV3O/kAKxfJb9/fffoWrVqoXCP7xDH3/8cSgc4ITCPyxC4R/XhSwNL88sEMvfzCOPPBIqVqxYaPDgwaHPP/88dN1117m/mw8//DDzrrkfB4F3333XxQGlS5fOc2+xfDfluVMfbmA+LFPSFemEE07I8WF70kknha6++upc63rfffeFwi1soXBzfcY2AwcODIV/PYX0gc5SeIFYjF988UX3Af3ll19mFODPP/8MHXzwwaFwa1vGOu7ELrBo0aLQfvvtF3rvvfcydhJudc73F6OCnHCraejII48kAM0QjM+dWD7LnnvuuVD4Kk5o5cqVGYWYOHFi6KijjgqFW0Yz1nEndoFY/2ZOPfXU0IUXXphx4N27d7sf2FdddVXGOu4UTkDfD/qxpR/EtWvXDuUnAI3lu6lwpSyaV3MJPsHN0b/++qstXbrULr300ixHat26tU2aNCnLuswPwi1r1rJlSwu3lGas1mt+//13++qrrzLWcSd2gViMwy2fNmLECDv99NMzDqxL8bqsEv6gyVjHndgF1J0hfMXAvf8jewkHPhb+8LZw4BJZFfX/LVu22DXXXGNPPPGEu9wbbt2Juh0rCy4Q62fZa6+9Zh06dLBwwJlxUHVhCQekdvjhh2es407sArH+zahLRObPrXAYYuEg1HUvir00vDKzQPjKmM2aNcvCP6gtfPXT8vOZFMt3U+ZjBuU+AWiCz9SPP/7ojhC+bJvlSHq8fv16y63j93//+1+L9hrtRP2pWAovEItx+DKw+xDJfHR9uKxYscIaNWqUeTX3YxTQeTnssMNcEJp5F+qntnbt2syrcty/9dZb7cQTT7TOnTvneI4VhROI9bNMgWadOnVszJgx7keF+sCrP7sCHZb4CMT6N9OjRw8Ld/GyO++80z755BP3423Hjh3WtWvX+BSMvZgaLZYtW2ZqQMrvEst3U3737aft9vdTYZKxLGqR0aJfmpkXDSzas2ePG1ihL9vsy+bNm3O85pBDDnGb5fUlnH1fPI4uEA9jnd9wP0M7/vjj7dprr41+INYWSEDnRQOPsi/6m9nXez/cb83efvttW7JkSfaX8jgOArF8lqlFTT+Yx40bZ3PnzrWOHTuaRgHfe++97soQA17icGLCu4j1b0aD+2666SYL9wV1N5VGA2U0sJIlPgLlypUr8I7i8d1U4IMWwQsIQBOMvv/+/yPOrdl9586dUUugEYnZXxN5vGvXrqivYWXBBAprrA+Jf/7zn+5SorIa6LIxS+EFdF7CfUBz7Ejv/9z+XjZt2uR+ADz66KNZLvXm2AkrYhaI5bMs3F/dnTO1rqkFVZkJtIT7s9uAAQPstttus9NOOy3mMvHC/wnE8jejV4bHIdgHH3xgQ4cOtebNm1t4YKXLHKER9eFBTfAWkUBhv5uKqNgFPmzOT/kC74IX7EsgPBDCPa0vyMzLxo0b3UP1H4y2HHHEERbZJvJ8ZB9lypSJrOL/QggUxlgpgc4991xTSib1vwqP0i5ESXhpZoFo50XP6+8ht78XpfXRDwClbdKPAd30Jap+i7qvQIilcAKxfJaFB1yYPq/OPvvsjOBTpbjiiitcYejPXrhzEnl1LH8z+gxTSi11W9EPgbp167pW0DZt2tjDDz8c2TX/F4FAtPOZjN//tIAm+M2lN5KWNWvWZDmSLktp4EpuwaRel72vZ2QfkVaELDvkQYEFYjX+448/7Pzzz3cDwmbMmOH6HBb44LwgVwEFOuofrS4qxYsXz9hOfw/KpRttWbBggf3888/WrFmzLE+rb646/+v/6tWrZ3mOBwUTiPWzTH13w2mYshxM+1Ird+SqTpYneVBggVj+ZsJpl9wYhEsuuSTL8dRXUV0jfvrpJ5d/OsuTPPBEINbvJk8KF8eD0AIaR8xou9IHwz/+8Y8co3cnTJhg5513XrSXuHUKcNSnTV/CkUUjgNUCxCWriEjh/o/FWIPGlJ1ArXEafKQBLyzxFVAQqUTyarmMLPoyVDaJ3P5mdBnxl19+yXLTqPkuXbq4dVWrVo3siv9jFCjMZ5n+VjJ3n1AGEP0tNWzYMMbS8LLMArH8zUR+FHz77beZd+X+7vTDT+ebpWgEYvluKpqSFvKoRZP9KbWOGk7b4xLPjx07NqScYA8++KB7vHz58gwIJc5WMuDIsnr1apfcXIm0wy1uofCXsctt+OSTT0Y24f9CCuTHONxvLXT55ZeHpk+f7o42cuRIl89Nkwkov2HmW/hLtZAl4uURgXD3hpBy5f7www+h8GX0UDjwDDVu3DhLIvrsfzOR10b+1+vJzRrRiM//+fkse/31193fzF9//eUOGh7RGwr3Hw116tQplJ6eHtLfSXjQXih8WT6kvJMs8RHI628m+2eZJnUIX1EIVapUyX2+aZINTZYSbuRwCenjUyr2klng8ccfdxPKZF6n+9k/y/Lz3ZR9H0F8TCJ6D86aPmTD/WxcQBn+vRBSMudw35ssR9ZMIS1atMiyLtxK6hLP6zVKrH399dfzgZ1FqPAP8jL+4osvXMD5wgsvuIOdddZZ7rHOSfZb9vNX+NKl7h4UdJ555pnOWMFLeIBESMnoMy/R/mYyP08AmlkjPvfz81l2++23u/MWHqSXcVDNoBSegjPjfCpYCuc0znieO4UXyOtvJvtnmY6oQCd8Cd7NhqTPs3DLp/ueCWc8KHyB2EMOgdwC0GifZXl9N+XYeQBXFFOZw288Fg8ENBBi3bp1OfpD7evQOj26tKhLiJFRqPvanucKLoBxwc28eoUmXlBfwWhpmbwqA8fJKRDLZ5n2ovnf1e89t8FkOY/EmoIKxPI3owF7OjfhHwlWqlSpgh6S7RMkkOzfTQSgCXrjsFsEEEAAAQQQQACB6AIMQoruwloEEEAAAQQQQACBBAkQgCYIlt0igAACCCCAAAIIRBcgAI3uwloEEEAAAQQQQACBBAkQgCYIlt0igAACCCCAAAIIRBcgAI3uwloEEEAAAQQQQACBBAkQgCYIlt0igAACCCCAAAIIRBcgAI3uwloEEEAAAQQQQACBBAkQgCYIlt0igAACCCCAAAIIRBcgAI3uwloEEEAAAQQQQACBBAkQgCYIlt0igAACCCCAAAIIRBcgAI3uwloEEEAAAQQQQACBBAkQgCYIlt0igAACCCCAAAIIRBcgAI3uwloEEEAAAQQQQACBBAkQgCYIlt0igAACCCCAAAIIRBcgAI3uwloEEEAAAQQQQACBBAkQgCYIlt0igAACCCCAAAIIRBcgAI3uwloEEEAAAQQQQACBBAkQgCYIlt0igAACCCCAAAIIRBcgAI3uwloEEEAAAQQQQACBBAkQgCYIlt0igAACCCCAAAIIRBcgAI3uwloEEEAAAQQQQACBBAkQgCYIlt0igAACCCCAAAIIRBcgAI3uwloEEEAAAQQQQACBBAkQgCYIlt0igAACCCCAAAIIRBcgAI3uwloEEEDAM4GdO3fanj17PDseB0IAAQSKWoAAtKjPAMdHAIECCzz44INWrFgxO+SQQ2zXrl1RX3/OOee4bR577LGoz+d35fjx491+NmzYkN+XWKdOnezss8/O1/Y///yzVa5c2T788MN8bR/PjQ499FB75JFH8r3La6+91k4//fR9br93714bMWKE/f333/vcjicRQCC1BQhAU/v8U3sEAiugAHTLli02bdq0HHVYu3atzZo1K8d6v61Q8HnJJZdYQYLbeNbhiiuusJNOOimeu7S3337bevbsSYtuXFXZGQLJJ0AAmnznlBohkBICxYsXtzPOOMPefffdHPVVq+Wpp56aY72fVqiVsE6dOrm24HpRVpXh4osvjuuh1ALKggACCOQlQACalxDPI4CAbwXatm1r7733nmUPesaOHWvt2rXLUW61jHbt2tWqVKlihx12mLVu3dqWL1+eZbsJEyZYixYtrEKFCu55vSb7snjxYrvgggusfPnyduyxx1r//v0LHEgOHjzYbrjhBps0aVL23ed4/NNPP1n9+vXtiy++yHhO5cy+7v3337fGjRvb7t273XYvvviiC8TLlCljDRo0MD2feVE3hVdeeSVj1YoVK0yX2dUlQC2jb731lutO8Pzzz2dsozujRo1ywbOM1IK7evVq97z2f/fdd7v7Ksfrr7/u7vMPAgggkF2AADS7CI8RQCAwApdddpmtW7fOZs+enVHm9evX22effWYKTjMv6ivarFkz95z6kD7zzDO2Zs0aO+200zICqAULFrjAVQHqq6++6gLVm2++OfNubOnSpdawYUPbuHGjPf7449anTx9TgNa5c+cs2+X14JtvvrGHHnrISpYsmdemdvTRR9uqVats8uTJGdsq2Js3b55NmTIlY924ceOsbNmytv/++9uQIUOse/fuduKJJ7qAUQFhmzZtTNtEloULF1okwN6xY4cz+/LLL+2pp55ywbECZLUmyymyLFq0yO69914XqN500002Z86cDGsdS8G7ll69ejnbyOv4HwEEEMgiEGJBAAEEAiYQbj0MhYMsV+pwABkKB4kZNRg5cmRI68KjykPhD7vQ0KFD3XPDhg0LhS/bh5YtW5axbbjvpVt3/fXXu3XhADXUpEmTjOd159JLL3X7+f333936cNAbCrf8hcKDbDK2C7e4um3CAaFbl5aWFgoHfBnP7+tOenq6e224RXNfm/2/9s4mFLcuiuP71Vu4lIl81A3p5iOFoRhIUYih3MlNl6kMpJCRTAwVSgaMJGMZmCAGFBnKwISMpRt3et7933WejvM+D9eL3v0cv1Wu5+yzz3nW/u26/Vt7rSWwkdvAFjal5nz79i2orq4OOjs73ZiNAgelpaXB0tJSYMVxYIVo8PPnz9R8fRgcHAz0XGi2iCuYn593l3pOvC4uLsLbwfr6uhubnZ11YyMjI4HNvQ2sCE/NsdFfx9BW8ruxjY0N98zDw0NqDh8gAAEIxAkQAX0ix7mAAASyjYCioNE80EzH76enp66CW0fmoekIXUfTiuLJFAFVlDBqVrRFL83h4aFpa2tz0Uc9p5+ioiKTk5NjTk5Onsx9z4ve3l73/sfHR3N7e2uurq7M+Pi4OT4+dkfuYTSzr6/PrePXr1+mqanJ+Rf6qbXrOUWJ46Zo6tevX019fX3qVhjNTA3YD+Xl5aauri41pMiqWkjJJwwCEIDAnxL4+08nMg8CEICAjwQkQGdmZpwgrKqqMvv7++54Pe6rKs51tB639vZ2Y6Om5u7uzlWj2yjikynKhwzt9+/fxkZCXS5lPJ9Sc5RD+VHW1dVlbATBVfcr7UBCUXmuo6Ojbu0HBwemoaHBVFZWGn2WxdMH3KD9R34qBzZql5eXLrUgOiaxaaOs0SGXHxodyM3NdZdh3mn0Hp8hAAEIZCKAAM1EhnEIQCArCCgap9xDRUElliTC7DHzvwqTJLgkMuOmVk6ar56YKtaJz9H90PLz841+1GZIOZZxU2uojzL1PG1tbTV7e3suginhLLEsIaqo7O7urlH0U6bIrkwRWUV445bOz5KSEpfXGp97f38fH+IaAhCAwJsJcAT/ZoS8AAIQ+L8JqOBIEUlVxA8MDKR1R8L07OzsichS9bz6iDY2Nrpm8zqylsCLWrTAScJNYle9LmW61o/NK3UFTjoO/0jr6elx/h0dHRlVsMv0e2dnxxVihS2VtFb5tbW1lfJR1ysrK45PuibxErcSrIrwhqaj+7ggD+9l+q3vkcU7E2SazzgEIPA5CSBAP+e+s2oIJIqAjuHVGklRwHTtl7RYVXTLfvz4Ya6vr10UcWxszNzc3LiKbt2bmppyQnZ5edk1ud/e3jaLi4u6lTId99vCIWMLfIwt2DGqZh8eHnbve+mvBKVe8h8/KA/0/Pzc5XEqAirr6Ohwlf0FBQUuQqoxRYKVu7q2tmZsEZardJc4n5iYcAI6Ly9P056YKubDdk2rq6tmbm7O9Pf3OwH7ZOILF3qHTK2a1D4KgwAEIJCOAAI0HRXGIACBrCLQ3NzsRFdNTY2pra1N67uOmNWySLmgVTZXVMfXypVUm6GWlhb3jCKICwsLRm2a1M5IwjLsaxm+1FbFGwk0iVNFGlWQpON79dNU+6OPNEVqlZOqNZaVlbmvCoVod3e3UXP+0JTXKl+np6fdXKUN2Op8dx3Oif7WehXBVUqDhPjm5qaREC8sLDRfvnyJTn32s4qStB/6vrf+GdRnv4ibEIBAVhP4S2XxWb0CnIcABCDwSgI6ZtZ/ffFCnPA1uqfIaEVFxbMRQM3RO5QX6qvZ9kiuh6hEd3g8ns5XNeTXsXm0S4CKrhTRVCR1aGgo3WMZx5Q7KvH60aI8owPcgAAEvCZABNTr7cE5CEDgIwgUFxdnFJ/6Pgk1VZM/J9g0TwLVZ/EpH9XoXo3sX1qLosEqaFIjepka009OThpVueuY/7WmoinE52upMR8Cn4cAEdDPs9esFAIQgEBGAhKc379/d38aVMf7avUkAakUBbWAwiAAAQi8JwEE6HvS5F0QgAAEspyAGt2ryl45s8o5JYqZ5RuK+xDwlAAC1NONwS0IQAACEIAABCCQVALkgCZ1Z1kXBCAAAQhAAAIQ8JQAAtTTjcEtCEAAAhCAAAQgkFQCCNCk7izrggAEIAABCEAAAp4SQIB6ujG4BQEIQAACEIAABJJKAAGa1J1lXRCAAAQgAAEIQMBTAghQTzcGtyAAAQhAAAIQgEBSCSBAk7qzrAsCEIAABCAAAQh4SgAB6unG4BYEIAABCEAAAhBIKgEEaFJ3lnVBAAIQgAAEIAABTwkgQD3dGNyCAAQgAAEIQAACSSWAAE3qzrIuCEAAAhCAAAQg4CkBBKinG4NbEIAABCAAAQhAIKkEEKBJ3VnWBQEIQAACEIAABDwlgAD1dGNwCwIQgAAEIAABCCSVAAI0qTvLuiAAAQhAAAIQgICnBBCgnm4MbkEAAhCAAAQgAIGkEkCAJnVnWRcEIAABCEAAAhDwlAAC1NONwS0IQAACEIAABCCQVAII0KTuLOuCAAQgAAEIQAACnhL4B9TPJJ0ISkxOAAAAAElFTkSuQmCC" /><!-- --></p>
<p>Note that we have now used the data to determine our ensemble weights and thus the in-sample error estimate for the ensemble is likely to be overly optimistic for the true MSE of the ensemble. We could use an outer layer of cross-validation to evaluate the ensembles performance.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="co">#================================================</span></a>
<a class="sourceLine" id="cb9-2" data-line-number="2"><span class="co"># Exercise 4:</span></a>
<a class="sourceLine" id="cb9-3" data-line-number="3"><span class="co">#</span></a>
<a class="sourceLine" id="cb9-4" data-line-number="4"><span class="co"># a (BONUS) Determine the cross-validated MSE of</span></a>
<a class="sourceLine" id="cb9-5" data-line-number="5"><span class="co"># the super learner ensemble. </span></a>
<a class="sourceLine" id="cb9-6" data-line-number="6"><span class="co"># Hint: Split the data into e.g., two pieces and in </span></a>
<a class="sourceLine" id="cb9-7" data-line-number="7"><span class="co"># each piece run the above code to determine the</span></a>
<a class="sourceLine" id="cb9-8" data-line-number="8"><span class="co"># optimal ensemble. Then get predictions based on</span></a>
<a class="sourceLine" id="cb9-9" data-line-number="9"><span class="co"># that ensemble in the other piece. </span></a>
<a class="sourceLine" id="cb9-10" data-line-number="10"><span class="co">#================================================</span></a></code></pre></div>
<h2 id="the-superlearner-pacakge">The <code>SuperLearner</code> pacakge</h2>
<p>While this professor may have just made you code up your own cross-validation-based ensemble by hand, thankfully, others have written <code>R</code> packages that do this for us. We will discuss the <code>SuperLearner</code> package and how it can be used to fit CV-based ensembles or to tune particular machine learning algorithms.</p>
<p>We begin by illustrating the “default” functionality of the <code>SuperLearner</code> function. For the sake of computational expediency, we will initially consider only a simple library of algorithms: a main effects GLM and an unadjusted (i.e., intercept) model. Later, we will look at how these algorithms are constructed for usage with <code>SuperLearner</code>.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="co"># because cross-validation is used, we need to set to the seed to ensure reproducibility</span></a>
<a class="sourceLine" id="cb10-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">1234</span>)</a>
<a class="sourceLine" id="cb10-3" data-line-number="3"></a>
<a class="sourceLine" id="cb10-4" data-line-number="4"><span class="co"># execute the call to SuperLearner</span></a>
<a class="sourceLine" id="cb10-5" data-line-number="5">sl1 &lt;-<span class="st"> </span><span class="kw">SuperLearner</span>(</a>
<a class="sourceLine" id="cb10-6" data-line-number="6">  <span class="co"># Y is the outcome variable</span></a>
<a class="sourceLine" id="cb10-7" data-line-number="7">  <span class="dt">Y =</span> full_data<span class="op">$</span>mi,</a>
<a class="sourceLine" id="cb10-8" data-line-number="8">  <span class="co"># X is a dataframe of features, in this case</span></a>
<a class="sourceLine" id="cb10-9" data-line-number="9">  <span class="co"># everything in full_data except for mi</span></a>
<a class="sourceLine" id="cb10-10" data-line-number="10">  <span class="dt">X =</span> full_data[,<span class="op">-</span><span class="kw">ncol</span>(full_data)], </a>
<a class="sourceLine" id="cb10-11" data-line-number="11">  <span class="co"># newX will be discussed later, for now leave as NULL (default)</span></a>
<a class="sourceLine" id="cb10-12" data-line-number="12">  <span class="dt">newX =</span> <span class="ot">NULL</span>,</a>
<a class="sourceLine" id="cb10-13" data-line-number="13">  <span class="co"># family will be discussed in more detail when we see how wrappers</span></a>
<a class="sourceLine" id="cb10-14" data-line-number="14">  <span class="co"># are written, for now set to binomial() for 0/1 outcome</span></a>
<a class="sourceLine" id="cb10-15" data-line-number="15">  <span class="dt">family =</span> <span class="kw">binomial</span>(), </a>
<a class="sourceLine" id="cb10-16" data-line-number="16">  <span class="co"># SL.library (for now) is specified as a vector of names of functions</span></a>
<a class="sourceLine" id="cb10-17" data-line-number="17">  <span class="co"># that implement the desired algorithms. SL.glm and SL.mean</span></a>
<a class="sourceLine" id="cb10-18" data-line-number="18">  <span class="co"># are included in the Super Learner package</span></a>
<a class="sourceLine" id="cb10-19" data-line-number="19">  <span class="dt">SL.library =</span> <span class="kw">c</span>(<span class="st">&quot;SL.glm&quot;</span>,<span class="st">&quot;SL.mean&quot;</span>),</a>
<a class="sourceLine" id="cb10-20" data-line-number="20">  <span class="co"># method specifies how the ensembling is done, for now we will use</span></a>
<a class="sourceLine" id="cb10-21" data-line-number="21">  <span class="co"># the \sum_{k=1}^K \alpha_k f_{k,n} method by using the default</span></a>
<a class="sourceLine" id="cb10-22" data-line-number="22">  <span class="co"># option for method (method.NNLS)</span></a>
<a class="sourceLine" id="cb10-23" data-line-number="23">  <span class="dt">method =</span> <span class="st">&quot;method.NNLS&quot;</span>,</a>
<a class="sourceLine" id="cb10-24" data-line-number="24">  <span class="co"># id specifies a unique subject identifier so that whole subjects </span></a>
<a class="sourceLine" id="cb10-25" data-line-number="25">  <span class="co"># are sampled in CV, not just rows of data. full_data only has one row </span></a>
<a class="sourceLine" id="cb10-26" data-line-number="26">  <span class="co"># per subject, so OK to leave as NULL (default)</span></a>
<a class="sourceLine" id="cb10-27" data-line-number="27">  <span class="dt">id =</span> <span class="ot">NULL</span>, </a>
<a class="sourceLine" id="cb10-28" data-line-number="28">  <span class="co"># verbose controls the printing of messages of SuperLearner's progress.</span></a>
<a class="sourceLine" id="cb10-29" data-line-number="29">  <span class="co"># We'll leave as FALSE (default) for now</span></a>
<a class="sourceLine" id="cb10-30" data-line-number="30">  <span class="dt">verbose =</span> <span class="ot">FALSE</span>, </a>
<a class="sourceLine" id="cb10-31" data-line-number="31">  <span class="co"># control contains options related to logistic ensemble (trimLogit) </span></a>
<a class="sourceLine" id="cb10-32" data-line-number="32">  <span class="co"># and whether to save the fit library to look at individual </span></a>
<a class="sourceLine" id="cb10-33" data-line-number="33">  <span class="co"># algorithms later. We will leave as default</span></a>
<a class="sourceLine" id="cb10-34" data-line-number="34">  <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">saveFitLibrary =</span> <span class="ot">TRUE</span>, <span class="dt">trimLogit =</span> <span class="fl">0.001</span>),</a>
<a class="sourceLine" id="cb10-35" data-line-number="35">  <span class="co"># cvControl specifies parameters related to cross validation. Of note</span></a>
<a class="sourceLine" id="cb10-36" data-line-number="36">  <span class="co"># the default is for V=10-fold cross validation. See ?SuperLearner</span></a>
<a class="sourceLine" id="cb10-37" data-line-number="37">  <span class="co"># for more details</span></a>
<a class="sourceLine" id="cb10-38" data-line-number="38">  <span class="dt">cvControl =</span> <span class="kw">list</span>(<span class="dt">V =</span> 10L, <span class="dt">stratifyCV =</span> <span class="ot">FALSE</span>, <span class="dt">shuffle =</span> <span class="ot">TRUE</span>, </a>
<a class="sourceLine" id="cb10-39" data-line-number="39">                   <span class="dt">validRows =</span> <span class="ot">NULL</span>)</a>
<a class="sourceLine" id="cb10-40" data-line-number="40">)</a>
<a class="sourceLine" id="cb10-41" data-line-number="41"></a>
<a class="sourceLine" id="cb10-42" data-line-number="42">sl1</a>
<a class="sourceLine" id="cb10-43" data-line-number="43"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb10-44" data-line-number="44"><span class="co">#&gt; Call:  </span></a>
<a class="sourceLine" id="cb10-45" data-line-number="45"><span class="co">#&gt; SuperLearner(Y = full_data$mi, X = full_data[, -ncol(full_data)], newX = NULL,  </span></a>
<a class="sourceLine" id="cb10-46" data-line-number="46"><span class="co">#&gt;     family = binomial(), SL.library = c(&quot;SL.glm&quot;, &quot;SL.mean&quot;), method = &quot;method.NNLS&quot;,  </span></a>
<a class="sourceLine" id="cb10-47" data-line-number="47"><span class="co">#&gt;     id = NULL, verbose = FALSE, control = list(saveFitLibrary = TRUE,  </span></a>
<a class="sourceLine" id="cb10-48" data-line-number="48"><span class="co">#&gt;         trimLogit = 0.001), cvControl = list(V = 10L, stratifyCV = FALSE,  </span></a>
<a class="sourceLine" id="cb10-49" data-line-number="49"><span class="co">#&gt;         shuffle = TRUE, validRows = NULL)) </span></a>
<a class="sourceLine" id="cb10-50" data-line-number="50"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb10-51" data-line-number="51"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb10-52" data-line-number="52"><span class="co">#&gt;                   Risk      Coef</span></a>
<a class="sourceLine" id="cb10-53" data-line-number="53"><span class="co">#&gt; SL.glm_All  0.02658219 0.8871921</span></a>
<a class="sourceLine" id="cb10-54" data-line-number="54"><span class="co">#&gt; SL.mean_All 0.03041508 0.1128079</span></a></code></pre></div>
<p>From the output, we see that SL.glm_All had the lowest cross-validated risk and is thus the cross-validation-selected estimator (aka the discrete Super Learner). We will discuss why the name of each algorithm has been augmented with the suffix <code>_All</code> when we illustrate variable screening functions later in the document.</p>
<p>Predictions from the discrete and continuous Super Learner on the observed data can now be obtained as follows:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="co"># default call to predict</span></a>
<a class="sourceLine" id="cb11-2" data-line-number="2">slPred &lt;-<span class="st"> </span><span class="kw">predict</span>(sl1)</a>
<a class="sourceLine" id="cb11-3" data-line-number="3"><span class="co"># slPred is a list with two components</span></a>
<a class="sourceLine" id="cb11-4" data-line-number="4"><span class="co">#   pred = continuous SL predictions</span></a>
<a class="sourceLine" id="cb11-5" data-line-number="5"><span class="co">#   library.predict = predictions from each algorithm</span></a>
<a class="sourceLine" id="cb11-6" data-line-number="6"></a>
<a class="sourceLine" id="cb11-7" data-line-number="7"><span class="co"># store the continuous SL predictions</span></a>
<a class="sourceLine" id="cb11-8" data-line-number="8">cslPred &lt;-<span class="st"> </span>slPred<span class="op">$</span>pred</a>
<a class="sourceLine" id="cb11-9" data-line-number="9"></a>
<a class="sourceLine" id="cb11-10" data-line-number="10"><span class="co"># get the discrete SL predictions</span></a>
<a class="sourceLine" id="cb11-11" data-line-number="11">dslPred &lt;-<span class="st"> </span>slPred<span class="op">$</span>library.predict[,<span class="kw">which</span>(sl1<span class="op">$</span>cvRisk<span class="op">==</span><span class="kw">min</span>(sl1<span class="op">$</span>cvRisk))]</a></code></pre></div>
<p>We can also obtain predictions on a new observation:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="co"># generate a new observation set to the mean of each variable</span></a>
<a class="sourceLine" id="cb12-2" data-line-number="2">newObs &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">t</span>(<span class="kw">colMeans</span>(full_data[,<span class="op">-</span><span class="kw">ncol</span>(full_data)])))</a>
<a class="sourceLine" id="cb12-3" data-line-number="3"></a>
<a class="sourceLine" id="cb12-4" data-line-number="4"><span class="co"># all predictions on newObs</span></a>
<a class="sourceLine" id="cb12-5" data-line-number="5">slPredNew &lt;-<span class="st"> </span><span class="kw">predict</span>(sl1,<span class="dt">newdata=</span>newObs)</a>
<a class="sourceLine" id="cb12-6" data-line-number="6"></a>
<a class="sourceLine" id="cb12-7" data-line-number="7"><span class="co"># continuous SL prediction on newObs</span></a>
<a class="sourceLine" id="cb12-8" data-line-number="8">cslPredNew &lt;-<span class="st"> </span>slPredNew<span class="op">$</span>pred</a>
<a class="sourceLine" id="cb12-9" data-line-number="9"></a>
<a class="sourceLine" id="cb12-10" data-line-number="10"><span class="co"># discrete SL prediction on newObs</span></a>
<a class="sourceLine" id="cb12-11" data-line-number="11">dslPredNew &lt;-<span class="st"> </span>slPredNew<span class="op">$</span>library.predict[,<span class="kw">which.min</span>(sl1<span class="op">$</span>cvRisk)]</a></code></pre></div>
<p>If one wishes to access the fitted object for any of the component algorithms (applied to all the data), this can be accessed through the <code>fitLibrary</code> component of the <code>SuperLearner</code> object. For example, to access the <code>glm</code> object from the <code>SL.glm</code> algorithm, we can use:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="co"># obtain gamma GLM with log-link fit</span></a>
<a class="sourceLine" id="cb13-2" data-line-number="2">glmObject &lt;-<span class="st"> </span>sl1<span class="op">$</span>fitLibrary<span class="op">$</span>SL.glm<span class="op">$</span>object</a>
<a class="sourceLine" id="cb13-3" data-line-number="3"></a>
<a class="sourceLine" id="cb13-4" data-line-number="4"><span class="co"># summarize the fit</span></a>
<a class="sourceLine" id="cb13-5" data-line-number="5"><span class="kw">summary</span>(glmObject)</a>
<a class="sourceLine" id="cb13-6" data-line-number="6"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb13-7" data-line-number="7"><span class="co">#&gt; Call:</span></a>
<a class="sourceLine" id="cb13-8" data-line-number="8"><span class="co">#&gt; glm(formula = Y ~ ., family = family, data = X, weights = obsWeights, </span></a>
<a class="sourceLine" id="cb13-9" data-line-number="9"><span class="co">#&gt;     model = model)</span></a>
<a class="sourceLine" id="cb13-10" data-line-number="10"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb13-11" data-line-number="11"><span class="co">#&gt; Deviance Residuals: </span></a>
<a class="sourceLine" id="cb13-12" data-line-number="12"><span class="co">#&gt;     Min       1Q   Median       3Q      Max  </span></a>
<a class="sourceLine" id="cb13-13" data-line-number="13"><span class="co">#&gt; -1.4162  -0.2271  -0.1342  -0.0766   3.5835  </span></a>
<a class="sourceLine" id="cb13-14" data-line-number="14"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb13-15" data-line-number="15"><span class="co">#&gt; Coefficients:</span></a>
<a class="sourceLine" id="cb13-16" data-line-number="16"><span class="co">#&gt;               Estimate Std. Error z value Pr(&gt;|z|)    </span></a>
<a class="sourceLine" id="cb13-17" data-line-number="17"><span class="co">#&gt; (Intercept)  5.4405844  1.9012226   2.862  0.00421 ** </span></a>
<a class="sourceLine" id="cb13-18" data-line-number="18"><span class="co">#&gt; waist       -0.0064552  0.0071065  -0.908  0.36370    </span></a>
<a class="sourceLine" id="cb13-19" data-line-number="19"><span class="co">#&gt; alcoh        0.1127744  0.0110880  10.171  &lt; 2e-16 ***</span></a>
<a class="sourceLine" id="cb13-20" data-line-number="20"><span class="co">#&gt; hdl          0.0044309  0.0052140   0.850  0.39543    </span></a>
<a class="sourceLine" id="cb13-21" data-line-number="21"><span class="co">#&gt; beta         0.3328622  0.2747572   1.211  0.22571    </span></a>
<a class="sourceLine" id="cb13-22" data-line-number="22"><span class="co">#&gt; smoke        0.1358397  0.2704664   0.502  0.61550    </span></a>
<a class="sourceLine" id="cb13-23" data-line-number="23"><span class="co">#&gt; ace          0.3195770  0.2900528   1.102  0.27055    </span></a>
<a class="sourceLine" id="cb13-24" data-line-number="24"><span class="co">#&gt; ldl         -0.0155763  0.0019280  -8.079 6.54e-16 ***</span></a>
<a class="sourceLine" id="cb13-25" data-line-number="25"><span class="co">#&gt; bmi         -0.1718827  0.0188935  -9.097  &lt; 2e-16 ***</span></a>
<a class="sourceLine" id="cb13-26" data-line-number="26"><span class="co">#&gt; aspirin      0.1921275  0.1940136   0.990  0.32204    </span></a>
<a class="sourceLine" id="cb13-27" data-line-number="27"><span class="co">#&gt; gend         0.1720266  0.2266058   0.759  0.44777    </span></a>
<a class="sourceLine" id="cb13-28" data-line-number="28"><span class="co">#&gt; age         -0.0498989  0.0165272  -3.019  0.00253 ** </span></a>
<a class="sourceLine" id="cb13-29" data-line-number="29"><span class="co">#&gt; estrgn      -0.2844683  0.3469420  -0.820  0.41226    </span></a>
<a class="sourceLine" id="cb13-30" data-line-number="30"><span class="co">#&gt; glu         -0.0016521  0.0024212  -0.682  0.49503    </span></a>
<a class="sourceLine" id="cb13-31" data-line-number="31"><span class="co">#&gt; ins          0.0009482  0.0022495   0.422  0.67338    </span></a>
<a class="sourceLine" id="cb13-32" data-line-number="32"><span class="co">#&gt; cysgfr      -0.0071902  0.0045757  -1.571  0.11609    </span></a>
<a class="sourceLine" id="cb13-33" data-line-number="33"><span class="co">#&gt; dm           0.4097270  0.2472677   1.657  0.09752 .  </span></a>
<a class="sourceLine" id="cb13-34" data-line-number="34"><span class="co">#&gt; fetuina     -0.3428327  0.7446875  -0.460  0.64525    </span></a>
<a class="sourceLine" id="cb13-35" data-line-number="35"><span class="co">#&gt; whr          0.0397150  0.7534039   0.053  0.95796    </span></a>
<a class="sourceLine" id="cb13-36" data-line-number="36"><span class="co">#&gt; hsed         0.0805406  0.1955452   0.412  0.68043    </span></a>
<a class="sourceLine" id="cb13-37" data-line-number="37"><span class="co">#&gt; race         0.0936239  0.2876978   0.325  0.74486    </span></a>
<a class="sourceLine" id="cb13-38" data-line-number="38"><span class="co">#&gt; logcystat   -0.0288129  0.3140621  -0.092  0.92690    </span></a>
<a class="sourceLine" id="cb13-39" data-line-number="39"><span class="co">#&gt; logtrig     -0.0586191  0.1576144  -0.372  0.70996    </span></a>
<a class="sourceLine" id="cb13-40" data-line-number="40"><span class="co">#&gt; logcrp      -0.0336396  0.0715266  -0.470  0.63813    </span></a>
<a class="sourceLine" id="cb13-41" data-line-number="41"><span class="co">#&gt; logcre      -0.2222800  0.2643888  -0.841  0.40050    </span></a>
<a class="sourceLine" id="cb13-42" data-line-number="42"><span class="co">#&gt; health       0.2299788  0.2707350   0.849  0.39562    </span></a>
<a class="sourceLine" id="cb13-43" data-line-number="43"><span class="co">#&gt; logkcal      0.0325390  0.0410616   0.792  0.42810    </span></a>
<a class="sourceLine" id="cb13-44" data-line-number="44"><span class="co">#&gt; sysbp        0.0047877  0.0033635   1.423  0.15461    </span></a>
<a class="sourceLine" id="cb13-45" data-line-number="45"><span class="co">#&gt; ---</span></a>
<a class="sourceLine" id="cb13-46" data-line-number="46"><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></a>
<a class="sourceLine" id="cb13-47" data-line-number="47"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb13-48" data-line-number="48"><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></a>
<a class="sourceLine" id="cb13-49" data-line-number="49"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb13-50" data-line-number="50"><span class="co">#&gt;     Null deviance: 1280.44  on 4589  degrees of freedom</span></a>
<a class="sourceLine" id="cb13-51" data-line-number="51"><span class="co">#&gt; Residual deviance:  944.26  on 4562  degrees of freedom</span></a>
<a class="sourceLine" id="cb13-52" data-line-number="52"><span class="co">#&gt; AIC: 1000.3</span></a>
<a class="sourceLine" id="cb13-53" data-line-number="53"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb13-54" data-line-number="54"><span class="co">#&gt; Number of Fisher Scoring iterations: 7</span></a></code></pre></div>
<h2 id="writing-algorithms-for-super-learner">Writing algorithms for Super Learner</h2>
<p>The <code>SuperLearner</code> functions works by doing cross-validation of each algorithm that is included in the <code>SL.library</code> option. These character inputs correspond to functions that are included in the <code>SuperLearner</code> package that implement various machine learning algorithms. We can check the algorithms that are included in the <code>SuperLearner</code> by default:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="kw">listWrappers</span>()</a>
<a class="sourceLine" id="cb14-2" data-line-number="2"><span class="co">#&gt; All prediction algorithm wrappers in SuperLearner:</span></a>
<a class="sourceLine" id="cb14-3" data-line-number="3"><span class="co">#&gt;  [1] &quot;SL.bartMachine&quot;      &quot;SL.bayesglm&quot;         &quot;SL.biglasso&quot;        </span></a>
<a class="sourceLine" id="cb14-4" data-line-number="4"><span class="co">#&gt;  [4] &quot;SL.caret&quot;            &quot;SL.caret.rpart&quot;      &quot;SL.cforest&quot;         </span></a>
<a class="sourceLine" id="cb14-5" data-line-number="5"><span class="co">#&gt;  [7] &quot;SL.dbarts&quot;           &quot;SL.earth&quot;            &quot;SL.extraTrees&quot;      </span></a>
<a class="sourceLine" id="cb14-6" data-line-number="6"><span class="co">#&gt; [10] &quot;SL.gam&quot;              &quot;SL.gbm&quot;              &quot;SL.glm&quot;             </span></a>
<a class="sourceLine" id="cb14-7" data-line-number="7"><span class="co">#&gt; [13] &quot;SL.glm.interaction&quot;  &quot;SL.glmnet&quot;           &quot;SL.ipredbagg&quot;       </span></a>
<a class="sourceLine" id="cb14-8" data-line-number="8"><span class="co">#&gt; [16] &quot;SL.kernelKnn&quot;        &quot;SL.knn&quot;              &quot;SL.ksvm&quot;            </span></a>
<a class="sourceLine" id="cb14-9" data-line-number="9"><span class="co">#&gt; [19] &quot;SL.lda&quot;              &quot;SL.leekasso&quot;         &quot;SL.lm&quot;              </span></a>
<a class="sourceLine" id="cb14-10" data-line-number="10"><span class="co">#&gt; [22] &quot;SL.loess&quot;            &quot;SL.logreg&quot;           &quot;SL.mean&quot;            </span></a>
<a class="sourceLine" id="cb14-11" data-line-number="11"><span class="co">#&gt; [25] &quot;SL.nnet&quot;             &quot;SL.nnls&quot;             &quot;SL.polymars&quot;        </span></a>
<a class="sourceLine" id="cb14-12" data-line-number="12"><span class="co">#&gt; [28] &quot;SL.qda&quot;              &quot;SL.randomForest&quot;     &quot;SL.ranger&quot;          </span></a>
<a class="sourceLine" id="cb14-13" data-line-number="13"><span class="co">#&gt; [31] &quot;SL.ridge&quot;            &quot;SL.rpart&quot;            &quot;SL.rpartPrune&quot;      </span></a>
<a class="sourceLine" id="cb14-14" data-line-number="14"><span class="co">#&gt; [34] &quot;SL.speedglm&quot;         &quot;SL.speedlm&quot;          &quot;SL.step&quot;            </span></a>
<a class="sourceLine" id="cb14-15" data-line-number="15"><span class="co">#&gt; [37] &quot;SL.step.forward&quot;     &quot;SL.step.interaction&quot; &quot;SL.stepAIC&quot;         </span></a>
<a class="sourceLine" id="cb14-16" data-line-number="16"><span class="co">#&gt; [40] &quot;SL.svm&quot;              &quot;SL.template&quot;         &quot;SL.xgboost&quot;</span></a>
<a class="sourceLine" id="cb14-17" data-line-number="17"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb14-18" data-line-number="18"><span class="co">#&gt; All screening algorithm wrappers in SuperLearner:</span></a>
<a class="sourceLine" id="cb14-19" data-line-number="19"><span class="co">#&gt; [1] &quot;All&quot;</span></a>
<a class="sourceLine" id="cb14-20" data-line-number="20"><span class="co">#&gt; [1] &quot;screen.corP&quot;           &quot;screen.corRank&quot;        &quot;screen.glmnet&quot;        </span></a>
<a class="sourceLine" id="cb14-21" data-line-number="21"><span class="co">#&gt; [4] &quot;screen.randomForest&quot;   &quot;screen.SIS&quot;            &quot;screen.template&quot;      </span></a>
<a class="sourceLine" id="cb14-22" data-line-number="22"><span class="co">#&gt; [7] &quot;screen.ttest&quot;          &quot;write.screen.template&quot;</span></a></code></pre></div>
<p>Note that both “prediction” and “screening”&quot; algorithms are shown. We focus first on prediction algorithms; screening algorithms are discussed in the next section. Let’s look at the guts of the <code>SL.glm</code> algorithm:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1">SL.glm</a>
<a class="sourceLine" id="cb15-2" data-line-number="2"><span class="co">#&gt; function (Y, X, newX, family, obsWeights, model = TRUE, ...) </span></a>
<a class="sourceLine" id="cb15-3" data-line-number="3"><span class="co">#&gt; {</span></a>
<a class="sourceLine" id="cb15-4" data-line-number="4"><span class="co">#&gt;     if (is.matrix(X)) {</span></a>
<a class="sourceLine" id="cb15-5" data-line-number="5"><span class="co">#&gt;         X = as.data.frame(X)</span></a>
<a class="sourceLine" id="cb15-6" data-line-number="6"><span class="co">#&gt;     }</span></a>
<a class="sourceLine" id="cb15-7" data-line-number="7"><span class="co">#&gt;     fit.glm &lt;- glm(Y ~ ., data = X, family = family, weights = obsWeights, </span></a>
<a class="sourceLine" id="cb15-8" data-line-number="8"><span class="co">#&gt;         model = model)</span></a>
<a class="sourceLine" id="cb15-9" data-line-number="9"><span class="co">#&gt;     if (is.matrix(newX)) {</span></a>
<a class="sourceLine" id="cb15-10" data-line-number="10"><span class="co">#&gt;         newX = as.data.frame(newX)</span></a>
<a class="sourceLine" id="cb15-11" data-line-number="11"><span class="co">#&gt;     }</span></a>
<a class="sourceLine" id="cb15-12" data-line-number="12"><span class="co">#&gt;     pred &lt;- predict(fit.glm, newdata = newX, type = &quot;response&quot;)</span></a>
<a class="sourceLine" id="cb15-13" data-line-number="13"><span class="co">#&gt;     fit &lt;- list(object = fit.glm)</span></a>
<a class="sourceLine" id="cb15-14" data-line-number="14"><span class="co">#&gt;     class(fit) &lt;- &quot;SL.glm&quot;</span></a>
<a class="sourceLine" id="cb15-15" data-line-number="15"><span class="co">#&gt;     out &lt;- list(pred = pred, fit = fit)</span></a>
<a class="sourceLine" id="cb15-16" data-line-number="16"><span class="co">#&gt;     return(out)</span></a>
<a class="sourceLine" id="cb15-17" data-line-number="17"><span class="co">#&gt; }</span></a>
<a class="sourceLine" id="cb15-18" data-line-number="18"><span class="co">#&gt; &lt;environment: namespace:SuperLearner&gt;</span></a></code></pre></div>
<p>Note that <code>SL.glm</code> is a function that takes as input: <code>Y</code>, <code>X</code>, <code>newX</code>, <code>family</code>, <code>obsWeights</code>, and other arguments via <code>...</code>. The <code>family</code> option allows one to use <code>SL.glm</code> when the outcome is both binary and continuous. In this case, <code>SL.glm</code> with <code>family=gaussian()</code> will call <code>glm</code> with <code>family=gaussian()</code> (linear regression); with <code>family=binomial()</code> it calls <code>glm</code> with <code>family=binomial()</code> (logistic regression).</p>
<p>The output of the function must be in a specific format: a list with components <code>pred</code>, a vector of predictions computed on the <code>newX</code> object (not <code>X</code>! source of many errors in my life…), and <code>fit</code>, which contains anything that is (1) required for predicting new values later; or (2) desired for later access via the <code>fitLibrary</code> component of the <code>SuperLearner</code> object. Because this <code>fit</code> object may be used for prediction later, it is important to specify its class so that an S3 predict method can be used on the object later. Note that such a method is already included for <code>SL.glm</code>:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1">predict.SL.glm</a>
<a class="sourceLine" id="cb16-2" data-line-number="2"><span class="co">#&gt; function (object, newdata, ...) </span></a>
<a class="sourceLine" id="cb16-3" data-line-number="3"><span class="co">#&gt; {</span></a>
<a class="sourceLine" id="cb16-4" data-line-number="4"><span class="co">#&gt;     if (is.matrix(newdata)) {</span></a>
<a class="sourceLine" id="cb16-5" data-line-number="5"><span class="co">#&gt;         newdata = as.data.frame(newdata)</span></a>
<a class="sourceLine" id="cb16-6" data-line-number="6"><span class="co">#&gt;     }</span></a>
<a class="sourceLine" id="cb16-7" data-line-number="7"><span class="co">#&gt;     pred &lt;- predict(object = object$object, newdata = newdata, </span></a>
<a class="sourceLine" id="cb16-8" data-line-number="8"><span class="co">#&gt;         type = &quot;response&quot;)</span></a>
<a class="sourceLine" id="cb16-9" data-line-number="9"><span class="co">#&gt;     pred</span></a>
<a class="sourceLine" id="cb16-10" data-line-number="10"><span class="co">#&gt; }</span></a>
<a class="sourceLine" id="cb16-11" data-line-number="11"><span class="co">#&gt; &lt;environment: namespace:SuperLearner&gt;</span></a></code></pre></div>
<p>This input/output structure is all that is needed to define a new prediction algorithm for <code>SuperLearner</code>. As an illustration, we could write a new algorithm specifying a our <code>glm</code> that used only <code>waist</code>, <code>smoke</code>, and <code>hdl</code>.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1"><span class="co"># the function must have named arguments Y, X, newX, family, obsWeights, but</span></a>
<a class="sourceLine" id="cb17-2" data-line-number="2"><span class="co"># could have other arguments as well. </span></a>
<a class="sourceLine" id="cb17-3" data-line-number="3">SL.smallglm &lt;-<span class="st"> </span><span class="cf">function</span>(Y, X, newX, family, obsWeights, ...){</a>
<a class="sourceLine" id="cb17-4" data-line-number="4"></a>
<a class="sourceLine" id="cb17-5" data-line-number="5">  <span class="cf">if</span>(family<span class="op">$</span>family <span class="op">==</span><span class="st"> &quot;gaussian&quot;</span>){</a>
<a class="sourceLine" id="cb17-6" data-line-number="6">    <span class="kw">stop</span>(<span class="st">&quot;We only care about using logistic regression right now.&quot;</span>)</a>
<a class="sourceLine" id="cb17-7" data-line-number="7">  }</a>
<a class="sourceLine" id="cb17-8" data-line-number="8"></a>
<a class="sourceLine" id="cb17-9" data-line-number="9">  <span class="co"># the data that will be seen by SL.small glm will be a vector outcome</span></a>
<a class="sourceLine" id="cb17-10" data-line-number="10">  <span class="co"># Y and a data.frame of predictors X, which will in particular include</span></a>
<a class="sourceLine" id="cb17-11" data-line-number="11">  <span class="co"># columns named waist, smoke, hdl</span></a>
<a class="sourceLine" id="cb17-12" data-line-number="12">  model2 &lt;-<span class="st"> </span><span class="kw">glm</span>(Y <span class="op">~</span><span class="st"> </span>waist <span class="op">+</span><span class="st"> </span>smoke <span class="op">+</span><span class="st"> </span>hdl, <span class="dt">data =</span> X, <span class="dt">family =</span> <span class="kw">binomial</span>())</a>
<a class="sourceLine" id="cb17-13" data-line-number="13">  </a>
<a class="sourceLine" id="cb17-14" data-line-number="14">  <span class="co"># get predictions on newX object as we did in Psi1 above</span></a>
<a class="sourceLine" id="cb17-15" data-line-number="15">  pred &lt;-<span class="st"> </span><span class="kw">predict</span>(model2, <span class="dt">newdata =</span> newX, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb17-16" data-line-number="16">  </a>
<a class="sourceLine" id="cb17-17" data-line-number="17">  <span class="co"># save the fit object</span></a>
<a class="sourceLine" id="cb17-18" data-line-number="18">  fit &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">object =</span> model2)</a>
<a class="sourceLine" id="cb17-19" data-line-number="19">  </a>
<a class="sourceLine" id="cb17-20" data-line-number="20">  <span class="co"># because this is simply a different form of glm, </span></a>
<a class="sourceLine" id="cb17-21" data-line-number="21">  <span class="co"># we can use predict.SL.glm to get predictions back, </span></a>
<a class="sourceLine" id="cb17-22" data-line-number="22">  <span class="co"># i.e. no need to write a new predict function</span></a>
<a class="sourceLine" id="cb17-23" data-line-number="23">  <span class="kw">class</span>(fit) &lt;-<span class="st"> &quot;SL.glm&quot;</span></a>
<a class="sourceLine" id="cb17-24" data-line-number="24">  </a>
<a class="sourceLine" id="cb17-25" data-line-number="25">  <span class="co"># out must be list with named objects pred (predictions on newX)</span></a>
<a class="sourceLine" id="cb17-26" data-line-number="26">  <span class="co"># and fit (anything needed to get predictions later)</span></a>
<a class="sourceLine" id="cb17-27" data-line-number="27">  out &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">pred =</span> pred, <span class="dt">fit =</span> fit)</a>
<a class="sourceLine" id="cb17-28" data-line-number="28">  <span class="kw">return</span>(out)</a>
<a class="sourceLine" id="cb17-29" data-line-number="29">}</a></code></pre></div>
<p>We have now defined a new algorithm for use in the SuperLearner.</p>
<p>This new algorithms can now be added to the library we used previously:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1234</span>)</a>
<a class="sourceLine" id="cb18-2" data-line-number="2"></a>
<a class="sourceLine" id="cb18-3" data-line-number="3">sl2 &lt;-<span class="st"> </span><span class="kw">SuperLearner</span>(</a>
<a class="sourceLine" id="cb18-4" data-line-number="4">  <span class="dt">Y =</span> full_data<span class="op">$</span>mi,</a>
<a class="sourceLine" id="cb18-5" data-line-number="5">  <span class="dt">X =</span> full_data[,<span class="op">-</span><span class="kw">ncol</span>(full_data)],</a>
<a class="sourceLine" id="cb18-6" data-line-number="6">  <span class="dt">SL.library =</span> <span class="kw">c</span>(<span class="st">&quot;SL.glm&quot;</span>,<span class="st">&quot;SL.smallglm&quot;</span>),</a>
<a class="sourceLine" id="cb18-7" data-line-number="7">  <span class="dt">family =</span> <span class="kw">binomial</span>()</a>
<a class="sourceLine" id="cb18-8" data-line-number="8">  )</a>
<a class="sourceLine" id="cb18-9" data-line-number="9"></a>
<a class="sourceLine" id="cb18-10" data-line-number="10">sl2</a>
<a class="sourceLine" id="cb18-11" data-line-number="11"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb18-12" data-line-number="12"><span class="co">#&gt; Call:  </span></a>
<a class="sourceLine" id="cb18-13" data-line-number="13"><span class="co">#&gt; SuperLearner(Y = full_data$mi, X = full_data[, -ncol(full_data)], family = binomial(),  </span></a>
<a class="sourceLine" id="cb18-14" data-line-number="14"><span class="co">#&gt;     SL.library = c(&quot;SL.glm&quot;, &quot;SL.smallglm&quot;)) </span></a>
<a class="sourceLine" id="cb18-15" data-line-number="15"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb18-16" data-line-number="16"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb18-17" data-line-number="17"><span class="co">#&gt;                       Risk      Coef</span></a>
<a class="sourceLine" id="cb18-18" data-line-number="18"><span class="co">#&gt; SL.glm_All      0.02658219 0.8877015</span></a>
<a class="sourceLine" id="cb18-19" data-line-number="19"><span class="co">#&gt; SL.smallglm_All 0.03016603 0.1122985</span></a></code></pre></div>
<p>The weights may be different than those computed via grid search since (1) by default <code>SuperLearner</code> uses 10-fold cross-validation and (2) the ensemble for <code>family = binomial()</code> is done based on negative log-likelihood, not MSE. They should be ballpark similar though.</p>
<p>We can double check to make sure that <code>predict.SL.glm</code> works for our the new algorithm we defined by attempting to predict on a new observation:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1">slPredNew2 &lt;-<span class="st"> </span><span class="kw">predict</span>(sl2, <span class="dt">newdata =</span> newObs)</a>
<a class="sourceLine" id="cb19-2" data-line-number="2">slPredNew2</a>
<a class="sourceLine" id="cb19-3" data-line-number="3"><span class="co">#&gt; $pred</span></a>
<a class="sourceLine" id="cb19-4" data-line-number="4"><span class="co">#&gt;            [,1]</span></a>
<a class="sourceLine" id="cb19-5" data-line-number="5"><span class="co">#&gt; [1,] 0.01193353</span></a>
<a class="sourceLine" id="cb19-6" data-line-number="6"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb19-7" data-line-number="7"><span class="co">#&gt; $library.predict</span></a>
<a class="sourceLine" id="cb19-8" data-line-number="8"><span class="co">#&gt;       SL.glm_All SL.smallglm_All</span></a>
<a class="sourceLine" id="cb19-9" data-line-number="9"><span class="co">#&gt; [1,] 0.009879685      0.02816883</span></a></code></pre></div>
<h2 id="machine-learning-algorithms-included-in-the-super-learner">Machine learning algorithms included in the super learner</h2>
<p>We have been focusing on generalized linear models for simplicity; however, there are many more complex algorithms included in the super learner. We discussed several of these algorithms in class (e.g., random forest <code>SL.randomForest</code>, gradient boosting <code>SL.gbm</code>, neural networks <code>SL.nnet</code>).</p>
<p>We can look at each of these functions to see (1) what packages are needed to execute the function; (2) the syntax of a normal call to the function; and (3) what tuning parameters there are. For example, let’s look at <code>SL.randomForest</code></p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1">SL.randomForest</a>
<a class="sourceLine" id="cb20-2" data-line-number="2"><span class="co">#&gt; function (Y, X, newX, family, mtry = ifelse(family$family == </span></a>
<a class="sourceLine" id="cb20-3" data-line-number="3"><span class="co">#&gt;     &quot;gaussian&quot;, max(floor(ncol(X)/3), 1), floor(sqrt(ncol(X)))), </span></a>
<a class="sourceLine" id="cb20-4" data-line-number="4"><span class="co">#&gt;     ntree = 1000, nodesize = ifelse(family$family == &quot;gaussian&quot;, </span></a>
<a class="sourceLine" id="cb20-5" data-line-number="5"><span class="co">#&gt;         5, 1), maxnodes = NULL, importance = FALSE, ...) </span></a>
<a class="sourceLine" id="cb20-6" data-line-number="6"><span class="co">#&gt; {</span></a>
<a class="sourceLine" id="cb20-7" data-line-number="7"><span class="co">#&gt;     .SL.require(&quot;randomForest&quot;)</span></a>
<a class="sourceLine" id="cb20-8" data-line-number="8"><span class="co">#&gt;     if (family$family == &quot;gaussian&quot;) {</span></a>
<a class="sourceLine" id="cb20-9" data-line-number="9"><span class="co">#&gt;         fit.rf &lt;- randomForest::randomForest(Y ~ ., data = X, </span></a>
<a class="sourceLine" id="cb20-10" data-line-number="10"><span class="co">#&gt;             ntree = ntree, xtest = newX, keep.forest = TRUE, </span></a>
<a class="sourceLine" id="cb20-11" data-line-number="11"><span class="co">#&gt;             mtry = mtry, nodesize = nodesize, maxnodes = maxnodes, </span></a>
<a class="sourceLine" id="cb20-12" data-line-number="12"><span class="co">#&gt;             importance = importance)</span></a>
<a class="sourceLine" id="cb20-13" data-line-number="13"><span class="co">#&gt;         pred &lt;- fit.rf$test$predicted</span></a>
<a class="sourceLine" id="cb20-14" data-line-number="14"><span class="co">#&gt;         fit &lt;- list(object = fit.rf)</span></a>
<a class="sourceLine" id="cb20-15" data-line-number="15"><span class="co">#&gt;     }</span></a>
<a class="sourceLine" id="cb20-16" data-line-number="16"><span class="co">#&gt;     if (family$family == &quot;binomial&quot;) {</span></a>
<a class="sourceLine" id="cb20-17" data-line-number="17"><span class="co">#&gt;         fit.rf &lt;- randomForest::randomForest(y = as.factor(Y), </span></a>
<a class="sourceLine" id="cb20-18" data-line-number="18"><span class="co">#&gt;             x = X, ntree = ntree, xtest = newX, keep.forest = TRUE, </span></a>
<a class="sourceLine" id="cb20-19" data-line-number="19"><span class="co">#&gt;             mtry = mtry, nodesize = nodesize, maxnodes = maxnodes, </span></a>
<a class="sourceLine" id="cb20-20" data-line-number="20"><span class="co">#&gt;             importance = importance)</span></a>
<a class="sourceLine" id="cb20-21" data-line-number="21"><span class="co">#&gt;         pred &lt;- fit.rf$test$votes[, 2]</span></a>
<a class="sourceLine" id="cb20-22" data-line-number="22"><span class="co">#&gt;         fit &lt;- list(object = fit.rf)</span></a>
<a class="sourceLine" id="cb20-23" data-line-number="23"><span class="co">#&gt;     }</span></a>
<a class="sourceLine" id="cb20-24" data-line-number="24"><span class="co">#&gt;     out &lt;- list(pred = pred, fit = fit)</span></a>
<a class="sourceLine" id="cb20-25" data-line-number="25"><span class="co">#&gt;     class(out$fit) &lt;- c(&quot;SL.randomForest&quot;)</span></a>
<a class="sourceLine" id="cb20-26" data-line-number="26"><span class="co">#&gt;     return(out)</span></a>
<a class="sourceLine" id="cb20-27" data-line-number="27"><span class="co">#&gt; }</span></a>
<a class="sourceLine" id="cb20-28" data-line-number="28"><span class="co">#&gt; &lt;environment: namespace:SuperLearner&gt;</span></a></code></pre></div>
<p>The line <code>.SL.require(&quot;randomForest&quot;)</code> indicates that we need to have the <code>randomForest</code> <code>R</code> package installed to use this function. The calls to <code>randomForest</code> (<code>fit.rf &lt;- ...</code>) illustrate the syntax of calls to randomForest. The other options that are passed from <code>SL.randomForest</code> to <code>randomForest</code> are the tuning parameters for the algorithm (<code>mtry</code>, <code>ntree</code>, <code>nodesize</code>, <code>maxnodes</code>, …). These are generally given sane default values, but we may wish to include multiple choices as well.</p>
<p>The <code>SuperLearner</code> package can easily be used to implement a single method with different tuning parameter values. As an example, consider using random forests. We will consider three tuning parameters: the number of trees to build <code>ntree</code>, the size of the trees <code>nodesize</code>, and the number of randomly sampled covariates for each tree <code>mtry</code>.</p>
<p>We can define a new function that uses a single set of values for these parameters:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1"><span class="co"># here we simply pass through these values to SL.randomForest</span></a>
<a class="sourceLine" id="cb21-2" data-line-number="2">SL.rf_m5_nt1000_ns3 &lt;-<span class="st"> </span><span class="cf">function</span>(..., <span class="dt">mtry =</span> <span class="dv">5</span>, <span class="dt">ntree =</span> <span class="dv">1000</span>, <span class="dt">nodesize =</span> <span class="dv">3</span>){</a>
<a class="sourceLine" id="cb21-3" data-line-number="3">  <span class="kw">SL.randomForest</span>(..., <span class="dt">mtry =</span> mtry, <span class="dt">ntree =</span> ntree, <span class="dt">nodesize =</span> nodesize)</a>
<a class="sourceLine" id="cb21-4" data-line-number="4">}</a></code></pre></div>
<p>We can also use a loop to define functions over a grid of tuning parameter values:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1">tuneGrid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">mtry =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">5</span>), <span class="dt">ntree=</span><span class="kw">c</span>(<span class="dv">500</span>,<span class="dv">1000</span>), <span class="dt">nodesize=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))</a>
<a class="sourceLine" id="cb22-2" data-line-number="2"></a>
<a class="sourceLine" id="cb22-3" data-line-number="3"><span class="cf">for</span>(i <span class="cf">in</span> <span class="kw">seq</span>(<span class="kw">nrow</span>(tuneGrid))) { </a>
<a class="sourceLine" id="cb22-4" data-line-number="4">  <span class="kw">eval</span>(<span class="kw">parse</span>(<span class="dt">text =</span> <span class="kw">paste0</span>(<span class="st">&quot;SL.rf_m&quot;</span>,tuneGrid[i,<span class="dv">1</span>],<span class="st">&quot;_nt&quot;</span>,tuneGrid[i,<span class="dv">2</span>],<span class="st">&quot;_ns&quot;</span>,tuneGrid[i,<span class="dv">3</span>], </a>
<a class="sourceLine" id="cb22-5" data-line-number="5">                      <span class="st">&quot;&lt;- function(..., mtry = &quot;</span>, tuneGrid[i, <span class="dv">1</span>], <span class="st">&quot;, ntree = &quot;</span>, tuneGrid[i, <span class="dv">2</span>], </a>
<a class="sourceLine" id="cb22-6" data-line-number="6">                      <span class="st">&quot;, nodesize = &quot;</span>, tuneGrid[i,<span class="dv">3</span>],<span class="st">&quot;) { SL.randomForest(..., mtry = mtry, ntree = ntree, nodesize=nodesize)}&quot;</span>)))</a>
<a class="sourceLine" id="cb22-7" data-line-number="7">  }</a></code></pre></div>
<p>We have now created eight new prediction algorithms with each combination of tuning parameters specified in <code>tuneGrid</code>. For example, we can look at the algorithm that uses <code>mtry=3</code>, <code>ntree=500</code>, and <code>nodesize=1</code>:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1">SL.rf_m3_nt500_ns1</a>
<a class="sourceLine" id="cb23-2" data-line-number="2"><span class="co">#&gt; function (..., mtry = 3, ntree = 500, nodesize = 1) </span></a>
<a class="sourceLine" id="cb23-3" data-line-number="3"><span class="co">#&gt; {</span></a>
<a class="sourceLine" id="cb23-4" data-line-number="4"><span class="co">#&gt;     SL.randomForest(..., mtry = mtry, ntree = ntree, nodesize = nodesize)</span></a>
<a class="sourceLine" id="cb23-5" data-line-number="5"><span class="co">#&gt; }</span></a></code></pre></div>
<p>We can collect all of these algorithms by searching through <code>R</code> objects with a similar name:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" data-line-number="1"><span class="co"># get vector of all objects in R</span></a>
<a class="sourceLine" id="cb24-2" data-line-number="2">allObjects &lt;-<span class="st"> </span><span class="kw">ls</span>()</a>
<a class="sourceLine" id="cb24-3" data-line-number="3"><span class="co"># search names of objects for 'SL.randomForest_m'</span></a>
<a class="sourceLine" id="cb24-4" data-line-number="4">allrfobjects &lt;-<span class="st"> </span><span class="kw">grep</span>(<span class="st">&quot;SL.rf_m&quot;</span>,allObjects)</a>
<a class="sourceLine" id="cb24-5" data-line-number="5"><span class="co"># get only objects with 'SL.randomForest_m' in their name</span></a>
<a class="sourceLine" id="cb24-6" data-line-number="6">allRf &lt;-<span class="st"> </span>allObjects[allrfobjects]</a>
<a class="sourceLine" id="cb24-7" data-line-number="7">allRf</a>
<a class="sourceLine" id="cb24-8" data-line-number="8"><span class="co">#&gt; [1] &quot;SL.rf_m3_nt1000_ns1&quot; &quot;SL.rf_m3_nt1000_ns3&quot; &quot;SL.rf_m3_nt500_ns1&quot; </span></a>
<a class="sourceLine" id="cb24-9" data-line-number="9"><span class="co">#&gt; [4] &quot;SL.rf_m3_nt500_ns3&quot;  &quot;SL.rf_m5_nt1000_ns1&quot; &quot;SL.rf_m5_nt1000_ns3&quot;</span></a>
<a class="sourceLine" id="cb24-10" data-line-number="10"><span class="co">#&gt; [7] &quot;SL.rf_m5_nt500_ns1&quot;  &quot;SL.rf_m5_nt500_ns3&quot;</span></a></code></pre></div>
<p>We can now use Super Learner to evaluate the performance of the random forest method using various tuning parameter values:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1"><span class="co"># this will take a while since we are fitting 8x(10 + 1) </span></a>
<a class="sourceLine" id="cb25-2" data-line-number="2"><span class="co"># random forests.</span></a>
<a class="sourceLine" id="cb25-3" data-line-number="3">rf.sl &lt;-<span class="st"> </span><span class="kw">SuperLearner</span>(</a>
<a class="sourceLine" id="cb25-4" data-line-number="4">  <span class="dt">Y =</span> full_data<span class="op">$</span>mi, </a>
<a class="sourceLine" id="cb25-5" data-line-number="5">  <span class="dt">X =</span> full_data[,<span class="op">-</span><span class="kw">ncol</span>(full_data)],</a>
<a class="sourceLine" id="cb25-6" data-line-number="6">  <span class="dt">family =</span> <span class="kw">binomial</span>(),</a>
<a class="sourceLine" id="cb25-7" data-line-number="7">  <span class="dt">method=</span><span class="st">&quot;method.NNLS&quot;</span>,</a>
<a class="sourceLine" id="cb25-8" data-line-number="8">  <span class="dt">SL.library =</span> allRf</a>
<a class="sourceLine" id="cb25-9" data-line-number="9">  )</a>
<a class="sourceLine" id="cb25-10" data-line-number="10"></a>
<a class="sourceLine" id="cb25-11" data-line-number="11">rf.sl</a>
<a class="sourceLine" id="cb25-12" data-line-number="12"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb25-13" data-line-number="13"><span class="co">#&gt; Call:  </span></a>
<a class="sourceLine" id="cb25-14" data-line-number="14"><span class="co">#&gt; SuperLearner(Y = full_data$mi, X = full_data[, -ncol(full_data)], family = binomial(),  </span></a>
<a class="sourceLine" id="cb25-15" data-line-number="15"><span class="co">#&gt;     SL.library = allRf, method = &quot;method.NNLS&quot;) </span></a>
<a class="sourceLine" id="cb25-16" data-line-number="16"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb25-17" data-line-number="17"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb25-18" data-line-number="18"><span class="co">#&gt;                               Risk       Coef</span></a>
<a class="sourceLine" id="cb25-19" data-line-number="19"><span class="co">#&gt; SL.rf_m3_nt1000_ns1_All 0.02798615 0.00000000</span></a>
<a class="sourceLine" id="cb25-20" data-line-number="20"><span class="co">#&gt; SL.rf_m3_nt1000_ns3_All 0.02794101 0.00000000</span></a>
<a class="sourceLine" id="cb25-21" data-line-number="21"><span class="co">#&gt; SL.rf_m3_nt500_ns1_All  0.02795937 0.07225953</span></a>
<a class="sourceLine" id="cb25-22" data-line-number="22"><span class="co">#&gt; SL.rf_m3_nt500_ns3_All  0.02798630 0.00000000</span></a>
<a class="sourceLine" id="cb25-23" data-line-number="23"><span class="co">#&gt; SL.rf_m5_nt1000_ns1_All 0.02785780 0.67307311</span></a>
<a class="sourceLine" id="cb25-24" data-line-number="24"><span class="co">#&gt; SL.rf_m5_nt1000_ns3_All 0.02787465 0.25466735</span></a>
<a class="sourceLine" id="cb25-25" data-line-number="25"><span class="co">#&gt; SL.rf_m5_nt500_ns1_All  0.02799607 0.00000000</span></a>
<a class="sourceLine" id="cb25-26" data-line-number="26"><span class="co">#&gt; SL.rf_m5_nt500_ns3_All  0.02791834 0.00000000</span></a></code></pre></div>
<h2 id="screening-algorithms-for-the-super-learner">Screening algorithms for the Super Learner</h2>
<p>We now discuss how screening algorithms can be utilized to create Super Learner libraries. As the name suggests, these are algorithms that define a screening step prior to the execution of the prediction algorithm. The <code>SuperLearner</code> function will apply this screening step in each of the V folds. The combination of screening algorithm and prediction algorithm defines a new algorithm. We can look at how screening algorithms are constructed for use with the <code>SuperLearner</code> package:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" data-line-number="1"><span class="kw">write.screen.template</span>()</a>
<a class="sourceLine" id="cb26-2" data-line-number="2"><span class="co">#&gt; screen.template &lt;- function(Y, X, family, obsWeights, id, ...) {</span></a>
<a class="sourceLine" id="cb26-3" data-line-number="3"><span class="co">#&gt;   # load required packages</span></a>
<a class="sourceLine" id="cb26-4" data-line-number="4"><span class="co">#&gt;   # require('pkg')</span></a>
<a class="sourceLine" id="cb26-5" data-line-number="5"><span class="co">#&gt;   if (family$family == 'gaussian') {</span></a>
<a class="sourceLine" id="cb26-6" data-line-number="6"><span class="co">#&gt;     </span></a>
<a class="sourceLine" id="cb26-7" data-line-number="7"><span class="co">#&gt;   }</span></a>
<a class="sourceLine" id="cb26-8" data-line-number="8"><span class="co">#&gt;   if (family$family == 'binomial') {</span></a>
<a class="sourceLine" id="cb26-9" data-line-number="9"><span class="co">#&gt;   </span></a>
<a class="sourceLine" id="cb26-10" data-line-number="10"><span class="co">#&gt;   }</span></a>
<a class="sourceLine" id="cb26-11" data-line-number="11"><span class="co">#&gt;   # whichVariable is a logical vector,</span></a>
<a class="sourceLine" id="cb26-12" data-line-number="12"><span class="co">#&gt;   # TRUE indicates variable will be used</span></a>
<a class="sourceLine" id="cb26-13" data-line-number="13"><span class="co">#&gt;   whichVariable &lt;- rep(TRUE, ncol(X))</span></a>
<a class="sourceLine" id="cb26-14" data-line-number="14"><span class="co">#&gt;   return(whichVariable)</span></a>
<a class="sourceLine" id="cb26-15" data-line-number="15"><span class="co">#&gt; }</span></a></code></pre></div>
<p>Screening algorithms take the same input as prediction algorithms, but output a logical vector with <code>TRUE</code> indicating that a column of <code>X</code> should be used in the prediction step. To illustrate why these functions are useful, in our running example, consider the possibility of an interaction between treatment and SOFA score. If we are unsure of the existence of this interaction, we may wish to include algorithms that both do and do not account for this interaction. To construct a new library that includes algorithms both with and without interactions, we can make use of screening algorithms.</p>
<p>Let’s write a screening algorithm that only includes demographic variables:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" data-line-number="1">demographics &lt;-<span class="st"> </span><span class="cf">function</span>(X,...){</a>
<a class="sourceLine" id="cb27-2" data-line-number="2">  returnCols &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">FALSE</span>, <span class="kw">ncol</span>(X))</a>
<a class="sourceLine" id="cb27-3" data-line-number="3">  returnCols[<span class="kw">names</span>(X) <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;age&quot;</span>,<span class="st">&quot;gend&quot;</span>,<span class="st">&quot;race&quot;</span>,<span class="st">&quot;hsed&quot;</span>)] &lt;-<span class="st"> </span><span class="ot">TRUE</span></a>
<a class="sourceLine" id="cb27-4" data-line-number="4">  <span class="kw">return</span>(returnCols)</a>
<a class="sourceLine" id="cb27-5" data-line-number="5">}</a></code></pre></div>
<p>Now we can fit the SuperLearner using the two GLMs both with all variables and only demographic variables. The call to <code>SuperLearner</code> is nearly identical; however, we now specify <code>SL.library</code> as a list, where each component is a vector of the form <code>c(predictionAlgorithm,screeningAlgorithm)</code>. To include all the covariates, we specify the <code>All</code> screening algorithm that is included in the <code>SuperLearner</code> package.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1234</span>) </a>
<a class="sourceLine" id="cb28-2" data-line-number="2"></a>
<a class="sourceLine" id="cb28-3" data-line-number="3"><span class="co"># Fit the Super Learner</span></a>
<a class="sourceLine" id="cb28-4" data-line-number="4">sl3 &lt;-<span class="st"> </span><span class="kw">SuperLearner</span>(</a>
<a class="sourceLine" id="cb28-5" data-line-number="5">  <span class="dt">Y =</span> full_data<span class="op">$</span>mi,</a>
<a class="sourceLine" id="cb28-6" data-line-number="6">  <span class="dt">X =</span> full_data[,<span class="op">-</span><span class="kw">ncol</span>(full_data)],</a>
<a class="sourceLine" id="cb28-7" data-line-number="7">  <span class="dt">SL.library=</span><span class="kw">list</span>(<span class="kw">c</span>(<span class="st">&quot;SL.glm&quot;</span>,<span class="st">&quot;All&quot;</span>),</a>
<a class="sourceLine" id="cb28-8" data-line-number="8">                  <span class="kw">c</span>(<span class="st">&quot;SL.glm&quot;</span>,<span class="st">&quot;demographics&quot;</span>),</a>
<a class="sourceLine" id="cb28-9" data-line-number="9">                  <span class="kw">c</span>(<span class="st">&quot;SL.mean&quot;</span>,<span class="st">&quot;All&quot;</span>), <span class="co"># not adjusted, so doesn't matter</span></a>
<a class="sourceLine" id="cb28-10" data-line-number="10">                  <span class="kw">c</span>(<span class="st">&quot;SL.smallglm&quot;</span>,<span class="st">&quot;All&quot;</span>)),</a>
<a class="sourceLine" id="cb28-11" data-line-number="11">  <span class="dt">family =</span> <span class="kw">binomial</span>()</a>
<a class="sourceLine" id="cb28-12" data-line-number="12">  )</a>
<a class="sourceLine" id="cb28-13" data-line-number="13"></a>
<a class="sourceLine" id="cb28-14" data-line-number="14">sl3</a>
<a class="sourceLine" id="cb28-15" data-line-number="15"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb28-16" data-line-number="16"><span class="co">#&gt; Call:  </span></a>
<a class="sourceLine" id="cb28-17" data-line-number="17"><span class="co">#&gt; SuperLearner(Y = full_data$mi, X = full_data[, -ncol(full_data)], family = binomial(),  </span></a>
<a class="sourceLine" id="cb28-18" data-line-number="18"><span class="co">#&gt;     SL.library = list(c(&quot;SL.glm&quot;, &quot;All&quot;), c(&quot;SL.glm&quot;, &quot;demographics&quot;),  </span></a>
<a class="sourceLine" id="cb28-19" data-line-number="19"><span class="co">#&gt;         c(&quot;SL.mean&quot;, &quot;All&quot;), c(&quot;SL.smallglm&quot;, &quot;All&quot;))) </span></a>
<a class="sourceLine" id="cb28-20" data-line-number="20"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb28-21" data-line-number="21"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb28-22" data-line-number="22"><span class="co">#&gt;                           Risk       Coef</span></a>
<a class="sourceLine" id="cb28-23" data-line-number="23"><span class="co">#&gt; SL.glm_All          0.02658219 0.88191870</span></a>
<a class="sourceLine" id="cb28-24" data-line-number="24"><span class="co">#&gt; SL.glm_demographics 0.03031070 0.01335312</span></a>
<a class="sourceLine" id="cb28-25" data-line-number="25"><span class="co">#&gt; SL.mean_All         0.03041508 0.01455926</span></a>
<a class="sourceLine" id="cb28-26" data-line-number="26"><span class="co">#&gt; SL.smallglm_All     0.03016603 0.09016893</span></a></code></pre></div>
<p>Note that the output for <code>sl3</code> lists five algorithms: the three original algorithms each with the interaction (<code>_All</code>) and without (<code>_demographics</code>). Note that this explains why the output for <code>sl1</code> contained the <code>_All</code> addendum: by default <code>SuperLearner</code> uses all the <code>All</code> screening function to pass through all variables in <code>X</code> to the prediction algorithms.</p>
<p>This flexibility in combining screening and prediction algorithms to generate new algorithms allows one to easily implement a library containing a large number of candidate algorithms. Check out <code>listWrappers()</code> to see other screening functions that are useful for more high dimensional settings.</p>
<h2 id="using-different-lossensemble-functions">Using different loss/ensemble functions</h2>
<p>So far, we have been focusing on using mean-squared error loss, by virtue of using the default <code>method=method.NNLS</code>. Because our outcome is binary, we may instead prefer the negative log-likelihood loss function instead. We can easily change our original call to <code>SuperLearner</code> to this loss function:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1234</span>)</a>
<a class="sourceLine" id="cb29-2" data-line-number="2"></a>
<a class="sourceLine" id="cb29-3" data-line-number="3">sl4 &lt;-<span class="st"> </span><span class="kw">SuperLearner</span>(</a>
<a class="sourceLine" id="cb29-4" data-line-number="4">  <span class="dt">Y =</span> full_data<span class="op">$</span>mi,</a>
<a class="sourceLine" id="cb29-5" data-line-number="5">  <span class="dt">X =</span> full_data[,<span class="op">-</span><span class="kw">ncol</span>(full_data)], </a>
<a class="sourceLine" id="cb29-6" data-line-number="6">  <span class="dt">SL.library=</span><span class="kw">c</span>(<span class="st">&quot;SL.glm&quot;</span>,<span class="st">&quot;SL.mean&quot;</span>),</a>
<a class="sourceLine" id="cb29-7" data-line-number="7">  <span class="dt">method =</span> <span class="st">&quot;method.NNloglik&quot;</span>,</a>
<a class="sourceLine" id="cb29-8" data-line-number="8">  <span class="dt">family =</span> <span class="kw">binomial</span>()</a>
<a class="sourceLine" id="cb29-9" data-line-number="9">  )</a>
<a class="sourceLine" id="cb29-10" data-line-number="10"></a>
<a class="sourceLine" id="cb29-11" data-line-number="11">sl4</a>
<a class="sourceLine" id="cb29-12" data-line-number="12"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb29-13" data-line-number="13"><span class="co">#&gt; Call:  </span></a>
<a class="sourceLine" id="cb29-14" data-line-number="14"><span class="co">#&gt; SuperLearner(Y = full_data$mi, X = full_data[, -ncol(full_data)], family = binomial(),  </span></a>
<a class="sourceLine" id="cb29-15" data-line-number="15"><span class="co">#&gt;     SL.library = c(&quot;SL.glm&quot;, &quot;SL.mean&quot;), method = &quot;method.NNloglik&quot;) </span></a>
<a class="sourceLine" id="cb29-16" data-line-number="16"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb29-17" data-line-number="17"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb29-18" data-line-number="18"><span class="co">#&gt;                  Risk      Coef</span></a>
<a class="sourceLine" id="cb29-19" data-line-number="19"><span class="co">#&gt; SL.glm_All  0.1096895 0.9060648</span></a>
<a class="sourceLine" id="cb29-20" data-line-number="20"><span class="co">#&gt; SL.mean_All 0.1399198 0.0939352</span></a></code></pre></div>
<p>We may wish instead to maximize AUC (equivalent to minimizing rank loss); for this, we can specify <code>method=method.AUC</code>:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1234</span>)</a>
<a class="sourceLine" id="cb30-2" data-line-number="2"></a>
<a class="sourceLine" id="cb30-3" data-line-number="3">sl5 &lt;-<span class="st"> </span><span class="kw">SuperLearner</span>(</a>
<a class="sourceLine" id="cb30-4" data-line-number="4">  <span class="dt">Y =</span> full_data<span class="op">$</span>mi,</a>
<a class="sourceLine" id="cb30-5" data-line-number="5">  <span class="dt">X =</span> full_data[,<span class="op">-</span><span class="kw">ncol</span>(full_data)], </a>
<a class="sourceLine" id="cb30-6" data-line-number="6">  <span class="dt">SL.library=</span><span class="kw">c</span>(<span class="st">&quot;SL.glm&quot;</span>,<span class="st">&quot;SL.mean&quot;</span>),</a>
<a class="sourceLine" id="cb30-7" data-line-number="7">  <span class="dt">method =</span> <span class="st">&quot;method.AUC&quot;</span>,</a>
<a class="sourceLine" id="cb30-8" data-line-number="8">  <span class="dt">family=</span><span class="kw">binomial</span>()</a>
<a class="sourceLine" id="cb30-9" data-line-number="9">  )</a>
<a class="sourceLine" id="cb30-10" data-line-number="10"><span class="co">#&gt; Loading required package: cvAUC</span></a>
<a class="sourceLine" id="cb30-11" data-line-number="11"><span class="co">#&gt; Loading required package: ROCR</span></a>
<a class="sourceLine" id="cb30-12" data-line-number="12"><span class="co">#&gt; Loading required package: gplots</span></a>
<a class="sourceLine" id="cb30-13" data-line-number="13"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb30-14" data-line-number="14"><span class="co">#&gt; Attaching package: 'gplots'</span></a>
<a class="sourceLine" id="cb30-15" data-line-number="15"><span class="co">#&gt; The following object is masked from 'package:stats':</span></a>
<a class="sourceLine" id="cb30-16" data-line-number="16"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb30-17" data-line-number="17"><span class="co">#&gt;     lowess</span></a>
<a class="sourceLine" id="cb30-18" data-line-number="18"><span class="co">#&gt; Loading required package: data.table</span></a>
<a class="sourceLine" id="cb30-19" data-line-number="19"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb30-20" data-line-number="20"><span class="co">#&gt; cvAUC version: 1.1.0</span></a>
<a class="sourceLine" id="cb30-21" data-line-number="21"><span class="co">#&gt; Notice to cvAUC users: Major speed improvements in version 1.1.0</span></a>
<a class="sourceLine" id="cb30-22" data-line-number="22"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb30-23" data-line-number="23"></a>
<a class="sourceLine" id="cb30-24" data-line-number="24">sl5</a>
<a class="sourceLine" id="cb30-25" data-line-number="25"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb30-26" data-line-number="26"><span class="co">#&gt; Call:  </span></a>
<a class="sourceLine" id="cb30-27" data-line-number="27"><span class="co">#&gt; SuperLearner(Y = full_data$mi, X = full_data[, -ncol(full_data)], family = binomial(),  </span></a>
<a class="sourceLine" id="cb30-28" data-line-number="28"><span class="co">#&gt;     SL.library = c(&quot;SL.glm&quot;, &quot;SL.mean&quot;), method = &quot;method.AUC&quot;) </span></a>
<a class="sourceLine" id="cb30-29" data-line-number="29"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb30-30" data-line-number="30"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb30-31" data-line-number="31"><span class="co">#&gt;                  Risk Coef</span></a>
<a class="sourceLine" id="cb30-32" data-line-number="32"><span class="co">#&gt; SL.glm_All  0.1583508    1</span></a>
<a class="sourceLine" id="cb30-33" data-line-number="33"><span class="co">#&gt; SL.mean_All 0.5996542    0</span></a></code></pre></div>
<p>Or we can even write our own method. The package contains a template for doing so. It requires a function that returns a list with three components: (1) <code>require</code> lists the packages needed to execute the functions; (2) <code>computeCoef</code> is a function that takes a specific input and returns a cross validated risk estimate and vector of weight coefficients corresponding to the (K) algorithms in the library; (3) <code>computePred</code> a function that computes the ensemble prediction.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" data-line-number="1">method.template</a>
<a class="sourceLine" id="cb31-2" data-line-number="2"><span class="co">#&gt; function () </span></a>
<a class="sourceLine" id="cb31-3" data-line-number="3"><span class="co">#&gt; {</span></a>
<a class="sourceLine" id="cb31-4" data-line-number="4"><span class="co">#&gt;     out &lt;- list(require = NULL, computeCoef = function(Z, Y, </span></a>
<a class="sourceLine" id="cb31-5" data-line-number="5"><span class="co">#&gt;         libraryNames, obsWeights, control, verbose, ...) {</span></a>
<a class="sourceLine" id="cb31-6" data-line-number="6"><span class="co">#&gt;         cvRisk &lt;- numeric()</span></a>
<a class="sourceLine" id="cb31-7" data-line-number="7"><span class="co">#&gt;         coef &lt;- numeric()</span></a>
<a class="sourceLine" id="cb31-8" data-line-number="8"><span class="co">#&gt;         out &lt;- list(cvRisk = cvRisk, coef = coef, optimizer = NULL)</span></a>
<a class="sourceLine" id="cb31-9" data-line-number="9"><span class="co">#&gt;         return(out)</span></a>
<a class="sourceLine" id="cb31-10" data-line-number="10"><span class="co">#&gt;     }, computePred = function(predY, coef, control, ...) {</span></a>
<a class="sourceLine" id="cb31-11" data-line-number="11"><span class="co">#&gt;         out &lt;- crossprod(t(predY), coef)</span></a>
<a class="sourceLine" id="cb31-12" data-line-number="12"><span class="co">#&gt;         return(out)</span></a>
<a class="sourceLine" id="cb31-13" data-line-number="13"><span class="co">#&gt;     })</span></a>
<a class="sourceLine" id="cb31-14" data-line-number="14"><span class="co">#&gt;     invisible(out)</span></a>
<a class="sourceLine" id="cb31-15" data-line-number="15"><span class="co">#&gt; }</span></a>
<a class="sourceLine" id="cb31-16" data-line-number="16"><span class="co">#&gt; &lt;environment: namespace:SuperLearner&gt;</span></a></code></pre></div>
<h2 id="evaluating-the-super-learner">Evaluating the Super Learner</h2>
<p>The <code>SuperLearner</code> package comes with an additional function to objectively evaluate the performance of the SuperLearner predictions relative to those from its component methods. This is achieved by adding an additional outer layer of V-fold cross-validation to the procedure. That is the data is split into, e.g. ten equally sized pieces and each algorithm is trained on nine-tenths of the data – including the Super Learner, which itself uses 10-fold cross-validation – and evaluated on the remaining piece. Each piece of data serves as the evaluation set once and the cross-validated risk of the Super Learner and each component algorithm is computed.</p>
<p>We can use the <code>CV.SuperLearer</code> function to evaluate our over-simplified library:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">1234</span>)</a>
<a class="sourceLine" id="cb32-2" data-line-number="2"></a>
<a class="sourceLine" id="cb32-3" data-line-number="3"><span class="co"># fit cross-validated super learner</span></a>
<a class="sourceLine" id="cb32-4" data-line-number="4">cvsl1 &lt;-<span class="st"> </span><span class="kw">CV.SuperLearner</span>(</a>
<a class="sourceLine" id="cb32-5" data-line-number="5">  <span class="dt">Y =</span> full_data<span class="op">$</span>mi, </a>
<a class="sourceLine" id="cb32-6" data-line-number="6">  <span class="dt">X =</span> full_data[,<span class="op">-</span><span class="kw">ncol</span>(full_data)],</a>
<a class="sourceLine" id="cb32-7" data-line-number="7">  <span class="co"># V specifies the number of outer CV layers used to evalute</span></a>
<a class="sourceLine" id="cb32-8" data-line-number="8">  <span class="co"># the Super Learner (which by default uses 10-fold CV)</span></a>
<a class="sourceLine" id="cb32-9" data-line-number="9">  <span class="dt">V =</span> <span class="dv">10</span>,</a>
<a class="sourceLine" id="cb32-10" data-line-number="10">  <span class="dt">family =</span> <span class="kw">binomial</span>(),</a>
<a class="sourceLine" id="cb32-11" data-line-number="11">  <span class="dt">method=</span><span class="st">&quot;method.NNLS&quot;</span>,</a>
<a class="sourceLine" id="cb32-12" data-line-number="12">  <span class="dt">SL.library =</span> <span class="kw">c</span>(<span class="st">&quot;SL.glm&quot;</span>,<span class="st">&quot;SL.smallglm&quot;</span>)</a>
<a class="sourceLine" id="cb32-13" data-line-number="13">)</a></code></pre></div>
<p>The object itself is not all that informative:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" data-line-number="1">cvsl1</a>
<a class="sourceLine" id="cb33-2" data-line-number="2"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb33-3" data-line-number="3"><span class="co">#&gt; Call:  </span></a>
<a class="sourceLine" id="cb33-4" data-line-number="4"><span class="co">#&gt; CV.SuperLearner(Y = full_data$mi, X = full_data[, -ncol(full_data)],  </span></a>
<a class="sourceLine" id="cb33-5" data-line-number="5"><span class="co">#&gt;     V = 10, family = binomial(), SL.library = c(&quot;SL.glm&quot;, &quot;SL.smallglm&quot;),  </span></a>
<a class="sourceLine" id="cb33-6" data-line-number="6"><span class="co">#&gt;     method = &quot;method.NNLS&quot;) </span></a>
<a class="sourceLine" id="cb33-7" data-line-number="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb33-8" data-line-number="8"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb33-9" data-line-number="9"><span class="co">#&gt; Cross-validated predictions from the SuperLearner:  SL.predict </span></a>
<a class="sourceLine" id="cb33-10" data-line-number="10"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb33-11" data-line-number="11"><span class="co">#&gt; Cross-validated predictions from the discrete super learner (cross-validation selector):  discreteSL.predict </span></a>
<a class="sourceLine" id="cb33-12" data-line-number="12"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb33-13" data-line-number="13"><span class="co">#&gt; Which library algorithm was the discrete super learner:  whichDiscreteSL </span></a>
<a class="sourceLine" id="cb33-14" data-line-number="14"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb33-15" data-line-number="15"><span class="co">#&gt; Cross-validated prediction for all algorithms in the library:  library.predict</span></a></code></pre></div>
<p>However, there is a nice plotting function to display the results:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" data-line-number="1"><span class="co"># plot cross-validated risk</span></a>
<a class="sourceLine" id="cb34-2" data-line-number="2"><span class="kw">plot</span>(cvsl1)</a></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>The plot shows the ordered cross-validated risk estimates and 95% confidence intervals about these estimates for each of the candidate algorithms, in addition to the discrete and continuous Super Learner.</p>

</body>
</html>
